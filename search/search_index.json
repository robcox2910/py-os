{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"PyOS","text":"<p>A simulated operating system built in Python for learning. If you know basic Python and are curious about how computers actually work under the hood, this project is for you.</p> <p>Every module mirrors a real OS subsystem -- processes, memory, filesystems, networking -- built piece by piece using test-driven development.</p>"},{"location":"#what-will-i-learn","title":"What Will I Learn?","text":"<p>Ever wondered what happens when you open a program, save a file, or connect to the internet? An operating system makes all of that work. PyOS builds a mini version of one so you can see the pieces and how they fit together.</p> <p>Start here: What Is an Operating System?</p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Install dependencies\nuv sync\n\n# Run the interactive OS\npython -m py_os\n\n# Run the test suite\nuv run pytest\n</code></pre>"},{"location":"#learn-the-concepts","title":"Learn the Concepts","text":"<p>Each guide explains one part of the OS with real-world analogies and simple language.</p> Guide What You'll Learn What Is an OS? The big picture -- what an OS does and why you need one Processes Programs that are running, how they take turns, forking, and threads Memory How the OS manages limited memory with pages, virtual addresses, and swap Filesystem How files and folders are organised, and how they're saved to disk The Kernel The brain of the OS -- boot sequence and system calls The Shell Typing commands, pipes, scripting, and environment variables Devices and Networking Hardware, inter-process communication, disk scheduling, and sockets Interrupts and Timers Interrupt controller, vectors, masking, timer, preemption TCP: Reliable Delivery Three-way handshake, flow control, congestion control, retransmission Users and Safety Permissions, signals, logging, and deadlocks Synchronization Mutexes, semaphores, condition variables, and race conditions The Boot Chain What happens between pressing power and seeing a prompt Interactive Tutorials Guided lessons that teach OS concepts hands-on Web UI Browser-based terminal interface <p>For a technical overview of every module, see Architecture.</p>"},{"location":"#modules","title":"Modules","text":"Module File What It Teaches Process <code>process/pcb.py</code> Five-state lifecycle, PID assignment Scheduler <code>process/scheduler.py</code> CPU scheduling (FCFS, Round Robin, Priority, Aging Priority, MLFQ, CFS) Memory <code>memory/manager.py</code> Page-based allocation, frame management Virtual Memory <code>memory/virtual.py</code> Address translation, page tables, isolation Filesystem <code>fs/filesystem.py</code> Inodes, path resolution, file CRUD Kernel <code>kernel.py</code> Boot/shutdown lifecycle, subsystem coordination System Calls <code>syscalls.py</code> User/kernel boundary, dispatch table Shell <code>shell.py</code> Commands, pipes, scripting, job control Users <code>users.py</code> Identity, file permissions Devices <code>io/devices.py</code> Null, console, and random devices IPC <code>io/ipc.py</code> Pipes and message queues Signals <code>process/signals.py</code> SIGTERM, SIGKILL, SIGSTOP, SIGCONT, SIGUSR1, SIGUSR2, custom handlers Logging <code>logging.py</code> Kernel log buffer, audit trail Environment <code>env.py</code> KEY=VALUE config Jobs <code>jobs.py</code> Background/foreground job control Swap <code>memory/swap.py</code> Page replacement (FIFO, LRU, Clock) Fork <code>kernel.py</code> Process forking, parent-child trees Threads <code>process/threads.py</code> Lightweight execution within a process Deadlock <code>sync/deadlock.py</code> Detection and Banker's algorithm Disk Scheduling <code>io/disk.py</code> FCFS, SSTF, SCAN, C-SCAN Scripting <code>shell.py</code> Scripts, variables, conditionals Networking <code>io/networking.py</code> Sockets, client-server model Persistence <code>fs/persistence.py</code> Save/load filesystem to JSON Execution <code>process/pcb.py</code> Running programs, exit codes Synchronization <code>sync/primitives.py</code> Mutex, semaphore, condition variable Bootloader <code>bootloader.py</code> Firmware POST, kernel image loading, boot chain Tutorials <code>tutorials.py</code> Guided hands-on lessons using real syscalls DNS <code>io/dns.py</code> Name resolution, A records HTTP <code>io/http.py</code> Request/response protocol, status codes Shared Memory <code>io/shm.py</code> Zero-copy IPC between processes Interrupts <code>io/interrupts.py</code> Interrupt controller, vectors, masking, priority-based servicing Timer <code>io/timer.py</code> Programmable interval timer, tick-driven preemption TCP <code>io/tcp.py</code> Reliable delivery: three-way handshake, flow control, congestion control File Descriptors <code>fs/fd.py</code> Open files, seek, per-process fd tables Journal <code>fs/journal.py</code> Write-ahead log, crash recovery ProcFS <code>fs/procfs.py</code> Virtual /proc filesystem Slab Allocator <code>memory/slab.py</code> Fixed-size object pools mmap <code>memory/mmap.py</code> Memory-mapped file regions Web Frontend <code>web/app.py</code> Browser-based terminal via Flask REPL <code>repl.py</code> Interactive terminal"},{"location":"#shell-commands","title":"Shell Commands","text":"<pre><code>help        List available commands\nps          Show running processes\nls [path]   List directory contents\nmkdir path  Create a directory\ntouch path  Create an empty file\nwrite path  Write content to a file\ncat path    Read file contents\nrm path     Remove a file or directory\nkill pid    Terminate a process by PID\nwhoami      Show the current user\nadduser     Create a new user\nsu uid      Switch to another user\nsignal pid  Send a signal (SIGTERM, SIGKILL, SIGUSR1, etc.)\nhandle pid  Register a signal handler (log, ignore)\nenv         List environment variables\nexport K=V  Set an environment variable\nunset key   Remove an environment variable\nlog         Show kernel log entries\ntop         System status dashboard\nhistory     Show command history\nalias N=CMD Create a command alias\nunalias N   Remove a command alias\njobs        List background jobs\nbg pid      Move a process to background\nfg job_id   Bring a job to foreground\nfork pid    Fork a process (create a child copy)\nwait pid    Wait for any child to terminate and collect its exit code\nwaitpid p c Wait for a specific child (c) of parent (p) to terminate\npstree      Show the process tree hierarchy\nthreads pid List threads of a process\nresources   Show resource allocation status\ndeadlock    Run deadlock detection\ndevices     List registered devices\ndevread     Read from a device\ndevwrite    Write to a device\nscheduler   Show or switch scheduling policy (fcfs, rr, priority, aging, mlfq, cfs)\n            scheduler boost \u2014 reset MLFQ levels (anti-starvation)\nmutex       Manage mutexes (create, list)\nsemaphore   Manage semaphores (create, list)\necho args   Print arguments to output\nsource path Run a script from a file\nrun prog [p] Run a built-in program with optional priority\ngrep pat    Filter piped input (used with |)\nwc          Count lines in piped input\nopen path   Open a file and get a file descriptor\nclose fd    Close a file descriptor\nreadfd fd   Read from a file descriptor\nwritefd fd  Write to a file descriptor\nseek fd pos Reposition a file descriptor's offset\nlsfd        List open file descriptors\nln          Create hard or symbolic links\nreadlink p  Read a symlink target\nstat path   Show file metadata (type, size, links)\njournal     Manage journaling (status, checkpoint, recover, crash)\nrwlock      Manage reader-writer locks (create, list)\npi          Priority inheritance (demo, status)\nordering    Resource ordering (register, status, mode, violations, demo)\nwaitjob id  Wait for a background job to complete\nshm         Shared memory (create, attach, detach, write, read, list, destroy, demo)\ndns         DNS operations (register, lookup, remove, list, flush, demo)\nsocket      Socket operations (create, bind, listen, connect, accept, send, recv, close, list)\nhttp        HTTP demo (end-to-end request/response over sockets)\ntcp         TCP connections (listen, connect, send, recv, close, info, list, demo)\nproc        /proc virtual filesystem demo\nperf        Show performance metrics\nstrace      Syscall tracing (on, off, show, clear, demo)\ndmesg       Show kernel boot log\ncpu         Show per-CPU status and scheduling info\ntaskset     Show or set CPU affinity for a process\nmmap        Memory-map a file\nmunmap      Unmap a memory-mapped region\nmsync       Sync a shared mapping\nslabcreate  Create a slab cache\nslaballoc   Allocate from a slab cache\nslabfree    Free a slab allocation\nslabinfo    Show slab allocator statistics\ntick [N]    Advance the system clock by N ticks (default 1)\ninterrupt   Manage interrupts (list, mask &lt;vector&gt;, unmask &lt;vector&gt;)\ntimer       Manage the timer (info, set &lt;interval&gt;)\nlearn       Interactive tutorials (processes, memory, filesystem, ...)\nexit        Shut down the kernel\n</code></pre> <p>Commands can be piped: <code>ls / | grep txt | wc</code></p>"},{"location":"#scripting","title":"Scripting","text":"<p>The shell supports scripts -- multi-line sequences of commands with comments, variable substitution, and conditionals:</p> <pre><code># Setup script\nmkdir /data\nexport NAME=hello\necho $NAME\nif ls /data\nthen\n  touch /data/$NAME.txt\nfi\n</code></pre> <p>Scripts can be run from files with <code>source /path/to/script.sh</code>.</p>"},{"location":"#web-ui","title":"Web UI","text":"<p>PyOS includes an optional browser-based terminal. Install Flask and start the server:</p> <pre><code>pip install py-os[web]\npy-os-web\n</code></pre> <p>Then open <code>http://localhost:8080</code> in your browser. See Web UI for details.</p>"},{"location":"#development","title":"Development","text":"<pre><code># Run tests with coverage\nuv run pytest --cov\n\n# Format code\nuv run ruff format src/ tests/\n\n# Lint and type check\nuv run ruff check src/ tests/\nuv run pyright src/\n\n# Pre-commit hooks (ruff, pyright, commitizen)\nuv run pre-commit run --all-files\n</code></pre> <p>Branch workflow: <code>feat/</code>, <code>fix/</code>, <code>chore/</code> prefixes, squash merges to protected <code>main</code>.</p> <p>TDD cycle: Write failing tests (Red) -&gt; Implement (Green) -&gt; Lint and refactor (Refactor).</p>"},{"location":"architecture/","title":"PyOS Architecture","text":"<p>Technical reference for every module in the system. For beginner-friendly explanations with analogies, see the concept guides.</p>"},{"location":"architecture/#design-principles","title":"Design Principles","text":"<ol> <li>Mirror real OS architecture -- every module corresponds to a real OS subsystem.</li> <li>TDD -- tests written first, then implementation, then refactoring.</li> <li>Syscalls as the boundary -- the shell never touches kernel internals directly.</li> <li>Returns strings, not prints -- everything is testable, no side effects.</li> <li>Simplicity over performance -- clarity wins in a learning simulator.</li> </ol>"},{"location":"architecture/#concept-guides","title":"Concept Guides","text":"Guide Topics What Is an OS? Big picture, layered architecture, how PyOS works Processes PCB, five-state model, scheduler, multi-CPU, fork (COW), threads, execution, zombies, wait/waitpid Memory Frames/pages, virtual memory, page replacement, swap, copy-on-write, mmap, slab allocator Filesystem Inodes, path resolution, hard/symbolic links, persistence, journaling, /proc virtual filesystem The Boot Chain Firmware POST, bootloader, kernel image, init process, dmesg Kernel and System Calls Boot sequence, lifecycle, syscall dispatch, number ranges The Shell Commands, pipes, redirection, loops, scripting, jobs, history, aliases, tab completion, env Devices and Networking Device protocol, IPC, disk scheduling, sockets, DNS, HTTP Interrupts and Timers Interrupt controller, vectors, masking, timer, preemption TCP: Reliable Delivery Three-way handshake, flow control, congestion control, retransmission Users and Safety Permissions, signals, logging, deadlock Synchronization Mutex, semaphore, condition variable, reader-writer lock, race conditions, deadlock prevention Interactive Tutorials Guided hands-on lessons using real syscalls Web UI Browser-based terminal via Flask"},{"location":"architecture/#module-map","title":"Module Map","text":"<p>Every source file and what it implements.</p>"},{"location":"architecture/#boot-layer","title":"Boot Layer","text":"File Class/Function Purpose <code>bootloader.py</code> <code>Bootloader</code> Simulated firmware + bootloader: POST, load kernel image, boot kernel <code>bootloader.py</code> <code>BootStage</code> FIRMWARE / BOOTLOADER / KERNEL / USERSPACE stage enum <code>bootloader.py</code> <code>PostResult</code> Frozen dataclass capturing POST check outcomes <code>bootloader.py</code> <code>KernelImage</code> Frozen dataclass representing the kernel binary on disk <code>bootloader.py</code> <code>BootError</code> Raised when the boot chain cannot continue"},{"location":"architecture/#kernel-layer","title":"Kernel Layer","text":"File Class/Function Purpose <code>kernel.py</code> <code>Kernel</code> Central coordinator, boot/shutdown lifecycle, subsystem ownership <code>kernel.py</code> <code>KernelState</code> SHUTDOWN / BOOTING / RUNNING / SHUTTING_DOWN state machine <code>kernel.py</code> <code>ExecutionMode</code> USER / KERNEL privilege level (enforced at property access) <code>kernel.py</code> <code>KernelModeError</code> Raised when user-mode code accesses a kernel-only resource <code>kernel.py</code> <code>kernel_mode()</code> Context manager that switches to kernel mode and restores on exit <code>kernel.py</code> <code>strace_enable()</code> / <code>strace_disable()</code> Enable/disable syscall tracing <code>kernel.py</code> <code>strace_log()</code> / <code>strace_clear()</code> Read/clear the strace trace log <code>kernel.py</code> <code>_sanitize_value()</code> Format values for strace display (truncation, callable/bytes placeholders) <code>syscalls.py</code> <code>dispatch_syscall()</code> Trap handler -- routes syscall numbers to kernel subsystem handlers <code>kernel.py</code> <code>dmesg()</code> Return the kernel boot log (like Linux dmesg) <code>kernel.py</code> <code>init_pid</code> PID of the init process (root of process tree) <code>syscalls.py</code> <code>SyscallNumber</code> IntEnum of all syscall numbers (1-247) <code>syscalls.py</code> <code>SyscallError</code> User-facing exception wrapping internal errors"},{"location":"architecture/#process-management","title":"Process Management","text":"File Class/Function Purpose <code>process/pcb.py</code> <code>Process</code> PCB with five-state model, program/output/exit_code, thread management, effective_priority for PI, performance timing (wait_time, cpu_time, response_time, turnaround_time) <code>process/pcb.py</code> <code>ProcessState</code> NEW / READY / RUNNING / WAITING / TERMINATED <code>process/scheduler.py</code> <code>Scheduler</code> Per-CPU ready queue management, dispatch using pluggable policy, context_switches counter <code>process/scheduler.py</code> <code>MultiCPUScheduler</code> Wraps N per-CPU Schedulers with load balancing, CPU affinity, migration <code>process/scheduler.py</code> <code>FCFSPolicy</code> First Come, First Served scheduling <code>process/scheduler.py</code> <code>RoundRobinPolicy</code> Time-sliced scheduling with configurable quantum <code>process/scheduler.py</code> <code>PriorityPolicy</code> Highest-priority-first scheduling with FIFO tiebreaker <code>process/scheduler.py</code> <code>AgingPriorityPolicy</code> Priority scheduling with aging to prevent starvation <code>process/scheduler.py</code> <code>MLFQPolicy</code> Multilevel Feedback Queue with demotion and boost <code>process/scheduler.py</code> <code>CFSPolicy</code> Completely Fair Scheduler with weighted virtual runtime <code>process/threads.py</code> <code>Thread</code> Lightweight execution unit within a process <code>process/signals.py</code> <code>Signal</code> SIGKILL / SIGUSR1 / SIGUSR2 / SIGTERM / SIGCONT / SIGSTOP <code>process/signals.py</code> <code>SignalAction</code> TERMINATE / STOP / CONTINUE / IGNORE default actions <code>process/signals.py</code> <code>DEFAULT_ACTIONS</code> Maps every signal to its default action <code>process/signals.py</code> <code>UNCATCHABLE</code> frozenset of signals that cannot have handlers (SIGKILL, SIGSTOP)"},{"location":"architecture/#memory-management","title":"Memory Management","text":"File Class/Function Purpose <code>memory/manager.py</code> <code>MemoryManager</code> Frame-based allocation with free set, page tables, and refcounting for COW <code>memory/virtual.py</code> <code>VirtualMemory</code> Per-process address space with page table translation and COW fault handling <code>memory/mmap.py</code> <code>MmapRegion</code> Frozen dataclass describing a memory-mapped file region <code>memory/mmap.py</code> <code>MmapError</code> Exception for mmap operation failures <code>memory/slab.py</code> <code>SlabAllocator</code> Registry of named slab caches backed by physical frames <code>memory/slab.py</code> <code>SlabCache</code> Pool of slabs for one fixed object size, auto-grows <code>memory/slab.py</code> <code>Slab</code> One physical frame divided into equal-sized object slots <code>memory/slab.py</code> <code>SlabError</code> Exception for slab operation failures <code>memory/swap.py</code> <code>SwapSpace</code> Key-value backing store for evicted pages <code>memory/swap.py</code> <code>FIFOPolicy</code> / <code>LRUPolicy</code> / <code>ClockPolicy</code> Page replacement strategies <code>memory/swap.py</code> <code>Pager</code> Demand paging orchestrator (page faults, eviction, swap I/O)"},{"location":"architecture/#filesystem","title":"Filesystem","text":"File Class/Function Purpose <code>fs/filesystem.py</code> <code>FileSystem</code> Inode-based filesystem with path resolution, links, CRUD, and offset-based I/O <code>fs/filesystem.py</code> <code>_Inode</code> Internal metadata record (type, size, data, children, link_count) <code>fs/filesystem.py</code> <code>FileType</code> FILE / DIRECTORY / SYMLINK <code>fs/filesystem.py</code> <code>MAX_SYMLINK_DEPTH</code> Loop detection limit (40, matching Linux SYMLOOP_MAX) <code>fs/fd.py</code> <code>FdTable</code> Per-process table mapping fd numbers (&gt;= 3) to open file descriptions <code>fs/fd.py</code> <code>OpenFileDescription</code> Track an open file's path, mode, and current byte offset <code>fs/fd.py</code> <code>FileMode</code> READ / WRITE / READ_WRITE access modes <code>fs/fd.py</code> <code>SeekWhence</code> SET / CUR / END seek directions <code>fs/fd.py</code> <code>FdError</code> Exception for file descriptor operation failures <code>fs/journal.py</code> <code>JournaledFileSystem</code> Composition wrapper adding WAL logging to every filesystem mutation <code>fs/journal.py</code> <code>Journal</code> Write-ahead log managing transactions (begin/append/commit/abort) <code>fs/journal.py</code> <code>JournalOp</code> CREATE_FILE / CREATE_DIR / WRITE / WRITE_AT / DELETE / LINK / SYMLINK <code>fs/journal.py</code> <code>TransactionState</code> ACTIVE / COMMITTED / ABORTED <code>fs/journal.py</code> <code>JournalEntry</code> Single logged operation within a transaction <code>fs/journal.py</code> <code>Transaction</code> Atomic unit grouping journal entries <code>fs/persistence.py</code> <code>dump_filesystem()</code> Serialize filesystem to JSON <code>fs/persistence.py</code> <code>load_filesystem()</code> Deserialize filesystem from JSON <code>fs/persistence.py</code> <code>dump_journaled_filesystem()</code> Serialize journaled filesystem (fs + journal + checkpoint) to JSON <code>fs/persistence.py</code> <code>load_journaled_filesystem()</code> Deserialize journaled filesystem from JSON <code>fs/procfs.py</code> <code>ProcFilesystem</code> Virtual /proc filesystem generating content from live kernel state <code>fs/procfs.py</code> <code>ProcError</code> Exception for /proc operation failures"},{"location":"architecture/#user-space","title":"User Space","text":"File Class/Function Purpose <code>shell.py</code> <code>Shell</code> Command interpreter with pipes, redirection (<code>&gt;</code>, <code>&gt;&gt;</code>, <code>&lt;</code>, <code>2&gt;</code>), scripting (if/else, while/for loops), job control, background execution (<code>&amp;</code>) <code>shell.py</code> <code>_Redirections</code> Parsed I/O redirection operators from a command string <code>completer.py</code> <code>Completer</code> Context-aware tab completion for commands, subcommands, paths, programs, env vars, signals <code>users.py</code> <code>UserManager</code> User registry with auto-incrementing UIDs <code>users.py</code> <code>FilePermissions</code> Per-file owner/other read/write permission bits <code>env.py</code> <code>Environment</code> KEY=VALUE store with copy semantics <code>jobs.py</code> <code>JobManager</code> Background/foreground job tracking with output capture"},{"location":"architecture/#io-and-networking","title":"I/O and Networking","text":"File Class/Function Purpose <code>io/devices.py</code> <code>DeviceManager</code> Device registry with uniform read/write protocol <code>io/devices.py</code> <code>NullDevice</code> / <code>ConsoleDevice</code> / <code>RandomDevice</code> Built-in devices <code>io/ipc.py</code> <code>Pipe</code> Byte-stream channel (FIFO) <code>io/ipc.py</code> <code>MessageQueue</code> Typed generic message queue <code>io/disk.py</code> <code>DiskScheduler</code> Request queue with pluggable scheduling policy <code>io/disk.py</code> <code>FCFSPolicy</code> / <code>SSTFPolicy</code> / <code>SCANPolicy</code> / <code>CSCANPolicy</code> Disk I/O scheduling strategies <code>io/shm.py</code> <code>SharedMemorySegment</code> Named shared memory region (dataclass with frames, storage, attachments) <code>io/shm.py</code> <code>SharedMemoryError</code> Exception for shared memory operation failures <code>io/dns.py</code> <code>DnsResolver</code> Local phone book \u2014 register, look up, remove, list, flush hostname records <code>io/dns.py</code> <code>DnsRecord</code> Frozen dataclass \u2014 one hostname-to-IP (A record) mapping <code>io/dns.py</code> <code>DnsError</code> Exception for DNS operation failures <code>io/networking.py</code> <code>SocketManager</code> Socket lifecycle, connection routing, data buffers <code>io/networking.py</code> <code>Socket</code> / <code>SocketState</code> Endpoint with CREATED/BOUND/LISTENING/CONNECTED/CLOSED states <code>io/networking.py</code> <code>SocketError</code> Exception for socket operation failures <code>io/http.py</code> <code>HttpMethod</code> GET / POST request methods (StrEnum) <code>io/http.py</code> <code>HttpStatus</code> 200 OK / 400 / 404 / 500 status codes (IntEnum) <code>io/http.py</code> <code>HttpRequest</code> / <code>HttpResponse</code> Frozen dataclasses for HTTP messages <code>io/http.py</code> <code>HttpError</code> Exception for HTTP operation failures <code>io/http.py</code> <code>format_request()</code> / <code>parse_request()</code> Serialize/deserialize HTTP requests <code>io/http.py</code> <code>format_response()</code> / <code>parse_response()</code> Serialize/deserialize HTTP responses <code>io/interrupts.py</code> <code>InterruptController</code> Manage interrupt vectors, handlers, and pending IRQs with priority-based servicing <code>io/interrupts.py</code> <code>InterruptType</code> TIMER / IO / SOFTWARE interrupt categories (StrEnum) <code>io/interrupts.py</code> <code>InterruptPriority</code> LOW / NORMAL / HIGH / CRITICAL priority levels (IntEnum) <code>io/interrupts.py</code> <code>InterruptVector</code> Frozen dataclass describing a registered vector (number, type, priority) <code>io/interrupts.py</code> <code>InterruptRequest</code> Frozen dataclass for a queued IRQ (vector, type, priority, data, timestamp) <code>io/interrupts.py</code> <code>VECTOR_TIMER</code> / <code>VECTOR_IO_BASE</code> Well-known vector numbers (0 and 16) <code>io/timer.py</code> <code>TimerDevice</code> Programmable interval timer \u2014 fires VECTOR_TIMER interrupt every N ticks <code>io/tcp.py</code> <code>TcpState</code> 11-state TCP connection state machine (StrEnum) <code>io/tcp.py</code> <code>TcpFlag</code> SYN / ACK / FIN / RST segment flags (StrEnum) <code>io/tcp.py</code> <code>TcpSegment</code> Frozen dataclass for a TCP segment (ports, seq/ack numbers, flags, window, payload) <code>io/tcp.py</code> <code>TcpConnection</code> One endpoint: state machine, seq tracking, flow control, congestion control (slow start + AIMD), retransmission <code>io/tcp.py</code> <code>TcpStack</code> Manage multiple TCP connections, listener queues, segment routing, retransmission ticks"},{"location":"architecture/#synchronization","title":"Synchronization","text":"File Class/Function Purpose <code>sync/inheritance.py</code> <code>PriorityInheritanceManager</code> Coordinate priority inheritance across mutexes, prevent priority inversion <code>sync/primitives.py</code> <code>Mutex</code> Mutual exclusion lock with owner tracking, FIFO wait queue, and <code>waiters</code> property <code>sync/primitives.py</code> <code>Semaphore</code> Counting semaphore with optional max bound <code>sync/primitives.py</code> <code>Condition</code> Condition variable (wait/notify) paired with a mutex <code>sync/primitives.py</code> <code>ReadWriteLock</code> Reader-writer lock with writer-preference and batch reader wake <code>sync/primitives.py</code> <code>SyncManager</code> Registry for all sync primitives (mutexes, semaphores, conditions, rwlocks) <code>sync/ordering.py</code> <code>OrderingMode</code> STRICT / WARN / OFF enforcement modes for resource ordering <code>sync/ordering.py</code> <code>OrderingViolation</code> Frozen dataclass recording a single ordering violation <code>sync/ordering.py</code> <code>ResourceOrderingManager</code> Enforce resource acquisition ordering to prevent circular wait (deadlock prevention)"},{"location":"architecture/#observability","title":"Observability","text":"File Class/Function Purpose <code>logging.py</code> <code>Logger</code> Ring buffer of structured log entries <code>logging.py</code> <code>LogLevel</code> DEBUG / INFO / WARNING / ERROR (IntEnum) <code>sync/deadlock.py</code> <code>ResourceManager</code> Banker's algorithm matrices, deadlock detection <code>repl.py</code> <code>run()</code> Interactive terminal with bootloader chain and dynamic boot banner <code>repl.py</code> <code>format_boot_log()</code> Format boot log messages into a displayable banner"},{"location":"architecture/#tutorials","title":"Tutorials","text":"File Class/Function Purpose <code>tutorials.py</code> <code>TutorialRunner</code> Guided, hands-on lessons that use real syscalls with educational commentary <code>tutorials.py</code> <code>list_lessons()</code> Return sorted list of available lesson names <code>tutorials.py</code> <code>run(name)</code> Execute a single lesson by name <code>tutorials.py</code> <code>run_all()</code> Execute every lesson in recommended order"},{"location":"architecture/#web-frontend","title":"Web Frontend","text":"File Class/Function Purpose <code>web/app.py</code> <code>create_app()</code> Flask application factory \u2014 boots kernel, creates shell, wires routes <code>web/app.py</code> <code>main()</code> Console entry point for <code>py-os-web</code> development server <code>web/templates/index.html</code> \u2014 Single-page terminal UI with dark theme <code>web/static/style.css</code> \u2014 Dark terminal aesthetic (green on dark blue) <code>web/static/terminal.js</code> \u2014 Command input, history (Up/Down), fetch API calls"},{"location":"architecture/#syscall-number-ranges","title":"Syscall Number Ranges","text":"Range Category 1-8 Process operations (create, terminate, list, fork, threads, wait, waitpid) 10-19 Filesystem operations (create, read, write, delete, list, open, close, read_fd, write_fd) 20 Memory info 21-23 Memory-mapped files (mmap, munmap, msync) 24-27 Slab allocator (create cache, alloc, free, info) 28 File descriptor seek 34-36 Link operations (link, symlink, readlink) 30-33 User operations (whoami, create, list, switch) 40-42 Device operations (read, write, list) 50 Logging 60-61 Signal operations (send, register handler) 70-73 Environment variables 80 System info 90 Deadlock detection 91-93 Deadlock prevention (resource ordering) 100-101 Process execution (exec, run) 110-119, 122-125 Synchronization (mutex, semaphore, condition, reader-writer lock) 120-121 Scheduler operations (policy switching, MLFQ boost) 130-133 Journal operations (status, checkpoint, recover, crash) 140-146 Shared memory IPC (create, attach, detach, destroy, write, read, list) 150-154 DNS operations (register, lookup, remove, list, flush) 160-168 Socket operations (create, bind, listen, connect, accept, send, recv, close, list) 170-171 /proc virtual filesystem (read, list) 172 Performance metrics (read) 180-183 Strace operations (enable, disable, log, clear) 190-203 Kernel-mode helpers (shutdown, scheduler info, lstat, sync listing, fd listing, resource listing, PI status, ordering violations, destroy mutex, dispatch, process info, strace status) 210-211 Boot info (dmesg boot log, boot metadata) 220-224 Multi-CPU operations (cpu info, set/get affinity, balance, migrate) 230-235 Interrupt and timer operations (tick, interrupt list/mask/unmask, timer info/set interval) 240-247 TCP operations (connect, send, recv, close, info, list, listen, accept)"},{"location":"architecture/#strategy-pattern-usage","title":"Strategy Pattern Usage","text":"<p>The Strategy pattern appears in three subsystems, always with the same structure: a mechanism (the manager class) delegates to a policy (a swappable protocol implementation).</p> Subsystem Mechanism Policies CPU Scheduling <code>Scheduler</code> <code>FCFSPolicy</code>, <code>RoundRobinPolicy</code>, <code>PriorityPolicy</code>, <code>AgingPriorityPolicy</code>, <code>MLFQPolicy</code>, <code>CFSPolicy</code> Page Replacement <code>Pager</code> <code>FIFOPolicy</code>, <code>LRUPolicy</code>, <code>ClockPolicy</code> Disk Scheduling <code>DiskScheduler</code> <code>FCFSPolicy</code>, <code>SSTFPolicy</code>, <code>SCANPolicy</code>, <code>CSCANPolicy</code>"},{"location":"concepts/bootloader/","title":"The Boot Chain","text":"<p>When you press the power button on a real computer, quite a lot happens before you see a login screen. This page explains the journey from \"power on\" to \"ready to use.\"</p>"},{"location":"concepts/bootloader/#1-the-power-button-analogy","title":"1. The Power Button Analogy","text":"<p>Imagine you're opening a school building in the morning. You can't just throw the doors open and hope for the best. There's a whole sequence:</p> <ol> <li>Security guard checks the building -- lights work? Water running? Doors    not broken? This is the firmware POST (Power-On Self-Test).</li> <li>Janitor fetches today's plan -- they go to the supply closet (the disk)    and pull out a file called \"Today's School Plan.\" This is the bootloader    loading the kernel image.</li> <li>Principal sets up departments -- using the plan, the principal    (the kernel) sets up each department one by one: memory, files, users,    devices, scheduler. This is the kernel boot.</li> <li>Vice principal opens the front desk -- students can now check in. This    is the init process starting the shell so you can type commands.</li> </ol> <p>In a real computer, the chain looks like this:</p> <pre><code>Power on\n   |\n   v\nFirmware POST     -- \"Is the hardware OK?\"\n   |\n   v\nBootloader        -- \"Find and load the kernel from disk\"\n   |\n   v\nKernel boot       -- \"Set up all subsystems\"\n   |\n   v\nInit (PID 1)      -- \"Start the first user-facing process\"\n   |\n   v\nShell prompt      -- \"Ready for your commands!\"\n</code></pre>"},{"location":"concepts/bootloader/#2-firmware-post","title":"2. Firmware POST","text":"<p>POST stands for Power-On Self-Test. Before doing anything else, the computer's firmware (a tiny program baked into the motherboard) checks that the essential hardware is working:</p> <ul> <li>Memory -- are there enough memory frames available?</li> <li>Disk -- can we read from the storage device?</li> <li>Devices -- are basic devices responding?</li> </ul> <p>If any check fails, the computer cannot boot. On real machines, you might hear a series of beeps or see an error code. In PyOS, a <code>BootError</code> is raised with a message explaining what went wrong.</p> <p>In PyOS, you can see the POST results in the boot log:</p> <pre><code>[POST] Memory: 64 frames ... OK\n[POST] Disk: accessible ... OK\n[POST] Devices: ready ... OK\n</code></pre>"},{"location":"concepts/bootloader/#3-the-bootloader","title":"3. The Bootloader","text":"<p>Once POST passes, the bootloader takes over. Its job is simple but critical: find the kernel on disk and load it into memory.</p> <p>On a real PC, the bootloader (like GRUB or systemd-boot) reads a file called something like <code>/boot/vmlinuz</code> from the hard drive. This file is the kernel image -- the compiled kernel binary plus its configuration.</p> <p>In PyOS, the <code>Bootloader</code> class does the same thing. It can load a kernel image from a JSON file on disk, or use sensible defaults. The kernel image contains:</p> <ul> <li>version -- which version of the kernel to boot (e.g. \"0.1.0\")</li> <li>total_frames -- how much memory the kernel should manage</li> <li>num_cpus -- how many CPUs the kernel should use (default 1)</li> <li>default_policy -- which scheduling policy to start with</li> <li>boot_args -- extra configuration settings</li> </ul> <pre><code>[BOOT] Loading kernel image v0.1.0 ... OK\n</code></pre>"},{"location":"concepts/bootloader/#4-kernel-boot","title":"4. Kernel Boot","text":"<p>With the kernel image loaded, the kernel itself takes over. It initializes every subsystem in a specific order (because each one depends on the ones before it):</p> <pre><code>[OK] Logger\n[OK] Memory manager (64 frames)\n[OK] Slab allocator\n[OK] File system (journaled)\n[OK] User manager\n[OK] Environment\n[OK] Device manager\n[OK] DNS resolver\n[OK] Network stack\n[OK] Sync primitives\n[OK] Scheduler (FCFS)\n[OK] /proc filesystem\n[OK] Init process (PID ...)\n</code></pre> <p>This is exactly what we covered in the Kernel and System Calls page -- the boot sequence hasn't changed, we've just made it visible through the boot log.</p>"},{"location":"concepts/bootloader/#5-the-init-process","title":"5. The Init Process","text":"<p>At the very end of the kernel boot, something special happens: the kernel creates a process called init. This is the first process in the system, and every other process is a child (or grandchild, or great-grandchild) of init.</p> <p>In real Unix/Linux: - init always gets PID 1 - It is the root of the process tree - If a process's parent dies, init \"adopts\" the orphaned children - init is the last process to stop during shutdown</p> <p>In PyOS, the kernel creates init the same way:</p> <pre><code>init = Process(name=\"init\", priority=0)\ninit.admit()\nscheduler.add(init)\n</code></pre> <p>Notice that init doesn't allocate memory -- it's a lightweight sentinel that just represents the root of the process tree. When you create a new process with <code>create_process()</code>, it automatically becomes a child of init (unless you specify a different parent). This means <code>pstree</code> always shows init at the top.</p>"},{"location":"concepts/bootloader/#6-the-dmesg-command","title":"6. The dmesg Command","text":"<p>In Linux, the <code>dmesg</code> command shows the kernel's boot messages. It's like reading the school's morning checklist after everything is already open -- you can see exactly what happened during startup.</p> <p>PyOS has the same command:</p> <pre><code>$ dmesg\n[OK] Logger\n[OK] Memory manager (64 frames)\n[OK] Slab allocator\n[OK] File system (journaled)\n...\n</code></pre> <p>Behind the scenes, <code>dmesg</code> uses the <code>SYS_DMESG</code> syscall (number 210) to fetch the boot log from the kernel.</p> <p>There's also <code>SYS_BOOT_INFO</code> (number 211) that returns metadata about the boot: the init process PID, system uptime, and kernel version.</p>"},{"location":"concepts/bootloader/#7-the-boot-chain-in-pyos-code","title":"7. The Boot Chain in PyOS Code","text":"<p>Here's how the REPL brings everything together:</p> <pre><code>bootloader = Bootloader()\nkernel = bootloader.boot()    # POST -&gt; load image -&gt; kernel.boot()\nshell = Shell(kernel=kernel)\nprint(format_boot_log(bootloader.boot_log + kernel.dmesg()))\n</code></pre> <p>The <code>Bootloader.boot()</code> method runs through all four stages:</p> <ol> <li>FIRMWARE -- run POST, check hardware</li> <li>BOOTLOADER -- load the kernel image</li> <li>KERNEL -- create a <code>Kernel</code> and call <code>boot()</code></li> <li>USERSPACE -- return the running kernel</li> </ol> <p>You can track which stage the bootloader is in via its <code>stage</code> property, which returns a <code>BootStage</code> enum value.</p>"},{"location":"concepts/bootloader/#where-to-go-next","title":"Where to Go Next","text":"<ul> <li>Kernel and System Calls -- What happens after boot</li> <li>Processes -- How the OS runs programs (starting from init)</li> <li>What Is an Operating System? -- The big picture</li> </ul>"},{"location":"concepts/devices-and-networking/","title":"Devices and Networking: How the OS Talks to Hardware and the World","text":"<p>Your computer is surrounded by stuff -- a screen, a keyboard, a printer, a Wi-Fi card. And your programs constantly want to talk to these things: \"print this document,\" \"show this pixel,\" \"send this message across the internet.\"</p> <p>But every device is different on the inside. A printer doesn't work anything like a keyboard, and neither of them works like a Wi-Fi card. Somebody has to translate between your programs and all this varied hardware.</p> <p>That somebody is the OS.</p> <p>In PyOS, this area is split across four files. Let's walk through each one.</p>"},{"location":"concepts/devices-and-networking/#1-devices-iodevicespy","title":"1. Devices (<code>io/devices.py</code>)","text":""},{"location":"concepts/devices-and-networking/#the-school-supplies-analogy","title":"The School Supplies Analogy","text":"<p>Imagine a school that provides tools for students: printers, projectors, whiteboards. They all work completely differently on the inside. A printer has ink cartridges and rollers. A projector has a lamp and a lens. A whiteboard is just... a board.</p> <p>But the school doesn't make you learn how each tool works internally. Instead, it gives you the same simple instructions for every tool: \"read from it\" or \"write to it.\" Want the projector to show something? Write to it. Want to see what's on the whiteboard? Read from it. Same instructions, every time.</p> <p>In computing, this idea is called a uniform interface (or a protocol). Every device supports the same basic operations -- <code>name</code>, <code>status</code>, <code>read()</code>, and <code>write()</code> -- even though the devices themselves do wildly different things. Your program doesn't need to know how a printer works to use it. It just calls <code>write()</code> and the device handles the rest.</p> <p>In PyOS, the <code>Device</code> protocol defines these four operations. Any Python class that has a <code>name</code>, a <code>status</code>, a <code>read()</code> method, and a <code>write()</code> method counts as a valid device. This is Python's duck typing at work -- if it walks like a device and quacks like a device, it is a device.</p>"},{"location":"concepts/devices-and-networking/#three-built-in-devices","title":"Three Built-In Devices","text":""},{"location":"concepts/devices-and-networking/#nulldevice-devnull-the-trash-can","title":"NullDevice (<code>/dev/null</code>) -- The Trash Can","text":"<p>Think of a trash can. You can throw anything in it -- paper, wrappers, old homework. It all disappears. If you try to pull something out of the trash can, you get nothing.</p> <p>That's exactly what <code>NullDevice</code> does. You can write any data to it, and the data is silently discarded. If you try to read from it, you get back empty bytes. It's always ready and it never fails.</p> <p>Why would you want a device that throws everything away? It's surprisingly useful. Sometimes a program produces output you don't care about -- log messages, status updates, debug information. Instead of building a special \"ignore this output\" feature into every program, you just point the output at <code>/dev/null</code> and it vanishes. Simple.</p>"},{"location":"concepts/devices-and-networking/#consoledevice-the-whiteboard","title":"ConsoleDevice -- The Whiteboard","text":"<p>Think of a classroom whiteboard. A teacher writes a message on it, and later a student reads it. If the teacher writes three messages, the student reads them in the same order they were written. First message in, first message out.</p> <p>This ordering is called FIFO -- \"first in, first out.\" It's the same idea as a queue at a lunch counter. Whoever gets in line first gets served first.</p> <p>The <code>ConsoleDevice</code> works the same way. You write data to it, and the data goes into a buffer (a waiting area). When someone reads from it, they get the oldest piece of data first. In a real OS, the console device would be backed by actual screen hardware, but in PyOS we simulate it with a Python <code>deque</code> (a double-ended queue).</p>"},{"location":"concepts/devices-and-networking/#randomdevice-devrandom-the-magic-8-ball","title":"RandomDevice (<code>/dev/random</code>) -- The Magic 8-Ball","text":"<p>You know those Magic 8-Balls where you shake it and get a random answer every time? That's <code>/dev/random</code>. Every time you read from it, you get back random bytes -- a different answer each time.</p> <p>Unlike the other devices, this one is read-only. You can't write to it. If you try, it raises an <code>OSError</code>. This makes sense -- you don't tell a random number generator what to produce. You just ask it for bytes and it gives you whatever it comes up with. Under the hood, PyOS uses Python's <code>os.urandom()</code> to generate cryptographically random bytes.</p>"},{"location":"concepts/devices-and-networking/#the-device-manager","title":"The Device Manager","text":"<p>In a real OS, there's a directory called <code>/dev</code> that lists all the devices available on the system. PyOS has something similar: the <code>DeviceManager</code>. It's a registry -- a lookup table -- where devices are registered by name. You can add a new device, look one up by name, or list all the devices that are currently registered.</p> <p>If you try to register two devices with the same name, the manager raises a <code>ValueError</code>. Just like you can't have two files with the same name in the same folder.</p>"},{"location":"concepts/devices-and-networking/#2-ipc-inter-process-communication-ioipcpy","title":"2. IPC -- Inter-Process Communication (<code>io/ipc.py</code>)","text":"<p>Processes are isolated by design -- each one lives in its own little world with its own memory, and it can't peek at what other processes are doing. That's great for safety, but it creates a problem: what if two processes need to share information?</p> <p>That's where IPC comes in. IPC stands for \"inter-process communication,\" which is a fancy way of saying \"how processes talk to each other.\"</p> <p>PyOS provides three IPC mechanisms. Think of them as three different ways students in a school can pass information without talking out loud.</p>"},{"location":"concepts/devices-and-networking/#pipes-the-tin-can-telephone","title":"Pipes -- The Tin-Can Telephone","text":"<p>Remember those toy telephones made from two tin cans connected by a string? One kid talks into one can, and the other kid listens at the other end. The sound travels in one direction through the string.</p> <p>A pipe works just like that. One process writes bytes into one end of the pipe, and another process reads bytes out of the other end. The data flows in one direction, and it comes out in the same order it went in (FIFO again).</p> <p>Here's what you can do with a pipe:</p> <ul> <li>Write -- push bytes into the pipe. If the pipe has been closed, you get a   <code>BrokenPipeError</code> (like trying to talk into a tin can when someone has cut the   string).</li> <li>Read -- pull the next chunk of bytes out. If the pipe is empty, you get   <code>None</code>.</li> <li>Close -- shut the pipe for writing. Data already inside can still be read   (drained), but no new data goes in.</li> </ul> <p>Pipes are great for simple, streaming communication. If you've ever used the <code>|</code> symbol in a command line (like <code>ls | grep \".py\"</code>), you've used a pipe. The output of one command flows directly into the input of the next.</p>"},{"location":"concepts/devices-and-networking/#message-queues-the-mailbox","title":"Message Queues -- The Mailbox","text":"<p>Now imagine a mailbox mounted on the wall. Anyone can walk up and drop a message in. Anyone else can open the mailbox and take the next message out. Messages come out in the order they were put in (FIFO, once again).</p> <p>A message queue is exactly that. But it has two advantages over a pipe:</p> <ol> <li> <p>Messages stay whole. With a pipe, you're sending raw bytes -- just a    stream of data with no boundaries. With a message queue, each message is a    separate, complete unit. You put in \"meeting at 3pm\" and you get back    \"meeting at 3pm\" -- not \"meet\" and then \"ing at 3pm.\"</p> </li> <li> <p>Type safety. In PyOS, message queues are generic -- you can create    a <code>MessageQueue[str]</code> that only accepts and returns strings, or a    <code>MessageQueue[int]</code> that only works with integers. Python checks the types    for you so you don't accidentally put the wrong kind of data into the queue.</p> </li> </ol> <p>Message queues are also named. You give the queue a name when you create it (like \"print_jobs\" or \"notifications\"), and any process that knows the name can find it and send or receive messages. This is great for many-to-many communication -- multiple processes can all send to the same queue, and multiple processes can all read from it.</p>"},{"location":"concepts/devices-and-networking/#shared-memory-the-shared-whiteboard","title":"Shared Memory -- The Shared Whiteboard","text":"<p>Pipes and message queues are great, but they both involve copying data. The sender writes data into the pipe or queue, and the receiver reads its own copy out. For small messages that's fine, but what if two processes need to share a huge chunk of data -- like a big spreadsheet or a video frame? Copying all that data back and forth would be slow.</p> <p>Shared memory solves this by giving multiple processes access to the same chunk of memory. No copying at all.</p> <p>Think of a whiteboard in the school hallway. Any student can walk up and write on it, and every other student can see what's there instantly. Nobody has to copy anything -- they're all looking at the same board. That's shared memory.</p> <p>Here's how it works in PyOS:</p> <ol> <li> <p>Create -- a process asks the kernel to set up a named whiteboard (a    shared memory segment) of a certain size. The kernel allocates physical    memory frames to back it, just like it does for virtual memory.    The name is like a label on the whiteboard (\"project-data\" or \"scoreboard\").</p> </li> <li> <p>Attach -- any process that knows the name can attach to the segment.    The kernel maps the segment's frames into that process's virtual address    space so it can read and write directly. Multiple processes can attach at    the same time.</p> </li> <li> <p>Read / Write -- attached processes read and write bytes directly.    Because everyone is looking at the same underlying memory, a write by one    process is instantly visible to all others. Zero copying.</p> </li> <li> <p>Detach -- when a process is done, it detaches. The kernel unmaps the    frames from that process's address space, but the whiteboard stays up for    anyone else still using it.</p> </li> <li> <p>Destroy -- when nobody needs the whiteboard anymore, any process can    ask the kernel to destroy it. If processes are still attached, the kernel    marks it \"for deletion\" and waits. Once the last process detaches, the    memory is freed.</p> </li> </ol>"},{"location":"concepts/devices-and-networking/#the-synchronization-problem","title":"The Synchronization Problem","text":"<p>Here's the catch. Shared memory is the fastest IPC mechanism -- but it's also the most dangerous if you're not careful.</p> <p>Imagine two students try to write on the whiteboard at the exact same time. One writes \"Meeting at 3\" and the other writes \"Pizza party.\" You might end up with \"MePizzting party at 3\" -- a garbled mess. This is called a race condition.</p> <p>To prevent this, processes need a way to take turns. That's where synchronization primitives come in -- mutexes, semaphores, and reader-writer locks can all coordinate access to shared memory. Think of it like a \"WRITING -- DO NOT ERASE\" sign that a student puts on the whiteboard while they're using it.</p> <p>Real operating systems face this exact same challenge. Shared memory gives you speed, but you have to be disciplined about synchronization. That's the trade-off.</p>"},{"location":"concepts/devices-and-networking/#pipes-vs-message-queues-vs-shared-memory-when-to-use-which","title":"Pipes vs. Message Queues vs. Shared Memory -- When to Use Which?","text":"<ul> <li>Use a pipe when you have a simple producer-consumer setup: one process   generates a stream of bytes, and another consumes it. Think \"command output.\"</li> <li>Use a message queue when you need structured, discrete messages and   possibly many senders or receivers. Think \"task assignments\" or \"event   notifications.\"</li> <li>Use shared memory when you need fast, random-access, bidirectional data   sharing between processes. Think \"shared spreadsheet\" or \"game state.\" Just   remember to add synchronization.</li> </ul>"},{"location":"concepts/devices-and-networking/#3-disk-scheduling-iodiskpy","title":"3. Disk Scheduling (<code>io/disk.py</code>)","text":""},{"location":"concepts/devices-and-networking/#the-elevator-analogy","title":"The Elevator Analogy","text":"<p>Picture a really tall building with 200 floors. There's one elevator, and it moves up and down to pick people up. Lots of people are pressing buttons on different floors at the same time, and the elevator has to decide: which floor do I go to next?</p> <p>A hard drive works the same way. It has a read head (the elevator) that moves across the surface of the disk to different positions called cylinders (the floors). When several processes want to read or write data at the same time, the OS has to decide which order to visit those positions. The time it takes the head to move from one position to another is called seek time, and it's the slowest part of the whole operation. So choosing a good order really matters.</p> <p>PyOS implements four strategies, and they're all named after how the elevator could behave.</p>"},{"location":"concepts/devices-and-networking/#fcfs-first-come-first-served","title":"FCFS -- First Come, First Served","text":"<p>The simplest rule: visit floors in the order people pressed the button.</p> <p>If someone on floor 98 pressed first, then floor 3, then floor 175, then floor 14, the elevator goes: 98, 3, 175, 14. It zigzags all over the building like crazy.</p> <p>This is perfectly fair -- nobody gets skipped. But the total distance the elevator travels is huge because it never plans ahead. It just blindly follows the order of the requests.</p>"},{"location":"concepts/devices-and-networking/#sstf-shortest-seek-time-first","title":"SSTF -- Shortest Seek Time First","text":"<p>A greedier rule: always go to the nearest floor.</p> <p>If the elevator is on floor 53 and the requests are at floors 98, 3, 175, and 14, it would go to 14 first (closest), then 3, then 98, then 175. Much less zigzagging.</p> <p>The problem? Starvation. Imagine the elevator is near floor 50, and people keep pressing buttons near floor 50. Someone on floor 199 might wait forever because there's always a closer request. It's fast in the short term but potentially unfair.</p>"},{"location":"concepts/devices-and-networking/#scan-the-elevator-algorithm","title":"SCAN -- The Elevator Algorithm","text":"<p>This is actually how most real elevators work. The elevator picks a direction -- say, up -- and goes all the way up, picking up everyone along the way. When it reaches the top, it reverses and goes all the way down, picking up everyone on the way down.</p> <p>Nobody waits more than two full trips (one up, one down). There's no starvation -- everyone gets served eventually. The total distance traveled is much better than FCFS because the elevator moves in a predictable sweep instead of zigzagging randomly.</p>"},{"location":"concepts/devices-and-networking/#c-scan-circular-scan","title":"C-SCAN -- Circular SCAN","text":"<p>C-SCAN is a variation of SCAN with one twist: the elevator only picks people up in one direction. It goes all the way up, and when it hits the top, instead of turning around, it jumps straight back to the bottom and goes up again. It never services requests on the way down.</p> <p>Why? With regular SCAN, floors near the middle of the building get visited twice per cycle (once going up, once going down), while floors at the very top or bottom only get visited once. C-SCAN fixes this unfairness by treating the disk like a circle -- after the top, wrap around to the bottom. Everyone gets roughly the same wait time.</p>"},{"location":"concepts/devices-and-networking/#the-classic-textbook-example","title":"The Classic Textbook Example","text":"<p>OS textbooks love this example. Imagine 8 requests at positions 98, 183, 37, 122, 14, 124, 65, and 67, with the read head starting at position 53.</p> <p>Using FCFS, the head visits them in arrival order and travels a total of 640 positions -- zigzagging wildly back and forth. Using SCAN, the head sweeps in one direction and then the other, covering far fewer positions overall. The difference is dramatic, and it shows why disk scheduling matters.</p>"},{"location":"concepts/devices-and-networking/#the-diskscheduler","title":"The DiskScheduler","text":"<p>PyOS wraps these policies in a <code>DiskScheduler</code> object. You give it a policy (FCFS, SSTF, SCAN, or C-SCAN) and a starting head position, then add requests to its queue. When you call <code>run()</code>, it uses the policy to determine the service order, moves the head to the last position serviced, and clears the queue. You can even swap policies at runtime -- this is an example of the Strategy pattern, where you can change an object's behaviour by plugging in a different strategy.</p>"},{"location":"concepts/devices-and-networking/#4-networking-ionetworkingpy","title":"4. Networking (<code>io/networking.py</code>)","text":""},{"location":"concepts/devices-and-networking/#the-phone-call-analogy","title":"The Phone Call Analogy","text":"<p>Think of sockets as phone calls between two buildings.</p> <p>Building A is a pizza shop (the server). Building B is a hungry customer (the client). Here's how the call works:</p> <p>The server (pizza shop) side:</p> <ol> <li>Get a phone -- create a socket. At this point you have a phone, but it    doesn't have a number yet.</li> <li>Assign a phone number -- bind the socket to an address and a port. The    address is like the area code (\"localhost\"), and the port is the specific    phone number (like 8080). Now people can reach you.</li> <li>Start answering calls -- call <code>listen()</code>. You're sitting by the phone,    ready for customers to call.</li> <li>Pick up when someone calls -- call <code>accept()</code>. This gives you a direct    line to that specific customer.</li> <li>Talk -- use <code>send()</code> and <code>recv()</code> to exchange data back and forth.</li> </ol> <p>The client (customer) side:</p> <ol> <li>Get a phone -- create a socket.</li> <li>Dial the pizza shop's number -- call <code>connect()</code> with the server's    address and port. If nobody's listening at that number, you get a    <code>ConnectionError</code> (\"connection refused\" -- nobody picked up).</li> <li>Talk -- use <code>send()</code> and <code>recv()</code> to place your order and hear back.</li> </ol>"},{"location":"concepts/devices-and-networking/#socket-states","title":"Socket States","text":"<p>A socket goes through a series of states during its life, like chapters in a phone call:</p> <ul> <li>CREATED -- you have a phone, but no number assigned. You can't call   anyone yet and nobody can call you.</li> <li>BOUND -- you've been assigned a phone number (address + port). You exist   in the phone book now.</li> <li>LISTENING -- you're sitting by the phone, waiting for incoming calls.   Only servers do this.</li> <li>CONNECTED -- you're on an active call with someone. Data can flow back   and forth.</li> <li>CLOSED -- you hung up. The call is over and the socket can't be used   anymore.</li> </ul> <p>These states always move in one direction. You can't go from CLOSED back to LISTENING, just like you can't un-hang-up a phone. If you want to accept more calls, you need a new socket.</p>"},{"location":"concepts/devices-and-networking/#handling-multiple-clients","title":"Handling Multiple Clients","text":"<p>Here's a neat detail: the server's original socket stays in the LISTENING state even after it accepts a connection. Each call to <code>accept()</code> creates a brand-new peer socket that handles that one conversation. The listening socket keeps waiting for more calls.</p> <p>Think of it like a call centre. The main phone number rings at the front desk. When a customer calls, the receptionist picks up and transfers them to an available operator (a new peer socket). The main line stays open for the next caller. The server can handle as many clients as it wants this way.</p>"},{"location":"concepts/devices-and-networking/#data-buffers-the-in-memory-network","title":"Data Buffers -- The In-Memory Network","text":"<p>Our sockets don't use a real network. There are no cables, no Wi-Fi signals, no TCP packets flying around. Instead, when two sockets are connected, PyOS creates two in-memory buffers between them -- one for each direction. When socket A sends data, it goes into a buffer. When socket B calls <code>recv()</code>, it pulls data from that buffer.</p> <p>This is a simplification, but it teaches the real concept perfectly. Real sockets work the same way from the programmer's perspective -- you call <code>send()</code> and <code>recv()</code> and data flows back and forth. The only difference is that real sockets push data through network hardware instead of a Python <code>deque</code>.</p>"},{"location":"concepts/devices-and-networking/#the-socket-manager","title":"The Socket Manager","text":"<p>Just like the <code>DeviceManager</code> keeps track of all devices, the <code>SocketManager</code> keeps track of all sockets. It handles the behind-the-scenes work that a real OS kernel would do:</p> <ul> <li>Creating sockets and assigning them unique IDs.</li> <li>Matching <code>connect()</code> calls to the right listening socket.</li> <li>Creating peer sockets when a server calls <code>accept()</code>.</li> <li>Setting up the bidirectional data buffers for each connection.</li> <li>Routing <code>send()</code> and <code>recv()</code> calls to the correct buffers.</li> </ul> <p>In a real OS, this logic lives deep in the network stack -- a complex set of layers that handle everything from raw electrical signals to high-level protocols like HTTP. PyOS strips all that away and gives you just the socket layer, which is the part your programs actually interact with.</p>"},{"location":"concepts/devices-and-networking/#5-dns-name-resolution-iodnspy","title":"5. DNS -- Name Resolution (<code>io/dns.py</code>)","text":""},{"location":"concepts/devices-and-networking/#the-phone-book-analogy","title":"The Phone Book Analogy","text":"<p>Imagine you want to call your friend Sarah. You know her name, but you don't know her phone number. So you open the phone book, find \"Sarah,\" and read the number next to her name. Now you can dial it.</p> <p>DNS (Domain Name System) does exactly the same thing, but for the internet. When you type <code>www.example.com</code> into a browser, your computer doesn't know where that website lives -- it only understands numeric IP addresses like <code>93.184.216.34</code>. So it asks a DNS server: \"What's the phone number for www.example.com?\" The DNS server looks it up and says \"93.184.216.34.\" Now your computer knows where to connect.</p>"},{"location":"concepts/devices-and-networking/#how-it-works-in-pyos","title":"How It Works in PyOS","text":"<p>PyOS simulates DNS with a <code>DnsResolver</code> -- a local phone book that the kernel owns. Each entry is called an A record (the \"A\" stands for \"Address\"). An A record maps a hostname to an IP address, just like a phone book maps a name to a phone number.</p> <p>You can:</p> <ul> <li>Register -- add a new entry: <code>dns register example.com 93.184.216.34</code></li> <li>Lookup -- find the IP for a name: <code>dns lookup example.com</code></li> <li>Remove -- delete an entry: <code>dns remove example.com</code></li> <li>List -- see all entries: <code>dns list</code></li> <li>Flush -- erase everything: <code>dns flush</code></li> </ul> <p>When the kernel boots, it automatically registers <code>localhost -&gt; 127.0.0.1</code>. That's the computer talking to itself -- like finding your own number in the phone book.</p>"},{"location":"concepts/devices-and-networking/#dns-over-sockets-how-queries-really-travel","title":"DNS Over Sockets -- How Queries Really Travel","text":"<p>Here's something cool: DNS queries don't just magically appear at the server. They travel over sockets, just like any other network communication. In the real world, DNS uses port 53.</p> <p>The <code>dns demo</code> command shows this in action:</p> <ol> <li>A client socket connects to a DNS server socket on port 53.</li> <li>The client sends a text query: <code>QUERY A example.com</code></li> <li>The server receives the query, looks up the hostname in the phone book,    and sends back: <code>ANSWER example.com 93.184.216.34</code></li> <li>The client reads the answer.</li> </ol> <p>This is called protocol layering -- DNS is a protocol that runs on top of sockets. The socket handles the \"how do I send bytes from here to there\" part, and DNS handles the \"what do those bytes mean\" part. It's like how a phone call (the socket) carries a conversation (the protocol) -- the phone doesn't care what language you speak, and the language doesn't care what kind of phone you're using.</p>"},{"location":"concepts/devices-and-networking/#a-records-keeping-it-simple","title":"A Records -- Keeping It Simple","text":"<p>Real DNS has many record types: A records (IPv4 addresses), AAAA records (IPv6), MX records (email servers), CNAME records (aliases), and more. PyOS only implements A records because they're the most fundamental and the easiest to understand. Once you get the concept of \"name -&gt; number,\" all the other record types are just variations on the same theme.</p>"},{"location":"concepts/devices-and-networking/#6-http-talking-on-the-web-iohttppy","title":"6. HTTP -- Talking on the Web (<code>io/http.py</code>)","text":""},{"location":"concepts/devices-and-networking/#the-restaurant-analogy","title":"The Restaurant Analogy","text":"<p>Imagine a restaurant. You (the client) sit down and read the menu. When you're ready, you fill out an order form and hand it to the waiter. The waiter (the socket) carries the order form to the kitchen (the server). The kitchen prepares your food, writes a receipt, and the waiter carries the receipt back to your table.</p> <p>HTTP (Hypertext Transfer Protocol) works exactly like this. When you visit a website, your browser (the client) writes an HTTP request -- an order form -- and sends it to a web server. The server reads the request, figures out what you're asking for, and sends back an HTTP response -- the receipt, which includes the actual web page (or an error message).</p> <p>The important thing is that the order form has a specific format that everyone agrees on. That agreed-upon format is the protocol. Without it, the kitchen wouldn't know how to read your order, and you wouldn't know how to read the receipt.</p>"},{"location":"concepts/devices-and-networking/#requests-the-order-form","title":"Requests -- The Order Form","text":"<p>An HTTP request has three parts:</p> <ol> <li>Method -- what you're asking for:</li> <li><code>GET</code> means \"give me this resource\" (like asking for a menu item)</li> <li> <p><code>POST</code> means \"here's some data for you\" (like submitting a form)</p> </li> <li> <p>Path -- which resource you want (like <code>/index.html</code> or <code>/images/logo.png</code>)</p> </li> <li> <p>Headers -- extra information, like metadata. For example, <code>Host: example.com</code>    tells the server which website you're trying to reach (important because one    server can host many websites).</p> </li> </ol> <p>Here's what a real HTTP request looks like \"on the wire\" -- the raw bytes that travel over the socket:</p> <pre><code>GET /index.html HTTP/1.0\nHost: localhost\n\n</code></pre> <p>That's it. A method, a path, a version, some headers, and a blank line at the end. Simple.</p>"},{"location":"concepts/devices-and-networking/#responses-the-receipt","title":"Responses -- The Receipt","text":"<p>An HTTP response also has a specific format:</p> <ol> <li>Status code -- a number that tells you what happened:</li> <li><code>200 OK</code> -- success! Here's what you asked for.</li> <li><code>404 Not Found</code> -- that resource doesn't exist.</li> <li><code>400 Bad Request</code> -- your order form was filled out wrong.</li> <li> <p><code>500 Internal Server Error</code> -- the kitchen caught fire (something went      wrong on the server's end).</p> </li> <li> <p>Headers -- metadata like <code>Content-Length: 42</code> (how many bytes are in the    body) or <code>Content-Type: text/html</code> (what kind of data this is).</p> </li> <li> <p>Body -- the actual content (the web page, the image, the data).</p> </li> </ol> <p>Here's what a real response looks like:</p> <pre><code>HTTP/1.0 200 OK\nContent-Type: text/html\nContent-Length: 25\n\n&lt;h1&gt;Welcome to PyOS!&lt;/h1&gt;\n</code></pre>"},{"location":"concepts/devices-and-networking/#protocol-layering-http-on-top-of-sockets","title":"Protocol Layering -- HTTP on Top of Sockets","text":"<p>Here's the key insight: HTTP doesn't know or care how bytes get from point A to point B. That's the socket's job. And sockets don't know or care what the bytes mean. That's HTTP's job.</p> <p>This separation is called protocol layering. Each layer does one thing well and relies on the layer below it for the rest:</p> <pre><code>  HTTP      (application layer -- what do the bytes mean?)\n    |\n  TCP       (transport layer -- reliable, ordered delivery)\n    |\n  Sockets   (network layer -- how do bytes get there?)\n    |\n  Buffers   (in-memory simulation of a network)\n</code></pre> <p>In a real OS, there are even more layers (IP, Ethernet). PyOS implements HTTP on TCP on sockets on in-memory buffers. See TCP: Reliable Delivery for how TCP guarantees delivery with congestion control.</p>"},{"location":"concepts/devices-and-networking/#the-http-demo-command","title":"The <code>http demo</code> Command","text":"<p>The <code>http demo</code> command walks through an end-to-end HTTP exchange:</p> <ol> <li>Creates a file in the filesystem (<code>/www/index.html</code>)</li> <li>Registers a DNS name for the web server</li> <li>Sets up a server socket (bind, listen) and a client socket (connect)</li> <li>Client builds an HTTP GET request, formats it, and sends it over the socket</li> <li>Server receives the raw bytes, parses the request, reads the file from the    filesystem, builds an HTTP 200 OK response, and sends it back</li> <li>Client receives and parses the response, displaying the file contents</li> <li>Then repeats with a file that doesn't exist, showing a 404 Not Found</li> </ol> <p>Every socket operation goes through syscalls -- demonstrating full kernel integration. This is real protocol layering in action: DNS resolves the name, sockets carry the bytes, and HTTP gives those bytes meaning.</p>"},{"location":"concepts/devices-and-networking/#http-is-user-space","title":"HTTP Is User-Space","text":"<p>One important design decision: HTTP is not a kernel subsystem. In PyOS (and in real operating systems), the kernel owns sockets, but HTTP is just a library of functions that any program can use. The kernel doesn't know or care about HTTP -- it just moves bytes. This mirrors reality: your web browser is a regular program, not part of the kernel.</p>"},{"location":"concepts/devices-and-networking/#putting-it-all-together","title":"Putting It All Together","text":"<p>These seven systems -- devices, IPC, disk scheduling, networking, TCP, DNS, and HTTP -- cover how the OS connects programs to the outside world and to each other.</p> <ul> <li> <p>Devices give programs a simple, uniform way to talk to hardware. Read and   write -- that's it. The OS handles the messy details of each specific piece   of hardware behind the scenes.</p> </li> <li> <p>IPC lets processes share data even though they live in   isolated memory spaces. Pipes handle byte streams, message   queues handle structured messages, and shared memory lets processes read   and write the same underlying bytes with zero copying.</p> </li> <li> <p>Disk scheduling decides the smartest order to serve disk requests, so   the read head doesn't waste time zigzagging. The choice of algorithm is a   trade-off between fairness and efficiency.</p> </li> <li> <p>Networking lets processes talk to each other across a connection, using   the familiar socket lifecycle: create, bind, listen, accept, send, receive,   close.</p> </li> <li> <p>TCP sits between sockets and HTTP, turning unreliable delivery   into a reliable, ordered byte stream. It uses a three-way handshake to   connect, sliding windows for flow control, and congestion control (slow   start + AIMD) to avoid flooding the network.</p> </li> <li> <p>DNS translates human-readable hostnames into numeric IP addresses,   acting as the internet's phone book. Queries travel over sockets,   demonstrating how protocols layer on top of each other.</p> </li> <li> <p>HTTP adds meaning to the raw bytes that sockets carry. Clients send   structured requests (GET /page) and servers send structured responses   (200 OK with a body). It's the top layer in our protocol stack.</p> </li> </ul> <p>All of these follow a common pattern in OS design: give programs a simple interface (read, write, send, receive) and let the OS handle the complicated stuff underneath. Your program says \"send this data,\" and it doesn't need to know whether it's going to a printer, a pipe, a disk, or another computer halfway around the world.</p>"},{"location":"concepts/devices-and-networking/#where-to-go-next","title":"Where to Go Next","text":"<ul> <li>What Is an OS? -- The big picture of how an OS works</li> <li>Processes -- How the OS runs programs and shares the processor</li> <li>Memory -- How the OS hands out and protects memory</li> <li>Filesystem -- How files and folders are organized and stored</li> <li>TCP: Reliable Delivery -- Three-way handshake, flow control, congestion control</li> <li>The Kernel -- The core of the OS and how programs talk to it</li> </ul>"},{"location":"concepts/filesystem/","title":"The Filesystem","text":"<p>You use files every day. Your homework, your photos, your game saves -- they all live somewhere on your computer. But have you ever wondered how the computer keeps track of all of them? That is the job of the filesystem.</p>"},{"location":"concepts/filesystem/#what-is-a-filesystem","title":"What Is a Filesystem?","text":"<p>Think of a filesystem like a giant filing cabinet.</p> <p>The cabinet has drawers, and those drawers are directories (also called folders). Inside the drawers you'll find papers, and those papers are files. Drawers can contain other drawers too -- a folder inside a folder inside a folder, as deep as you want.</p> <p>Now here is the interesting part. Every paper and every drawer has a little index card stapled to it. That index card records important facts: is this a file or a folder? How big is it? What's actually inside? In operating system terms, that index card is called an inode (short for \"index node\"). We'll dig into inodes in a moment.</p> <p>But first, there is one more surprising detail. The name of a file doesn't live on the file itself. It lives in the drawer (directory) that the file sits inside. It's like how a teacher's attendance sheet has your name on it, but the actual essay you turned in doesn't have your name written on the pages -- the folder it's in tells the teacher whose work it is.</p> <p>In our code (<code>fs/filesystem.py</code>), the <code>FileSystem</code> class manages all of this. When you create a file or folder, the filesystem creates a new inode and then adds the name to the parent directory's list. The name and the data live in different places, connected by a number.</p>"},{"location":"concepts/filesystem/#inodes-the-index-cards","title":"Inodes: The Index Cards","text":"<p>Every file and every directory in the filesystem gets its own numbered index card -- an inode. You can think of the inode number as a student ID. The school (filesystem) uses the ID to look up everything it needs to know about you.</p> <p>Here is what an inode keeps track of:</p> <ul> <li>Type -- Is this a file or a directory?</li> <li>Size -- How many bytes of data does it hold?</li> <li>Data -- For a file, this is the actual contents (the text, the image, the   bytes). For a directory, this is a list of \"name to inode number\" mappings --   basically the table of contents for that drawer.</li> </ul> <p>In our Python code, the <code>_Inode</code> class looks like this (simplified):</p> <pre><code>@dataclass\nclass _Inode:\n    inode_number: int\n    file_type: FileType      # FILE, DIRECTORY, or SYMLINK\n    data: bytes = b\"\"        # file contents (or symlink target path)\n    children: dict[str, int] # name -&gt; inode number (for directories)\n    link_count: int = 1      # how many names point to this inode\n</code></pre> <p>Notice the <code>children</code> dictionary. If this inode is a directory, <code>children</code> maps each child's name to its inode number. That is the \"attendance sheet\" we talked about -- the names live here, not on the files themselves.</p> <p>Why does this matter? In real Unix systems, this separation is what makes hard links possible. Two different names in two different folders can point to the same inode number -- the same underlying file. It's like two teachers both having your student ID on their attendance sheets, but there's only one you.</p>"},{"location":"concepts/filesystem/#path-resolution-finding-your-file","title":"Path Resolution: Finding Your File","text":"<p>When you ask the computer for a file like <code>/home/rob/homework.txt</code>, it doesn't magically jump straight to it. It has to walk the path, one step at a time, like following directions on a treasure map.</p> <p>Here's how it works:</p> <ol> <li>Start at the root (<code>/</code>) -- this is the main filing cabinet, the top-level    directory. Every path starts here.</li> <li>Look up \"home\" in the root directory's children -- the root inode has a    mapping that says \"home\" is at inode 2 (or whatever number). Follow that.</li> <li>Look up \"rob\" in the \"home\" directory's children -- another mapping,    another inode number. Follow that too.</li> <li>Look up \"homework.txt\" in the \"rob\" directory's children -- this time    it points to a file inode. You've found it.</li> </ol> <p>Each step is a lookup: \"does this directory have something called X?\" If the answer is yes, you follow the inode number and keep going. If the answer is no, you get a <code>FileNotFoundError</code> -- the path is broken somewhere along the way.</p> <p>In <code>fs/filesystem.py</code>, the <code>_resolve</code> method does exactly this:</p> <pre><code>def _resolve(self, path: str) -&gt; _Inode | None:\n    parts = path.strip(\"/\").split(\"/\")\n    current = self._inodes[self._root_ino]\n\n    for part in parts:\n        child_ino = current.children.get(part)\n        if child_ino is None:\n            return None\n        current = self._inodes[child_ino]\n\n    return current\n</code></pre> <p>It splits the path into parts (<code>[\"home\", \"rob\", \"homework.txt\"]</code>), then loops through them one by one, hopping from directory to directory. Simple and clean.</p> <p>When The Kernel receives a filesystem syscall (like \"read this file\" or \"list this directory\"), the kernel hands the path to the filesystem, and this resolution process kicks in before anything else happens.</p>"},{"location":"concepts/filesystem/#links-multiple-names-for-one-file","title":"Links: Multiple Names for One File","text":"<p>Remember how names live in the parent directory, not on the file itself? That separation makes something really cool possible: one file can have more than one name. There are two kinds of links in Unix, and they work very differently.</p>"},{"location":"concepts/filesystem/#the-phone-contacts-analogy","title":"The Phone Contacts Analogy","text":"<p>Hard link = Two entries in your phone's contacts that both reach the same person. \"Mom\" and \"Emergency Contact\" both dial the same number. If you delete \"Mom\", the person is still reachable through \"Emergency Contact\". The person only truly disappears from your phone when you delete every contact entry for that number.</p> <p>Symbolic link = A sticky note on your desk that says \"Call Mom's number\". It doesn't store the number itself -- it points to the contact entry. If someone deletes \"Mom\" from your contacts, the sticky note is useless (a dangling link). But if someone later adds \"Mom\" back, the sticky note works again.</p>"},{"location":"concepts/filesystem/#hard-links","title":"Hard Links","text":"<p>A hard link is a second name that points to the same inode. Since both names point to the same inode number, they share everything: the same data, the same size, the same type. Writing through one name changes the data for the other name too, because there is only one copy of the data.</p> <pre><code>Directory /         Directory /docs\nname \u2192 inode        name \u2192 inode\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500       \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nhello.txt \u2192 5      ref.txt \u2192 5      \u2190 same inode!\n</code></pre> <p>In PyOS:</p> <pre><code>fs.create_file(\"/hello.txt\")\nfs.write(\"/hello.txt\", b\"Hi!\")\nfs.link(\"/hello.txt\", \"/docs/ref.txt\")\n\n# Both names read the same data:\nfs.read(\"/docs/ref.txt\")   # b\"Hi!\"\n</code></pre> <p>Rules for hard links:</p> <ul> <li>You cannot hard-link directories. If you could, the directory tree would have   loops, and path resolution would never finish.</li> <li>The target file must already exist.</li> <li>The new name must not already exist.</li> </ul>"},{"location":"concepts/filesystem/#link-count","title":"Link Count","text":"<p>How does the OS know when to actually delete a file's data? It uses a link count -- a counter on the inode that tracks how many names point to it. Every time you create a hard link, the count goes up. Every time you delete a name, the count goes down. The inode (and its data) is only freed when the count hits zero.</p> <pre><code>fs.stat(\"/hello.txt\").link_count   # 1  (just created)\nfs.link(\"/hello.txt\", \"/alias.txt\")\nfs.stat(\"/hello.txt\").link_count   # 2  (two names now)\nfs.delete(\"/hello.txt\")\nfs.stat(\"/alias.txt\").link_count   # 1  (one name left, data still alive)\nfs.delete(\"/alias.txt\")            # link_count \u2192 0, inode freed\n</code></pre>"},{"location":"concepts/filesystem/#symbolic-links-symlinks","title":"Symbolic Links (Symlinks)","text":"<p>A symbolic link is a completely different kind of inode. Instead of pointing to the same inode number, it creates a new inode whose data is the path to the target. It is like a shortcut file that says \"go look over there\".</p> <pre><code>fs.create_file(\"/target.txt\")\nfs.symlink(\"/target.txt\", \"/shortcut.txt\")\n\nfs.readlink(\"/shortcut.txt\")   # \"/target.txt\"\nfs.read(\"/shortcut.txt\")       # reads /target.txt's data (followed the link)\n</code></pre> <p>The filesystem follows symlinks automatically during path resolution. When <code>_resolve()</code> encounters a symlink, it reads the stored target path and continues resolving from there.</p> <p>What makes symlinks special:</p> <ul> <li>The target doesn't have to exist. You can create a symlink pointing to   <code>/nonexistent</code>, and the symlink itself is valid. It just can't be followed   until the target exists. This is called a dangling symlink.</li> <li>You can symlink directories. This is safe because symlinks have depth   protection (see below).</li> <li>Symlinks can be relative (<code>real.txt</code>) or absolute (<code>/data/real.txt</code>).   Relative targets resolve from the symlink's parent directory.</li> </ul>"},{"location":"concepts/filesystem/#loop-detection","title":"Loop Detection","text":"<p>What if symlink A points to B, and B points back to A? The filesystem would follow links forever. To prevent this, <code>_resolve()</code> counts how many symlinks it has followed. If the count exceeds <code>MAX_SYMLINK_DEPTH</code> (40, matching Linux), it raises an error: \"Too many levels of symbolic links\".</p> <pre><code>fs.symlink(\"/b\", \"/a\")   # /a \u2192 /b\nfs.symlink(\"/a\", \"/b\")   # /b \u2192 /a (circular!)\nfs.stat(\"/a\")             # OSError: Too many levels of symbolic links\n</code></pre>"},{"location":"concepts/filesystem/#stat-vs-lstat","title":"stat vs. lstat","text":"<p>The <code>stat()</code> function follows symlinks -- if you stat a symlink, you get the target's metadata. But sometimes you want to see the symlink itself. That is what <code>lstat()</code> does: it returns the symlink's own inode info (type=SYMLINK, size=length of the target path) without following it.</p> <pre><code>fs.stat(\"/shortcut.txt\").file_type    # FileType.FILE (the target)\nfs.lstat(\"/shortcut.txt\").file_type   # FileType.SYMLINK (the link itself)\n</code></pre>"},{"location":"concepts/filesystem/#deleting-links","title":"Deleting Links","text":"<ul> <li>Deleting a hard link removes one name and decrements the link count. The   data survives as long as at least one name remains.</li> <li>Deleting a symlink removes the symlink inode. The target is untouched.</li> <li>Deleting the target of a symlink leaves the symlink dangling -- the   symlink still exists, but following it produces a \"not found\" error.</li> </ul>"},{"location":"concepts/filesystem/#saving-to-disk-persistence","title":"Saving to Disk: Persistence","text":"<p>Here is a problem. Our filesystem lives entirely in Python's memory. That means when you turn off the computer (or stop the program), everything vanishes. Gone. It is like building a beautiful filing cabinet out of ice -- when the power goes out, the whole thing melts.</p> <p>To solve this, we need persistence -- a way to save the filing cabinet so we can rebuild it later. That's what <code>fs/persistence.py</code> does.</p>"},{"location":"concepts/filesystem/#the-photograph-analogy","title":"The Photograph Analogy","text":"<p>Imagine taking a photograph of every single drawer and every single paper in your filing cabinet. You write down what's in each drawer, what each paper says, and how everything is organized. Then you save all those photographs in a safe place.</p> <p>When the power comes back on, you look at the photographs and carefully rebuild the entire cabinet from scratch. That process of taking the photograph is called serialization (turning the live data into a storable format). Rebuilding the cabinet from the photograph is called deserialization (turning the stored format back into live data).</p>"},{"location":"concepts/filesystem/#json-our-photograph-format","title":"JSON: Our \"Photograph\" Format","text":"<p>Our \"photographs\" are saved as JSON -- a simple text format that looks like this:</p> <pre><code>{\n  \"root_ino\": 0,\n  \"inodes\": {\n    \"0\": {\n      \"inode_number\": 0,\n      \"file_type\": \"directory\",\n      \"data\": \"\",\n      \"children\": {\"homework.txt\": 1}\n    },\n    \"1\": {\n      \"inode_number\": 1,\n      \"file_type\": \"file\",\n      \"data\": \"SGVsbG8gd29ybGQ=\",\n      \"children\": {}\n    }\n  }\n}\n</code></pre> <p>You can read it with your eyes -- it's just text. That is the whole point. JSON is human-readable, which makes it great for learning. You can open the saved file and see exactly what your filesystem looked like.</p>"},{"location":"concepts/filesystem/#base64-translating-pictures-into-words","title":"Base64: Translating Pictures Into Words","text":"<p>Wait -- there's a catch. JSON is a text format, but files can contain binary data (raw bytes, like images or compiled programs). You can't just shove random bytes into a text file. It would break.</p> <p>The solution is Base64 encoding. Think of it as translating a picture into words so it can be written in a text file. Base64 takes any sequence of bytes and converts it into safe text characters (letters, numbers, <code>+</code>, <code>/</code>, and <code>=</code>). The text is about 33% bigger than the original bytes, but it fits perfectly in JSON.</p> <p>In our code, <code>to_dict()</code> encodes file data with <code>base64.b64encode()</code>, and <code>from_dict()</code> decodes it back with <code>base64.b64decode()</code>. The data makes a round trip without losing a single byte.</p>"},{"location":"concepts/filesystem/#how-real-filesystems-do-it","title":"How Real Filesystems Do It","text":"<p>Real operating systems (Linux, Windows, macOS) don't use JSON. Their filesystems -- ext4, NTFS, APFS -- write directly to the hard drive in a special binary format. This is much faster and more compact, but much harder to read with human eyes. The tradeoff is speed versus understandability, and for a learning project, understandability wins.</p> <p>Here is a quick comparison:</p> PyOS (our version) Real Filesystem JSON text file Binary data on disk <code>dump_filesystem()</code> <code>sync</code> / unmount <code>load_filesystem()</code> <code>mount</code> Saves everything Only saves what changed No crash recovery Journaling (see below)"},{"location":"concepts/filesystem/#journaling-the-undo-history-safety-net","title":"Journaling: The Undo-History Safety Net","text":"<p>Imagine you're writing an essay in a text editor. Your editor saves a backup every 10 minutes (that's a checkpoint). Every keystroke you type is recorded in the undo history (that's the journal).</p> <p>If your computer suddenly loses power, you'd lose everything since the last save, right? But with a journal, you can do better:</p> <ol> <li>Open the last saved backup (restore from checkpoint).</li> <li>Look at the undo history and replay every keystroke that was \"finished\"    (committed transactions).</li> <li>Throw away any half-typed words that weren't finished (active/aborted    transactions).</li> </ol> <p>That's exactly how filesystem journaling works! The journal is a safety net that lets us recover from crashes without losing completed work.</p>"},{"location":"concepts/filesystem/#what-is-a-crash","title":"What Is a Crash?","text":"<p>A \"crash\" is anything that stops the computer without warning -- a power outage, a frozen program, or pulling the plug. The danger is that you might be in the middle of changing a file. If the power dies after writing half the data, the file is corrupted -- not the old version, not the new version, but a broken mix of both.</p>"},{"location":"concepts/filesystem/#write-ahead-logging-log-before-you-do","title":"Write-Ahead Logging: Log Before You Do","text":"<p>The key idea is simple: write down what you're about to do before you actually do it. This is called write-ahead logging (WAL). Here's the pattern every journaled operation follows:</p> <pre><code># 1. Begin a transaction\ntxn = journal.begin()\n\n# 2. Log what we're about to do\njournal.append(txn, entry)\n\n# 3. Actually do it\nfilesystem.create_file(path)\n\n# 4. Mark the transaction as done\njournal.commit(txn)\n</code></pre> <p>If a crash happens between steps 2 and 4, the transaction stays \"active\" (uncommitted). On recovery, we know it didn't finish, so we can safely ignore it.</p>"},{"location":"concepts/filesystem/#transactions-begin-commit-abort","title":"Transactions: Begin, Commit, Abort","text":"<p>A transaction is a bundle of work that either fully succeeds or fully fails -- there's no in-between. Each transaction goes through these states:</p> State Meaning active Work is in progress committed All done -- this work should be kept aborted Something went wrong -- throw this away <p>In our PyOS code, every filesystem mutation (create, write, delete, link) is wrapped in its own transaction. This keeps things simple: one operation = one transaction.</p>"},{"location":"concepts/filesystem/#checkpoints-the-known-good-snapshot","title":"Checkpoints: The Known-Good Snapshot","text":"<p>A checkpoint is like hitting \"Save\" in your text editor. It takes a photograph of the entire filesystem at that moment. We call this the \"known-good state\" because we know it's consistent and correct.</p> <p>After a checkpoint, we can also clean up the journal -- we don't need to keep records of work that's already been safely saved.</p> <pre><code>journal checkpoint    \u2192  \"Checkpoint created\"\n</code></pre>"},{"location":"concepts/filesystem/#recovery-restore-replay","title":"Recovery: Restore + Replay","text":"<p>When you recover from a crash, three things happen:</p> <ol> <li>Restore the filesystem to the last checkpoint (the last known-good    state).</li> <li>Replay all committed transactions that happened after the checkpoint.    These were finished work, so we redo them.</li> <li>Discard any active or aborted transactions. These were unfinished, so    we throw them away.</li> </ol> <pre><code>journal recover    \u2192  \"Recovery complete: replayed 3 transactions\"\n</code></pre> <p>The result? Your filesystem is back to a consistent state, with all completed work preserved. Only truly unfinished operations are lost.</p>"},{"location":"concepts/filesystem/#why-redo-logging-not-undo","title":"Why \"Redo\" Logging (Not Undo)?","text":"<p>There are two approaches to crash recovery:</p> <ul> <li>Redo logging (what we use): Save the checkpoint, then replay committed   work forward. Simple and clean.</li> <li>Undo logging: Record how to reverse each operation. Much more complex   because you need to figure out the \"opposite\" of every action.</li> </ul> <p>Real filesystems like ext3 and ext4 use redo logging in \"ordered\" mode. It's the simpler approach, and it works great.</p>"},{"location":"concepts/filesystem/#trying-it-in-pyos","title":"Trying It in PyOS","text":"<p>You can experiment with crash recovery in the PyOS shell:</p> <pre><code>touch /important.txt              # create a file\nwrite /important.txt secret data  # write to it\njournal checkpoint                # save a known-good state\ntouch /experiment.txt             # create another file\nwrite /experiment.txt testing     # write some data\njournal crash                     # simulate a power failure!\ncat /important.txt                # still here (was checkpointed)\ncat /experiment.txt               # Error! (but was committed...)\njournal recover                   # replay committed transactions\ncat /experiment.txt               # back! recovered from the journal\n</code></pre>"},{"location":"concepts/filesystem/#how-real-filesystems-do-it_1","title":"How Real Filesystems Do It","text":"<p>Real filesystems like ext4 journal their metadata by default. More advanced systems like ZFS and Btrfs use a technique called copy-on-write with checksums, which gives even stronger protection against corruption.</p> <p>Our PyOS journal keeps things simple for learning, but the core ideas -- write-ahead logging, transactions, checkpoints, and recovery -- are exactly what real operating systems use every day to keep your files safe.</p>"},{"location":"concepts/filesystem/#file-descriptors-bookmarks-in-a-library-book","title":"File Descriptors: Bookmarks in a Library Book","text":"<p>So far, every time we wanted to read or write a file, we gave the full path and got back the entire contents. That works fine for small operations, but real programs need something more flexible. They need to:</p> <ul> <li>Open a file once, then read a little bit at a time.</li> <li>Write a few bytes here, a few bytes there, without replacing the whole file.</li> <li>Jump to a specific position in the file (like flipping to page 50).</li> <li>Close the file when they're done, so the OS can clean up.</li> </ul> <p>This is where file descriptors come in.</p>"},{"location":"concepts/filesystem/#the-library-analogy","title":"The Library Analogy","text":"<p>Imagine you go to the library and want to read a book. You can't just grab the book off the shelf -- you have to check it out at the front desk. The librarian gives you a numbered ticket (your file descriptor). You put a bookmark in the book to remember where you stopped reading (the offset).</p> <ul> <li><code>open</code> = check out a book from the library, get your ticket number</li> <li><code>read</code> = read from where your bookmark is, then move it forward</li> <li><code>write</code> = scribble on the page at your bookmark, then move it forward</li> <li><code>seek</code> = move your bookmark to a different page</li> <li><code>close</code> = return the book to the library</li> </ul> <p>Why numbered tickets instead of holding the book directly? Because the librarian (the OS) needs to keep track of who has what checked out. If you leave the library without returning your books, the librarian can clean up automatically.</p>"},{"location":"concepts/filesystem/#how-it-works-in-pyos","title":"How It Works in PyOS","text":"<p>When you call <code>open</code>, the kernel:</p> <ol> <li>Checks that the file exists and is not a directory.</li> <li>Creates an open file description -- a little record that tracks the file    path, access mode (read, write, or both), and the current offset (starts    at 0, meaning the beginning of the file).</li> <li>Assigns the lowest available fd number (starting at 3) and stores it in    the process's fd table.</li> <li>Returns the fd number to you.</li> </ol> <p>Why does numbering start at 3? In Unix, fds 0, 1, and 2 are reserved:</p> FD Name Purpose 0 stdin Standard input (keyboard) 1 stdout Standard output (screen) 2 stderr Standard error (error messages) <p>We reserve these slots even though PyOS doesn't implement them yet -- it teaches the convention that every Unix programmer needs to know.</p>"},{"location":"concepts/filesystem/#access-modes","title":"Access Modes","text":"<p>When you open a file, you choose what you're allowed to do with it:</p> Mode Meaning Read? Write? <code>r</code> Read-only Yes No <code>w</code> Write-only No Yes <code>rw</code> Read-write Yes Yes <p>If you try to read from a write-only fd, or write to a read-only fd, you get an error. This is mode enforcement -- the OS protects you from accidentally doing something you didn't intend.</p>"},{"location":"concepts/filesystem/#reading-past-the-end","title":"Reading Past the End","text":"<p>What happens if you try to read 100 bytes from a file that only has 10 bytes left? You just get the 10 bytes that exist. No error, no crash. And if you try to read when you're already at the very end of the file, you get zero bytes back (empty). This matches how real Unix works -- programs use \"got zero bytes\" as the signal that they've reached the end.</p>"},{"location":"concepts/filesystem/#writing-past-the-end","title":"Writing Past the End","text":"<p>What if you seek past the end of a file and then write? The gap gets filled with null bytes (<code>\\x00</code>). It's like having a notebook where you skip ahead to page 50 and start writing -- pages 1 through 49 are just blank.</p>"},{"location":"concepts/filesystem/#fork-and-file-descriptors","title":"Fork and File Descriptors","text":"<p>When a process forks (creates a child copy), the child gets a copy of the parent's fd table. Both parent and child have the same fd numbers pointing to the same files. But their offsets are independent -- reading in the parent doesn't move the child's bookmark.</p> <p>(In real Unix, parent and child actually share the same offset. PyOS simplifies this to independent copies, which is easier to understand.)</p>"},{"location":"concepts/filesystem/#cleanup","title":"Cleanup","text":"<p>When a process terminates (normally or by signal), the kernel automatically closes all its open fds. You don't have to worry about leaked file descriptors -- the OS cleans up after you, just like the librarian knows which books you checked out and can return them when you leave.</p>"},{"location":"concepts/filesystem/#putting-it-all-together","title":"Putting It All Together","text":"<p>Let's trace what happens when you type <code>cat /home/rob/homework.txt</code> in the PyOS shell:</p> <ol> <li>The shell parses your command and sees you want to read a file.</li> <li>The shell sends a syscall (system call) to    The Kernel, asking to read <code>/home/rob/homework.txt</code>.</li> <li>The kernel passes the request to the filesystem.</li> <li>The filesystem resolves the path: root -&gt; \"home\" -&gt; \"rob\" -&gt;    \"homework.txt\", following inode numbers at each step.</li> <li>It finds the file's inode and reads its <code>data</code> field.</li> <li>The data travels back up: filesystem -&gt; kernel -&gt; shell -&gt; your screen.</li> </ol> <p>And when you shut down PyOS and save your work:</p> <ol> <li><code>dump_filesystem()</code> serializes every inode into JSON (with Base64 for binary    data) and writes it to a file on your real hard drive.</li> <li>Next time you boot PyOS, <code>load_filesystem()</code> reads that JSON file and    reconstructs the entire filing cabinet in memory.</li> </ol> <p>That is the full lifecycle of a file, from creation to storage to survival across reboots.</p>"},{"location":"concepts/filesystem/#key-vocabulary","title":"Key Vocabulary","text":"Term Plain English Filesystem The system that organizes and manages files and folders Inode An index card with metadata about a file or directory Directory A folder -- an inode whose \"data\" is a list of names and inode numbers Path resolution Walking a path like <code>/a/b/c</code> step by step to find the target File descriptor A small number (like a library ticket) that identifies an open file Offset Your current position in the file (like a bookmark) Fd table Per-process table that maps fd numbers to open file descriptions Hard link A second name pointing to the same inode (same data, same file) Symbolic link A special inode that stores a path to another file (a shortcut) Link count How many names point to an inode; file is freed when it hits zero Dangling symlink A symlink whose target doesn't exist (yet) Symlink loop Circular symlinks (A\u2192B\u2192A); caught by MAX_SYMLINK_DEPTH Serialization Converting live data into a storable format (like taking a photo) Deserialization Rebuilding live data from a stored format (like rebuilding from a photo) Base64 A way to encode binary data as safe text characters JSON A human-readable text format for structured data Journaling Writing a plan before doing work, so crashes don't cause corruption Write-ahead log The journal itself -- a record of planned operations Transaction A unit of work that fully succeeds or fully fails Commit Mark a transaction as successfully completed Abort Mark a transaction as failed or incomplete Checkpoint A snapshot of the filesystem at a known-good point Recovery Restoring from checkpoint and replaying committed transactions Crash consistency The guarantee that the filesystem is valid after a crash"},{"location":"concepts/filesystem/#virtual-filesystems-proc","title":"Virtual Filesystems -- /proc","text":"<p>So far, every file we've talked about lives on \"disk\" (in memory, for our simulator). But what if you could have a directory that doesn't store anything at all -- and yet, every time you open a file inside it, you get fresh, live information?</p> <p>That's exactly what <code>/proc</code> is. Think of it as a magic bulletin board in the school hallway. Nobody writes real papers and pins them there. When you walk up and look at a section, the information appears automatically from the school's current records. A new student arrives? Their name instantly appears on the board. A student leaves? Their entry vanishes.</p>"},{"location":"concepts/filesystem/#whats-inside-proc","title":"What's inside /proc?","text":"<pre><code>/proc/\n\u251c\u2500\u2500 meminfo          -- Memory statistics (total, free, used, shared)\n\u251c\u2500\u2500 uptime           -- How long the system has been running\n\u251c\u2500\u2500 cpuinfo          -- Scheduler policy, ready queue size (per-CPU on multi-CPU systems)\n\u251c\u2500\u2500 stat             -- Performance metrics (context switches, throughput)\n\u251c\u2500\u2500 [pid]/           -- One directory per process\n\u2502   \u251c\u2500\u2500 status       -- Name, PID, parent, state, priority, threads\n\u2502   \u251c\u2500\u2500 maps         -- Which memory pages the process uses\n\u2502   \u251c\u2500\u2500 cmdline      -- The process name\n\u2502   \u2514\u2500\u2500 sched        -- Timing info (wait time, CPU time, response time)\n\u2514\u2500\u2500 self/            -- Alias for whatever process is running right now\n    \u251c\u2500\u2500 status\n    \u251c\u2500\u2500 maps\n    \u251c\u2500\u2500 cmdline\n    \u2514\u2500\u2500 sched\n</code></pre>"},{"location":"concepts/filesystem/#how-to-use-it","title":"How to use it","text":"<p>You use the same commands you already know! <code>cat</code> and <code>ls</code> automatically detect <code>/proc</code> paths and route to the virtual filesystem instead of the real one.</p> <pre><code>ls /proc            -- see what's on the bulletin board\ncat /proc/meminfo   -- check memory usage\ncat /proc/uptime    -- see how long the system has been up\ncat /proc/stat      -- see performance metrics (context switches, throughput)\nls /proc/42         -- list files for process 42\ncat /proc/42/status -- see process 42's details\ncat /proc/42/sched  -- see process 42's timing (wait, CPU, response time)\n</code></pre>"},{"location":"concepts/filesystem/#why-does-this-exist","title":"Why does this exist?","text":"<p>In real Linux, tools like <code>ps</code>, <code>top</code>, and <code>free</code> don't have special access to the kernel. They're just ordinary programs that read files from <code>/proc</code>. This is a beautiful design: instead of needing a special API for every kind of system information, the kernel just makes it look like files. If you know how to read a file, you know how to inspect the entire system.</p>"},{"location":"concepts/filesystem/#virtual-vs-real-files","title":"Virtual vs real files","text":"Property Real files (<code>/data/report.txt</code>) Virtual files (<code>/proc/meminfo</code>) Stored on disk? Yes No -- generated on every read Content changes? Only when someone writes Every read may be different Can you write? Yes (<code>write</code> command) No -- read-only Uses inodes? Yes No -- separate ProcFilesystem class Term Meaning Virtual filesystem A filesystem where files don't exist on disk -- content is generated live /proc The virtual filesystem that exposes kernel state as readable files /proc/self A shortcut that always points to whatever process is currently running"},{"location":"concepts/filesystem/#where-to-go-next","title":"Where to Go Next","text":"<ul> <li>The Kernel -- How the kernel routes your filesystem   requests through syscalls</li> <li>Processes -- How the OS runs programs that read and write files</li> <li>Memory -- How the OS gives programs space to work with file data</li> </ul>"},{"location":"concepts/interrupts/","title":"Interrupts and Timers","text":"<p>Imagine you are reading a book. Suddenly the doorbell rings. You stop reading, put a bookmark in, answer the door, and then come back and pick up where you left off. That is exactly how a hardware interrupt works.</p>"},{"location":"concepts/interrupts/#what-is-an-interrupt","title":"What Is an Interrupt?","text":"<p>An interrupt is a signal from a piece of hardware saying \"pay attention to me!\" When the CPU receives an interrupt, it pauses whatever it was doing, handles the event, and then goes back to its previous work.</p> <p>Without interrupts, the CPU would have to keep checking every device over and over: \"Keyboard, did you get a key press? Disk, are you done reading? Timer, is it time yet?\" This wasteful checking is called polling, and it is like constantly peeking out the window to see if anyone is at the door.</p> <p>With interrupts, the devices ring the doorbell only when something actually happens. The CPU can focus on useful work the rest of the time.</p>"},{"location":"concepts/interrupts/#the-interrupt-controller","title":"The Interrupt Controller","text":"<p>In a real computer, a chip called the interrupt controller sits between the devices and the CPU. It has a list of interrupt vectors -- numbered slots, one for each kind of event.</p> Vector Device Priority 0 Timer High 16 I/O completion Normal <p>When a device needs attention, it sends a signal to the controller. The controller adds the request to a queue. When the CPU is ready, it asks the controller \"what needs handling?\" and the controller serves requests in priority order -- urgent ones first.</p> <p>In PyOS, the <code>InterruptController</code> class does exactly this:</p> <pre><code>interrupt list\n\nVEC  TYPE      PRI  MASKED  PENDING  HANDLER\n  0  timer       3      no        0  yes\n 16  io          2      no        0  yes\n</code></pre>"},{"location":"concepts/interrupts/#interrupt-masking","title":"Interrupt Masking","text":"<p>Sometimes the OS needs to do something without being interrupted -- like updating a shared data structure. It can mask (silence) certain vectors temporarily. Masked interrupts still get queued, but they are not delivered until the vector is unmasked.</p> <p>Think of it like putting your phone on silent. Calls still come in (you see them later), but your phone does not ring while you are concentrating.</p> <pre><code>interrupt mask 0        # Silence the timer\ntick 5                  # Ticks happen, but timer interrupts queue silently\ninterrupt unmask 0      # Resume -- queued interrupts are delivered\n</code></pre>"},{"location":"concepts/interrupts/#the-timer","title":"The Timer","text":"<p>The timer is a special device that ticks at a regular rate. Every N ticks, it fires an interrupt. The OS uses this for three things:</p> <ol> <li>Preemption -- giving each process a fair time slice, then switching to the next one.</li> <li>Timekeeping -- tracking how long things take.</li> <li>Timeouts -- knowing when to retry a network request.</li> </ol> <p>In PyOS, the timer is a <code>TimerDevice</code> that plugs into the interrupt controller. You can check its status and change how often it fires:</p> <pre><code>timer info\n\nTimer device:\n  Interval:     5 ticks\n  Current tick: 0\n  Total ticks:  0\n  Total fires:  0\n\ntimer set 3             # Fire every 3 ticks instead of 5\n</code></pre>"},{"location":"concepts/interrupts/#ticking-the-system-clock","title":"Ticking the System Clock","text":"<p>In a real computer, the timer ticks automatically based on a crystal oscillator. In PyOS, we advance time manually with the <code>tick</code> command:</p> <pre><code>tick 10\n\nTicked 10 time(s)\n  Current tick: 10\n  Interrupts serviced: 2\n</code></pre> <p>Each tick:</p> <ol> <li>Advances the timer counter by one.</li> <li>If the counter reaches the interval, the timer fires -- it sends an interrupt to the controller.</li> <li>The controller delivers all pending interrupts to their handlers.</li> <li>The timer handler checks if the current process has used up its time slice. If so, it preempts the process (moves it to the back of the ready queue) and lets the next process run.</li> </ol>"},{"location":"concepts/interrupts/#timer-driven-preemption","title":"Timer-Driven Preemption","text":"<p>Without a timer, a process could hog the CPU forever. The timer makes preemptive scheduling possible:</p> <ol> <li>The scheduler gives a process a quantum (a fixed number of ticks to run).</li> <li>The timer counts ticks.</li> <li>When ticks reach the quantum, the timer fires and the kernel switches to the next process.</li> </ol> <p>This is how Round Robin, MLFQ, and CFS schedulers ensure fairness -- no single process can monopolise the CPU.</p>"},{"location":"concepts/interrupts/#how-interrupts-fit-in-the-big-picture","title":"How Interrupts Fit in the Big Picture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Kernel                        \u2502\n\u2502                                                  \u2502\n\u2502   Timer  \u2500\u2500fire\u2500\u2500\u25b6  Interrupt   \u2500\u2500dispatch\u2500\u2500\u25b6   \u2502\n\u2502  Device             Controller      Handler      \u2502\n\u2502                                                  \u2502\n\u2502   Disk   \u2500\u2500done\u2500\u2500\u25b6  (queue by  \u2500\u2500dispatch\u2500\u2500\u25b6   \u2502\n\u2502   NIC                priority)      Handler      \u2502\n\u2502                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Devices raise interrupts. The controller queues them by priority. Handlers process them. The kernel keeps running.</p>"},{"location":"concepts/interrupts/#try-it-yourself","title":"Try It Yourself","text":"<p>Boot PyOS and run the interactive lesson:</p> <pre><code>learn interrupts\n</code></pre> <p>Or experiment manually:</p> <pre><code>timer info              # See the timer's state\ntick 5                  # Advance 5 ticks (timer fires once at default interval)\ninterrupt list          # See all registered vectors\ninterrupt mask 0        # Silence the timer\ntick 5                  # Timer queues but doesn't fire\ninterrupt unmask 0      # Resume delivery\ntick 1                  # Queued interrupt is now serviced\n</code></pre> <p>Next: Learn about reliable network delivery in TCP: Reliable Delivery.</p>"},{"location":"concepts/kernel-and-syscalls/","title":"The Kernel and System Calls","text":"<p>In the What Is an Operating System? page we said the kernel is like the principal's office -- the place where all the real decisions get made. Now let's open that door and look inside.</p> <p>This page covers two files in the PyOS codebase:</p> <ul> <li>kernel.py -- the kernel itself, the brain of the OS.</li> <li>syscalls.py -- the front desk that sits between programs and the kernel.</li> </ul>"},{"location":"concepts/kernel-and-syscalls/#1-what-is-the-kernel","title":"1. What Is the Kernel?","text":"<p>The kernel is like the principal of a school. The principal doesn't teach classes or do homework. Instead, they coordinate everything: they make sure classrooms are assigned, teachers know their schedules, the building is maintained, and the whole school runs smoothly.</p> <p>In an operating system, the kernel does the same job. It coordinates every part of the system -- memory, files, running programs, devices, users -- so that everything works together without stepping on each other.</p> <p>Here are the key things to know about the kernel:</p> <p>It owns all the subsystems. The kernel holds references to the memory manager, the file system, the scheduler, the user manager, and the device manager. No other piece of code is allowed to create or destroy these. The kernel sets them up when the OS boots and tears them down when the OS shuts off.</p> <p>It is the ONLY thing that can directly touch hardware. Programs (the \"students\") are never allowed to reach past the kernel and poke at hardware themselves. They have to ask the kernel, and the kernel decides whether to grant the request. This keeps everything safe and organized.</p> <p>It has a lifecycle. The kernel is not just \"on\" or \"off.\" It moves through a series of states, like a school that opens in the morning and closes at night:</p> <pre><code>SHUTDOWN  --&gt;  BOOTING  --&gt;  RUNNING  --&gt;  SHUTTING_DOWN  --&gt;  SHUTDOWN\n</code></pre> <ul> <li>SHUTDOWN -- the school is closed, the lights are off.</li> <li>BOOTING -- the janitor is unlocking doors and turning things on.</li> <li>RUNNING -- the school is open, students and teachers are doing their thing.</li> <li>SHUTTING_DOWN -- the day is over, everyone is packing up and heading out.</li> </ul> <p>You can find the lifecycle defined as a <code>KernelState</code> enum near the top of <code>kernel.py</code>. In Python, that looks like this:</p> <pre><code>class KernelState(StrEnum):\n    SHUTDOWN = \"shutdown\"\n    BOOTING = \"booting\"\n    RUNNING = \"running\"\n    SHUTTING_DOWN = \"shutting_down\"\n</code></pre>"},{"location":"concepts/kernel-and-syscalls/#2-before-the-kernel-the-boot-chain","title":"2. Before the Kernel: The Boot Chain","text":"<p>Before the kernel even starts, a bootloader does the hard work of checking the hardware and loading the kernel from disk. Think of it as the security guard and janitor preparing the school building before the principal arrives. The full boot chain is covered in the Boot Chain guide.</p> <p>In short: Firmware POST checks the hardware, the Bootloader loads the kernel image from disk, and then the kernel takes over.</p>"},{"location":"concepts/kernel-and-syscalls/#3-the-kernel-boot-sequence","title":"3. The Kernel Boot Sequence","text":"<p>When a school opens in the morning, things happen in a specific order. You can't let students in before the teachers arrive, and teachers can't teach before their classrooms are set up.</p> <p>Computers work the same way. When PyOS boots, the kernel initializes each subsystem one at a time, in a careful order. If you look at the <code>boot()</code> method in <code>kernel.py</code>, you'll see something like this:</p> <pre><code>0. Logger           -- Turn on the security cameras first\n                       (so everything that happens is recorded)\n1. Memory Manager   -- Set up the desks\n                       (everything needs somewhere to sit)\n1b. Slab Allocator  -- Set up the supply cupboards\n                       (fixed-size object pools for fast allocation)\n2. File System      -- Unlock the filing cabinets\n3. User Manager     -- Get the attendance list ready\n4. Environment      -- Post the daily schedule on the board\n5. Device Manager   -- Turn on the printers and projectors\n5b. DNS Resolver    -- Open the phone book (hostname -&gt; IP)\n5c. Socket Manager  -- Set up the phone lines (network stack)\n5d. Interrupt Controller + Timer\n                    -- Wire up the doorbells (hardware event dispatch)\n5e. TCP Stack       -- Set up reliable mail delivery between buildings\n6. Resource Manager -- Set up the rules for sharing supplies\n7. Sync Manager     -- Hand out the shared-equipment sign-out sheets\n                       (mutexes, semaphores, condition variables)\n7b. PI Manager      -- Turn on the \"no cutting in line\" rule\n                       (priority inheritance to prevent priority inversion)\n7c. Ordering Manager -- Post the \"walk forward only\" rule for lockers\n                       (resource ordering to prevent deadlock)\n8. Scheduler        -- Open the doors and let students in\n9. /proc Filesystem -- Turn on the magic bulletin board\n                       (live stats from all subsystems)\n10. Init Process    -- The vice principal sits at the front desk\n                       (first process, parent of all others)\n</code></pre> <p>Only after every single one of those steps is finished does the kernel switch its state to <code>RUNNING</code> -- and it also flips the CPU from kernel mode to user mode (more on that in section 8 below).</p> <p>The init process is special: it is the root of the process tree. Every process you create afterwards becomes a child of init. You can read more about init in the Boot Chain guide.</p>"},{"location":"concepts/kernel-and-syscalls/#why-does-order-matter","title":"Why does order matter?","text":"<p>Think about it: you can't unlock the filing cabinets if there aren't any desks to put them on (the file system needs memory). You can't let students into classrooms that haven't been set up yet (the scheduler needs everything else to be ready first). And you want the security cameras rolling before anything else happens, so you have a record of the entire boot.</p>"},{"location":"concepts/kernel-and-syscalls/#shutdown-is-the-reverse","title":"Shutdown is the reverse","text":"<p>When the school day ends, you don't turn off the security cameras first and then try to get the students out. That would be backwards. Instead:</p> <ul> <li>Students leave first (scheduler shuts down).</li> <li>Then devices are unregistered.</li> <li>Then users, environment, file system, and memory are cleaned up.</li> <li>The logger is the very last thing to go, so it can record the entire   shutdown.</li> </ul> <p>This \"last in, first out\" pattern shows up everywhere in computer science. You'll see it again when you learn about memory and stacks.</p>"},{"location":"concepts/kernel-and-syscalls/#4-system-calls","title":"4. System Calls","text":"<p>Now we know the kernel is in charge. But here's the problem: if a program (like a text editor or a game) needs something -- say, \"please save this file\" -- how does it ask?</p> <p>Programs are not allowed to just reach into the kernel and grab things directly. That would be like a student walking into the principal's office, opening the filing cabinets, and taking whatever they want. Chaos.</p> <p>Instead, there is a front desk.</p>"},{"location":"concepts/kernel-and-syscalls/#the-front-desk-analogy","title":"The front desk analogy","text":"<p>Imagine the principal's office has a front desk with a secretary. Students can't walk past the front desk. When they need something, they fill out a request form and hand it to the secretary. The secretary checks that the form is filled out correctly, then walks it to the right person in the office. When the work is done, the secretary brings the answer back to the student.</p> <p>In an OS, that front desk is the system call interface (or \"syscall interface\" for short). In PyOS, it lives in <code>syscalls.py</code>.</p>"},{"location":"concepts/kernel-and-syscalls/#how-it-works-in-pyos","title":"How it works in PyOS","text":"<p>Every request a program can make has a number. Think of it like a form number at the front desk:</p> <ul> <li>Form #1: \"Create a new process\" (start a new program running)</li> <li>Form #10: \"Create a new file\"</li> <li>Form #12: \"Read a file\"</li> <li>Form #30: \"Who am I?\" (which user is logged in?)</li> </ul> <p>When a program wants something, it calls <code>kernel.syscall()</code> with the right number and any details. For example, to create a file:</p> <pre><code>kernel.syscall(SyscallNumber.SYS_CREATE_FILE, path=\"/homework/essay.txt\")\n</code></pre> <p>Behind the scenes, the <code>dispatch_syscall()</code> function in <code>syscalls.py</code> looks up the number in a big table, finds the right handler function, and calls it. If something goes wrong, the program gets back a <code>SyscallError</code> -- a friendly error message, never the raw internal details of how the kernel works.</p>"},{"location":"concepts/kernel-and-syscalls/#the-full-list-of-syscall-numbers","title":"The full list of syscall numbers","text":"<p>Here is every syscall number in PyOS, grouped by what they do:</p> Numbers What they're for 1-8 Processes (create, terminate, list, fork, threads, wait, waitpid) 10-15 Files (create, create directory, read, write, delete, list) 20 Memory info 30-33 Users (who am I, create user, list users, switch user) 40-42 Devices (read, write, list) 50 View logs 60-61 Signal operations (send signal, register handler) 70-73 Environment variables (get, set, list, delete) 80 System info (like the <code>top</code> command) 90 Deadlock detection 91-93 Deadlock prevention (resource ordering) 100-101 Run programs (load and execute) 110-119, 122-125 Synchronization (mutexes, semaphores, conditions, reader-writer locks) 120-121 Scheduler operations (switch policy, MLFQ boost) 130-133 Journal operations (status, checkpoint, recover, crash) 140-146 Shared memory IPC (create, attach, detach, destroy, write, read, list) 150-154 DNS operations (register, lookup, remove, list, flush) 160-168 Socket operations (create, bind, listen, connect, accept, send, recv, close, list) 170-171 /proc virtual filesystem (read, list) 172 Performance metrics (read) 180-183 Strace operations (enable, disable, log, clear) 190-203 Kernel-mode helpers (shutdown, scheduler info, lstat, list mutexes/semaphores/rwlocks, list fds, list resources, PI status, ordering violations, destroy mutex, dispatch, process info, strace status) 210-211 Boot info (dmesg boot log, boot metadata) 220-224 Multi-CPU operations (cpu info, set/get affinity, balance, migrate) 230-235 Interrupt and timer operations (tick, interrupt list/mask/unmask, timer info/set interval) 240-247 TCP operations (connect, send, recv, close, info, list, listen, accept) <p>You don't need to memorize these. The important thing is that every single operation a program can ask for has a number, and every single request goes through the same front desk.</p>"},{"location":"concepts/kernel-and-syscalls/#what-a-syscall-handler-looks-like","title":"What a syscall handler looks like","text":"<p>Here is a simplified version of the \"who am I?\" handler from <code>syscalls.py</code>:</p> <pre><code>def _sys_whoami(kernel, **kwargs):\n    \"\"\"Return the current user's info.\"\"\"\n    user = kernel.user_manager.get_user(kernel.current_uid)\n    return {\"uid\": user.uid, \"username\": user.username}\n</code></pre> <p>That's it. The front desk receives form #30 (\"who am I?\"), calls this function, and hands the answer back to the program. The program never had to touch the user manager directly.</p>"},{"location":"concepts/kernel-and-syscalls/#5-why-have-system-calls-at-all","title":"5. Why Have System Calls at All?","text":"<p>You might be thinking: \"This seems like a lot of extra work. Why not just let programs talk to the kernel directly?\"</p> <p>Great question. Here's why, using our school analogy:</p> <p>Security. If students could walk into the principal's office and grab whatever they wanted, someone could steal test answers or change their grades. System calls make sure every request is checked before it's granted. A program can't read a file it doesn't have permission to read.</p> <p>Rules. Every request goes through the same front desk, so you can check for mistakes in one place. If a program asks to read a file that doesn't exist, the syscall layer catches that and returns a clean error instead of crashing the entire OS.</p> <p>Privacy. Students don't need to know how the filing cabinets are organized inside the office. They just fill out a form and get a result. Similarly, programs don't need to know how the file system stores data internally. This means the kernel team can completely rewrite the file system, and as long as the forms (syscalls) stay the same, no program needs to change.</p> <p>Logging. The front desk can write down every request in a logbook. In PyOS, every syscall is recorded by the logger. This is incredibly useful for debugging (\"wait, when did that file get deleted?\") and for security (\"who tried to switch users at 3am?\").</p>"},{"location":"concepts/kernel-and-syscalls/#6-tying-it-all-together","title":"6. Tying It All Together","text":"<p>Here is the full picture of how a request flows through the system:</p> <pre><code>You type a command\n        |\n        v\n   [The Shell]          interprets what you typed\n        |\n        v\n   [System Call]        fills out the right form (syscall number + args)\n        |\n        v\n   [Kernel]             the principal's office does the work\n   |    |    |\n   v    v    v\nMemory Files Scheduler  ...and all the other subsystems\n</code></pre> <p>The shell is where you talk to the OS (see The Shell). System calls are the only way the shell -- or any program -- can ask the kernel to do something. And the kernel coordinates all the subsystems to make it happen.</p>"},{"location":"concepts/kernel-and-syscalls/#7-tracing-system-calls-with-strace","title":"7. Tracing System Calls with strace","text":"<p>Imagine you're sitting in a restaurant, and your food just magically appears. You have no idea what happened in the kitchen. What ingredients were used? What order were the steps done in? Did anything go wrong along the way?</p> <p>strace is like standing in the kitchen with a clipboard. Every time the chef (your program) asks an assistant (the kernel) for something -- \"Get me flour,\" \"Turn on the oven,\" \"Plate the pasta\" -- you write it down. You also write down what the assistant gives back: \"Here's the flour,\" \"Oven is on,\" or \"Error: we're out of pasta.\"</p> <p>In real Linux, <code>strace</code> intercepts every system call a program makes and shows you a log like this:</p> <pre><code>open(\"/etc/passwd\", O_RDONLY) = 3\nread(3, \"root:x:0:0...\", 4096) = 1024\nclose(3) = 0\n</code></pre> <p>PyOS has its own strace. When you turn it on, every syscall gets recorded: the syscall name, the arguments, and what came back (or if there was an error).</p>"},{"location":"concepts/kernel-and-syscalls/#using-strace-in-the-shell","title":"Using strace in the shell","text":"<pre><code>$ strace on\nStrace enabled.\n$ ls /\nbin  home  tmp\n--- strace ---\n#1 SYS_LIST_DIR(path=\"/\") = [\"bin\", \"home\", \"tmp\"]\n$ strace off\nStrace disabled.\n</code></pre> <p>The <code>--- strace ---</code> section appears automatically after every command when strace is on. Each entry has a sequence number (<code>#1</code>, <code>#2</code>, ...), the syscall name, the arguments, and the return value (or <code>ERROR:</code> if it failed).</p> <p>Other strace commands: - <code>strace show</code> -- display all captured entries so far - <code>strace clear</code> -- wipe the log and start fresh - <code>strace demo</code> -- a guided walkthrough that shows strace in action</p>"},{"location":"concepts/kernel-and-syscalls/#why-is-strace-useful","title":"Why is strace useful?","text":"<p>When something goes wrong and you can't figure out why, strace shows you exactly what happened step by step. Did a file not exist? Did a permission check fail? Was the wrong path used? The trace log tells you.</p> <p>It's also a fantastic learning tool. If you're curious what <code>ls</code> actually does behind the scenes, just turn on strace and watch. You'll see every syscall the shell makes to produce the output.</p>"},{"location":"concepts/kernel-and-syscalls/#how-it-works-inside-the-kernel","title":"How it works inside the kernel","text":"<p>The kernel's <code>syscall()</code> method is the single gateway for all requests. When strace is enabled, the kernel wraps each syscall dispatch: it calls the handler, captures the result (or error), formats a log entry with the syscall name, arguments, and return value, and appends it to a ring buffer (capped at 1,000 entries).</p> <p>Strace management syscalls (enable, disable, log, clear) and the read-log syscall are excluded from tracing to avoid infinite loops and noise.</p>"},{"location":"concepts/kernel-and-syscalls/#strace-syscall-numbers","title":"Strace syscall numbers","text":"Number Name What it does 180 SYS_STRACE_ENABLE Turn on syscall tracing 181 SYS_STRACE_DISABLE Turn off tracing (log is kept) 182 SYS_STRACE_LOG Read the current trace entries 183 SYS_STRACE_CLEAR Clear the log and reset the counter"},{"location":"concepts/kernel-and-syscalls/#8-user-mode-vs-kernel-mode","title":"8. User Mode vs Kernel Mode","text":"<p>Imagine your security badge at a building. Most of the time your badge is blue (user mode) -- you can enter the lobby and talk to the front desk, but you can't open the door to the server room. When you make a system call, the badge flips to red (kernel mode) -- now you can enter the server room and do whatever the request asks for. The moment the system call finishes, your badge flips right back to blue.</p> <p>In a real CPU, this protection is built into the hardware using privilege rings:</p> <pre><code>Ring 0 (kernel mode) -- full access to hardware and memory\nRing 3 (user mode)   -- restricted, can only ask the kernel for help\n</code></pre> <p>User programs always run in ring 3. They can't read the kernel's memory, they can't talk to hardware directly, and they can't touch the scheduler or filesystem structures. The only way to do any of those things is to make a system call, which temporarily switches the CPU to ring 0, runs the handler, and switches back.</p>"},{"location":"concepts/kernel-and-syscalls/#how-pyos-enforces-this","title":"How PyOS enforces this","text":"<p>PyOS has an <code>ExecutionMode</code> enum with two values:</p> <pre><code>class ExecutionMode(StrEnum):\n    USER = \"user\"\n    KERNEL = \"kernel\"\n</code></pre> <p>When the kernel boots, it starts in kernel mode (the janitor is setting up the building, so they need full access). At the very end of <code>boot()</code>, the mode flips to user mode -- the doors are open, and normal rules apply.</p> <p>Every sensitive kernel property (scheduler, memory, filesystem, processes, etc.) has a guard at the top:</p> <pre><code>@property\ndef scheduler(self):\n    self._require_kernel_mode()   # raises KernelModeError if in USER mode\n    return self._scheduler\n</code></pre> <p>If the shell (or any other user-space code) tries to reach past the front desk and grab the scheduler directly, they'll get a <code>KernelModeError</code>. The only way to get scheduler information is through the proper syscall:</p> <pre><code>kernel.syscall(SyscallNumber.SYS_SCHEDULER_INFO)\n</code></pre> <p>Inside <code>syscall()</code>, the kernel temporarily switches to kernel mode (flips the badge to red), runs the handler, and switches back (flips it to blue again). This is done with a context manager that always restores the previous mode, even if the handler crashes:</p> <pre><code>with self._kernel_mode():\n    result = dispatch_syscall(self, number, **kwargs)\n</code></pre>"},{"location":"concepts/kernel-and-syscalls/#why-bother","title":"Why bother?","text":"<p>Without this enforcement, nothing stops a programmer from writing <code>kernel.filesystem.create_file(...)</code> directly in the shell. It works, but it's cheating -- it bypasses all the safety checks, logging, and error wrapping that the syscall layer provides. With mode enforcement turned on:</p> <ul> <li>Every access goes through syscalls. No shortcuts, no backdoors.</li> <li>Bugs are caught early. If you accidentally access a kernel resource   from user-space code, you get an immediate, clear error message instead of   a subtle data corruption later.</li> <li>The architecture matches reality. Real operating systems enforce this   boundary in hardware. PyOS enforces it in software, but the principle is   the same.</li> </ul>"},{"location":"concepts/kernel-and-syscalls/#kernel-mode-helper-syscalls","title":"Kernel-mode helper syscalls","text":"<p>To replace every direct kernel access in the shell, PyOS added 14 new syscalls in the 190-203 range:</p> Number Name What it does 190 SYS_SHUTDOWN Shut down the kernel cleanly 191 SYS_SCHEDULER_INFO Return the current scheduling policy name 192 SYS_LSTAT Get file metadata (without following symlinks) 193 SYS_LIST_MUTEXES List all mutexes with locked/owner state 194 SYS_LIST_SEMAPHORES List all semaphores with their counts 195 SYS_LIST_RWLOCKS List all reader-writer locks with state 196 SYS_LIST_FDS List open file descriptors for a process 197 SYS_LIST_RESOURCES List resources managed by the deadlock detector 198 SYS_PI_STATUS Priority inheritance status and boosted processes 199 SYS_ORDERING_VIOLATIONS List resource ordering violations 200 SYS_DESTROY_MUTEX Destroy a named mutex 201 SYS_DISPATCH Dispatch the next process from the scheduler 202 SYS_PROCESS_INFO Get details about a single process 203 SYS_STRACE_STATUS Check whether strace is currently enabled"},{"location":"concepts/kernel-and-syscalls/#where-to-go-next","title":"Where to Go Next","text":"<ul> <li>What Is an Operating System? -- Start here if you haven't already</li> <li>Processes -- How the OS runs programs and shares the processor</li> <li>Memory -- How the OS hands out and protects memory</li> <li>Filesystem -- How files and folders are organized and stored</li> <li>The Shell -- Your command-line interface to the OS</li> <li>Devices and Networking -- How the OS talks to hardware and the internet</li> <li>Users and Safety -- How the OS keeps users and their data separate</li> </ul>"},{"location":"concepts/memory/","title":"Memory: How the OS Hands Out and Protects Memory","text":"<p>When a process runs, it needs somewhere to keep its stuff -- the variables it's working with, the instructions it's executing, the data it loaded from a file. That \"somewhere\" is memory (specifically, RAM -- the fast, temporary storage your computer uses while it's on).</p> <p>But here's the problem: lots of processes are running at the same time, and they all need memory. Somebody has to hand it out fairly, keep everyone's stuff separate, and deal with the situation when there's not enough to go around.</p> <p>That somebody is the OS.</p> <p>In PyOS, memory management is split into three files, each handling a different piece of the puzzle. Let's walk through them one at a time.</p>"},{"location":"concepts/memory/#1-physical-memory-memorymanagerpy","title":"1. Physical Memory (<code>memory/manager.py</code>)","text":""},{"location":"concepts/memory/#the-locker-analogy","title":"The Locker Analogy","text":"<p>Imagine a long hallway of school lockers. Every locker is exactly the same size, and they're numbered 0, 1, 2, 3, and so on. When a new student (a process) shows up at school, the principal (the OS) assigns them some lockers to store their stuff in.</p> <p>In OS terms, each locker is called a frame, and the chunk of data that fits inside one frame is called a page. Pages and frames are the same size -- think of a page as the stuff, and a frame as the locker it goes into.</p>"},{"location":"concepts/memory/#why-fixed-sizes","title":"Why Fixed Sizes?","text":"<p>You might wonder: why make every locker the same size? Why not have some big lockers and some small ones?</p> <p>Here's why. Imagine a hallway where lockers come in all different sizes. Over time, as students come and go, you end up with a bunch of tiny gaps scattered all over the hallway. You might have 10 small gaps, but none of them is big enough for a new student who needs a medium locker. This problem is called fragmentation -- you technically have free space, but it's chopped up into useless little pieces.</p> <p>Fixed-size lockers avoid this entirely. A free locker is a free locker. Any page fits in any frame. Simple.</p>"},{"location":"concepts/memory/#what-happens-when-a-process-finishes","title":"What Happens When a Process Finishes?","text":"<p>When a process is done running, the OS takes back all of its lockers and marks them as free. Now those frames are available for the next process that needs them. Nothing is wasted.</p>"},{"location":"concepts/memory/#what-if-all-the-lockers-are-full","title":"What If All the Lockers Are Full?","text":"<p>If every single frame is in use and a new process asks for memory, the OS has a choice: it can either refuse (raising an OutOfMemoryError, which crashes that process) or it can try to make room using swap space, which we'll get to in a moment.</p>"},{"location":"concepts/memory/#2-virtual-memory-memoryvirtualpy","title":"2. Virtual Memory (<code>memory/virtual.py</code>)","text":""},{"location":"concepts/memory/#the-personal-map-analogy","title":"The Personal Map Analogy","text":"<p>Here's where things get clever.</p> <p>Every student gets their own personal map of the locker hallway. On this map, it says things like:</p> <ul> <li>\"My locker 0 is actually real locker #47\"</li> <li>\"My locker 1 is actually real locker #12\"</li> <li>\"My locker 2 is actually real locker #83\"</li> </ul> <p>The student only ever sees their own simple numbering -- 0, 1, 2, 3 -- even though their actual lockers are scattered all over the hallway. The student doesn't need to know or care where the real lockers are. They just say \"open my locker 2,\" and the OS quietly translates that into \"go to real locker #83.\"</p> <p>This personal map is called a page table, and the simple numbering the student sees is called a virtual address. The real, physical locker number is the physical address.</p>"},{"location":"concepts/memory/#address-translation","title":"Address Translation","text":"<p>When a process says \"I want the data at my page 3, position 5,\" the OS does this:</p> <ol> <li>Look up page 3 in that process's page table.</li> <li>The page table says: \"Page 3 maps to frame #20.\"</li> <li>Go to frame #20 in physical memory and find position 5.</li> </ol> <p>That's it. The process said \"page 3, position 5\" and the OS translated it to \"frame 20, position 5.\" This translation happens every single time a process touches memory, and it's fast because the hardware helps out.</p>"},{"location":"concepts/memory/#isolation-keeping-students-apart","title":"Isolation: Keeping Students Apart","text":"<p>Here's the really important part. Student A and Student B both think they have a \"locker 0.\" But Student A's locker 0 points to real locker #47, while Student B's locker 0 points to real locker #91. They're completely different physical lockers.</p> <p>This means Student A can never accidentally (or intentionally) read or overwrite Student B's data. Each process lives in its own little world, with its own private numbering, completely unaware of what other processes are doing. This separation is called isolation, and it's one of the most important jobs of the OS.</p>"},{"location":"concepts/memory/#page-faults","title":"Page Faults","text":"<p>What happens if a student tries to open a locker that isn't on their map at all? Maybe they ask for \"my locker 99\" but their map only goes up to locker 5.</p> <p>That's called a page fault. The OS catches it and says, \"Hey, you don't have a locker 99.\" Depending on the situation, the OS might load the missing page from disk (more on that below), or it might just stop the process with an error because it tried to access memory it doesn't own.</p>"},{"location":"concepts/memory/#3-page-replacement-and-swap-memoryswappy","title":"3. Page Replacement and Swap (<code>memory/swap.py</code>)","text":""},{"location":"concepts/memory/#the-basement-storage-room","title":"The Basement Storage Room","text":"<p>OK, so what happens when all the lockers in the hallway are full, but a new student still needs one?</p> <p>The OS has a trick: there's a storage room in the basement. In real computers, this \"basement\" is your hard drive or SSD -- it's much slower than RAM, but there's a lot more of it. This system is called swap space.</p> <p>Here's how it works:</p> <ol> <li>The OS picks a locker that's currently in use.</li> <li>It moves everything from that locker down to the basement storage room.</li> <li>Now that locker is empty, so the OS gives it to the new student.</li> <li>Later, when the original owner needs their stuff back, the OS finds another    locker to free up, brings the stuff back from the basement, and the process    continues like nothing happened.</li> </ol> <p>The tricky part is step 1: which locker do you pick? You want to pick one that won't be needed again soon, so you don't have to keep shuffling things back and forth between the hallway and the basement. That shuffling is slow, and too much of it (called thrashing) makes the whole computer grind to a halt.</p>"},{"location":"concepts/memory/#three-strategies-for-picking-a-locker","title":"Three Strategies for Picking a Locker","text":""},{"location":"concepts/memory/#fifo-first-in-first-out","title":"FIFO -- First In, First Out","text":"<p>The simplest idea: empty whichever locker has had the same stuff in it the longest. If locker #12 was filled first, it gets emptied first.</p> <p>This is easy to implement -- you just keep a list in order. But it's not always smart. Sometimes the oldest stuff is actually the stuff you use the most. Imagine emptying the locker of the student who visits it every single period just because they got it a long time ago. Not great.</p>"},{"location":"concepts/memory/#lru-least-recently-used","title":"LRU -- Least Recently Used","text":"<p>A smarter idea: empty the locker that nobody has opened in the longest time. If locker #7 hasn't been touched in three hours but locker #12 was opened five minutes ago, empty locker #7.</p> <p>This usually makes better choices than FIFO, because stuff that hasn't been used in a while probably won't be used again soon. The downside? You have to keep track of every single time someone opens a locker, which takes extra work and extra bookkeeping.</p>"},{"location":"concepts/memory/#clock-second-chance","title":"Clock -- Second Chance","text":"<p>This is the clever compromise that most real operating systems actually use.</p> <p>Picture a clock hand sweeping around a circle of lockers. Each locker has a tiny flag -- a single bit that means \"I was used recently.\"</p> <p>When the OS needs to free a locker, the clock hand starts sweeping:</p> <ol> <li>It looks at the locker it's pointing to.</li> <li>If the flag is up (\"I was used recently!\"), the OS puts the flag down    and moves the hand to the next locker. That locker gets a second chance.</li> <li>If the flag is down (\"I haven't been used in a while\"), the OS empties    that locker and uses it.</li> </ol> <p>The clock hand keeps going around and around, like the hand of an actual clock. Any locker that gets used has its flag set back up. So the only lockers that get emptied are the ones that haven't been used since the last time the hand came around.</p> <p>This is nearly as smart as LRU -- it avoids emptying recently-used lockers -- but it's much simpler because you only need one flag per locker instead of a full history of every access.</p>"},{"location":"concepts/memory/#demand-paging","title":"Demand Paging","text":"<p>There's one more idea worth knowing about: demand paging.</p> <p>When a process starts up, the OS doesn't immediately load all of its pages into memory. That would be wasteful -- maybe the process has a ton of data but only uses a small piece of it right away. Instead, the OS waits.</p> <p>When the process actually tries to read a page that isn't in memory yet, a page fault happens. But this time it's not an error -- it's expected. The OS says, \"Oh, you need that page? Hold on.\" It pauses the process, loads the page from disk into a free frame (evicting another page if necessary), updates the page table, and then lets the process continue. The process doesn't even know it was paused.</p> <p>This \"load it only when you need it\" approach is called demand paging, and it means programs can start faster and use less memory overall, because they only occupy frames for the pages they're actually using right now.</p>"},{"location":"concepts/memory/#4-copy-on-write-cow","title":"4. Copy-on-Write (COW)","text":""},{"location":"concepts/memory/#the-shared-notebook-analogy","title":"The Shared Notebook Analogy","text":"<p>Imagine two students, Alice and Bob, are both studying from the same textbook. Instead of photocopying the whole book for Bob (slow and wasteful), the teacher says: \"Just share. You're both reading the same pages anyway.\"</p> <p>But there's a catch -- if Bob wants to scribble notes in the margin, he can't do it on the shared copy or he'd mess up Alice's book too. So the rule is: the first person to write on a page gets a photocopy of just that one page. Now Bob has his own copy to scribble on, and Alice's page is untouched. If neither of them ever writes, no copies are ever needed. Free sharing!</p> <p>This is copy-on-write (COW), and it's one of the cleverest tricks in operating systems.</p>"},{"location":"concepts/memory/#why-does-this-matter","title":"Why Does This Matter?","text":"<p>When a process forks (creates a child), the child needs its own copy of the parent's memory. The naive approach is to copy every single page immediately -- but that's wasteful. Many forked processes immediately call <code>exec()</code> to load a completely different program, throwing away all those copies before they're even read.</p> <p>With COW: 1. Fork is nearly free -- parent and child point to the same physical    frames. No copying happens. 2. Reads are shared -- both processes read from the same frames. No extra    memory used. 3. Writes trigger a copy -- only the page being written gets duplicated.    The writer gets a private copy; the other process keeps the original.</p>"},{"location":"concepts/memory/#how-it-works-under-the-hood","title":"How It Works Under the Hood","text":"<ol> <li>At fork time, the kernel marks all shared pages as COW-protected and    bumps a reference count on each physical frame (from 1 to 2).</li> <li>On read, nothing special happens. Both processes read the same data from    the same frame.</li> <li>On write, the virtual memory system detects the COW flag and triggers a    fault handler. The handler:</li> <li>Allocates a brand-new frame.</li> <li>Copies the data from the shared frame to the new one.</li> <li>Updates the writer's page table to point to the new frame.</li> <li>Decrements the old frame's reference count.</li> <li>Clears the COW flag on that page (it's now private).</li> <li>When refcount hits 0, the frame goes back to the free pool.</li> </ol>"},{"location":"concepts/memory/#reference-counting","title":"Reference Counting","text":"<p>The memory manager keeps a counter for each frame: \"how many processes are using this frame right now?\" When a frame is first allocated, the count is 1. When fork shares it, the count goes to 2. If three processes share it (A forks B, then B forks C), the count is 3. Each termination or COW copy decrements the count. The frame is only truly freed when the count reaches 0.</p>"},{"location":"concepts/memory/#5-memory-mapped-files-mmap","title":"5. Memory-Mapped Files (mmap)","text":""},{"location":"concepts/memory/#the-open-textbook-analogy","title":"The Open Textbook Analogy","text":"<p>Imagine you're doing homework and need to look something up in a textbook. The normal way is to grab the book, photocopy the pages you need, put the copies on your desk, read and scribble on them, and later copy your changes back into the book. That's a lot of steps!</p> <p>Memory-mapped files are like opening the textbook and laying it flat on your desk. Instead of photocopying pages, you read and write directly on the open book. No copying back and forth -- the book is right there.</p> <p>In OS terms, <code>mmap</code> takes a file and makes it appear as if it's part of a process's memory. The process can read and write those memory addresses, and the OS handles moving data between the file and RAM automatically.</p>"},{"location":"concepts/memory/#two-modes-private-vs-shared","title":"Two Modes: Private vs Shared","text":""},{"location":"concepts/memory/#map_private-your-own-photocopy","title":"MAP_PRIVATE -- Your own photocopy","text":"<p>With MAP_PRIVATE, the OS hands you your own copy of the pages. You can scribble all over them, but your changes stay with you -- the original book is untouched. This is useful when a process needs to read file data into memory but doesn't want to modify the actual file.</p> <p>When a process forks, private mmap pages get the same copy-on-write treatment as regular memory pages -- parent and child share until one of them writes.</p>"},{"location":"concepts/memory/#map_shared-everyone-reads-the-same-book","title":"MAP_SHARED -- Everyone reads the same book","text":"<p>With MAP_SHARED, multiple processes all look at the same physical pages. If one process writes \"HELLO\" at the top of page 3, every other process mapping that same file immediately sees \"HELLO\" there too -- because they're all looking at the same underlying memory.</p> <p>This is powerful for communication between processes. Instead of sending messages back and forth, they can just read and write the same shared memory.</p> <p>When a process forks, shared mmap pages are not marked copy-on-write. Writes by the parent or child should be visible to the other -- that's the whole point of \"shared.\"</p>"},{"location":"concepts/memory/#msync-saving-your-work","title":"msync -- Saving Your Work","text":"<p>Shared mappings live in memory, but the actual file on disk doesn't update automatically. When you want to make sure your changes are saved to the file, you call <code>msync</code> -- think of it as pressing \"Save.\" The OS takes whatever is in the shared memory pages and writes it back to the file.</p> <p>When a process unmaps a shared region (or terminates), the OS does an automatic msync to make sure nothing is lost.</p>"},{"location":"concepts/memory/#how-it-works-under-the-hood_1","title":"How It Works Under the Hood","text":"<ol> <li> <p>mmap -- The kernel reads the file data, allocates physical frames, copies    the data into those frames, and maps them into the process's virtual address    space. For shared mappings, a second process mapping the same file reuses the    same frames (zero extra allocation).</p> </li> <li> <p>Read/write -- The process just reads and writes memory addresses like    normal. For private mappings, changes stay local. For shared mappings,    changes are visible to all sharers.</p> </li> <li> <p>munmap -- Removes the mapping. For shared regions, data is written back    to the file first. Frames are released and reference counts updated.</p> </li> <li> <p>msync -- Writes shared data back to the file without removing the    mapping. Like saving a document without closing it.</p> </li> </ol>"},{"location":"concepts/memory/#6-slab-allocator-memoryslabpy","title":"6. Slab Allocator (<code>memory/slab.py</code>)","text":""},{"location":"concepts/memory/#the-supply-closet-analogy","title":"The Supply Closet Analogy","text":"<p>Imagine the school warehouse full of big storage crates (frames). Every time a teacher needs a single pencil, they get an entire crate. That's a huge waste of space!</p> <p>A slab allocator is like setting up a supply closet. You take one crate from the warehouse and divide it into little compartments -- one pencil per compartment. Now when a teacher needs a pencil, they grab one from the supply closet in a split second. When they're done, they put it back. No waste, no waiting.</p> <p>Each supply closet handles one type of item. The \"pencil closet\" has pencil-sized compartments, the \"eraser closet\" has eraser-sized ones. In OS terms, each closet is a slab cache, each compartment is a slot, and the crate backing it is a slab (one physical frame).</p>"},{"location":"concepts/memory/#why-not-just-use-frames","title":"Why Not Just Use Frames?","text":"<p>The memory manager allocates in whole frames (256 bytes each). But kernel objects like process control blocks (PCBs, ~64 bytes) and inodes (~48 bytes) are much smaller. If you use a whole frame for each one, you waste 75-80% of the space. Multiply that by hundreds of objects and the waste adds up fast.</p> <p>A slab allocator solves this by packing many small objects into a single frame. A 256-byte frame with 64-byte slots holds 4 PCBs. Same space, four times the capacity.</p>"},{"location":"concepts/memory/#the-three-level-hierarchy","title":"The Three-Level Hierarchy","text":"<p>The slab allocator has three levels, from bottom to top:</p> <ol> <li> <p>Slab -- one physical frame divided into equal-sized slots. A slab for    64-byte objects has 4 slots (256 / 64). It tracks which slots are free using    a simple stack: pop to allocate, push to free. Both operations are O(1) --    constant time, no matter how many slots there are.</p> </li> <li> <p>Slab Cache -- a pool of slabs, all for the same object size. The \"pcb\"    cache might have three slabs (three frames), giving 12 total slots for PCBs.    When all slabs are full, the cache auto-grows by requesting another frame    from the memory manager.</p> </li> <li> <p>Slab Allocator -- a registry of named caches. The kernel creates caches    for each type of object it needs: \"pcb\" for process control blocks, \"inode\"    for filesystem metadata, and so on. User code talks to the allocator by    cache name.</p> </li> </ol>"},{"location":"concepts/memory/#how-allocation-works","title":"How Allocation Works","text":"<p>When the kernel needs a new PCB:</p> <ol> <li>It asks the slab allocator for an object from the \"pcb\" cache.</li> <li>The allocator finds the \"pcb\" slab cache.</li> <li>The cache scans its slabs for one with free space.</li> <li>If a slab has a free slot, it pops the slot index from its free stack.    Done!</li> <li>If all slabs are full, the cache asks the memory manager for a new frame,    creates a new slab, and allocates from that.</li> </ol> <p>The result is a handle: <code>(slab_index, slot_index)</code> -- exactly which frame and which slot your object lives in. It's transparent and inspectable, which makes it great for learning.</p>"},{"location":"concepts/memory/#auto-growing","title":"Auto-Growing","text":"<p>When all slabs in a cache are full and a new allocation comes in, the cache automatically requests another frame from the memory manager. This is like the supply closet running out of pencils -- you grab another crate from the warehouse and add more compartments.</p> <p>In real operating systems, slab allocators can also shrink by returning empty slabs back to the page allocator. Our simulator keeps things simple and doesn't reclaim empty slabs.</p>"},{"location":"concepts/memory/#how-it-works-under-the-hood_2","title":"How It Works Under the Hood","text":"<ol> <li> <p>At boot, the kernel creates a <code>SlabAllocator</code> backed by the memory    manager. It pre-registers caches for common objects (\"pcb\" at 64 bytes,    \"inode\" at 48 bytes).</p> </li> <li> <p>On allocate, the cache pops a free slot index from one of its slabs.    If no slab has space, it requests a new frame and creates a new slab.</p> </li> <li> <p>On free, the slot index is pushed back onto the slab's free stack.    The slot is immediately available for the next allocation.</p> </li> <li> <p>On destroy, all backing frames are returned to the memory manager.</p> </li> </ol>"},{"location":"concepts/memory/#putting-it-all-together","title":"Putting It All Together","text":"<p>Here's how these pieces work as a team:</p> <ol> <li> <p>Physical memory (<code>memory/manager.py</code>) manages the actual frames -- the real    lockers in the hallway. It tracks which ones are free and which ones are    taken.</p> </li> <li> <p>Virtual memory (<code>memory/virtual.py</code>) gives each process its own private    map (page table) so that processes see clean, simple addresses and can't    interfere with each other.</p> </li> <li> <p>Swap (<code>memory/swap.py</code>) handles the overflow. When memory is full, it moves    pages to disk and brings them back when needed, using a replacement strategy    (FIFO, LRU, or Clock) to decide what to move.</p> </li> <li> <p>Slab allocator (<code>memory/slab.py</code>) sits on top of the frame allocator and    subdivides frames into small, fixed-size slots for kernel objects. It    eliminates waste when many tiny objects need their own space.</p> </li> </ol> <p>Together, they create the illusion that every process has its own big, private chunk of memory -- even if the physical RAM is small and shared among many processes. That illusion is one of the most powerful tricks in all of computing.</p>"},{"location":"concepts/memory/#where-to-go-next","title":"Where to Go Next","text":"<ul> <li>Processes -- How the OS runs programs and shares the processor</li> <li>What Is an OS? -- The big picture of how an OS works</li> <li>Filesystem -- How files and folders are organized and stored</li> </ul>"},{"location":"concepts/processes/","title":"Processes","text":"<p>Everything your computer does -- running a game, playing music, loading a web page -- happens inside a process. This page explains what processes are, how they take turns using the CPU, and how they are born, run, and finish.</p>"},{"location":"concepts/processes/#what-is-a-process","title":"What is a Process?","text":"<p>A program is a set of instructions sitting in a file, like a homework assignment printed on paper. It does not do anything on its own. A process is what happens when someone actually starts working on that assignment.</p> <p>Think of it this way. The assignment sheet is the program. But a student sitting at their desk, pencil in hand, page open, halfway through question three -- that is the process. The process is a program in action, with all of its current progress attached.</p> <p>Here is the important part: multiple students can work on the same assignment at the same time. Each student has their own desk, their own pencil, and their own progress. In the same way, you can launch the same program multiple times and get multiple independent processes.</p>"},{"location":"concepts/processes/#the-process-control-block-pcb","title":"The Process Control Block (PCB)","text":"<p>The operating system needs to keep track of every process. It does this with a data structure called the Process Control Block, or PCB.</p> <p>Think of it like a profile card the teacher keeps for every student:</p> Field What it tracks Example PID A unique ID number <code>pid=3</code> Name What the process is called <code>\"web_browser\"</code> State What the process is doing right now <code>RUNNING</code> Priority How important it is <code>priority=5</code> Parent PID Which process created this one <code>parent_pid=1</code> <p>In PyOS, the <code>Process</code> class is the PCB. When the kernel creates a process, it fills in all of these fields and keeps the Process object in a table so it can find it later.</p> <p>Every process also gets its own virtual memory -- a private chunk of memory that no other process can see or touch.</p>"},{"location":"concepts/processes/#the-five-states","title":"The Five States","text":"<p>A process is not always running. Most of the time, it is waiting for its turn. Every process moves through up to five states during its life:</p> <pre><code>NEW --&gt; READY &lt;--&gt; RUNNING --&gt; TERMINATED\n                    |   ^\n                    v   |\n                  WAITING\n</code></pre> <p>Think of a classroom where only one student can use the whiteboard at a time.</p> <p>NEW -- The student just arrived at school. They are registered, but they have not joined the line for the whiteboard yet. In PyOS, a process starts in NEW and moves to READY when it is admitted to the scheduler.</p> <p>READY -- The student is in line, waiting for their turn at the whiteboard. They are ready to work, but someone else is up there right now. The scheduler's ready queue holds all the READY processes.</p> <p>RUNNING -- The student is at the whiteboard, doing their work. Only one process can be RUNNING at a time (on a single CPU). This is the process that currently \"has\" the CPU.</p> <p>WAITING -- The student stepped out of the classroom to grab a book from the library. They cannot continue until they get the book back. In OS terms, the process is blocked on something -- maybe waiting for a file to be read from disk, or waiting for a network response. When the thing it is waiting for happens, the process moves back to READY and rejoins the line.</p> <p>TERMINATED -- The student finished their work and left the classroom. The process is done. The kernel cleans up its memory. If the process has a living parent, it stays in the process table as a zombie until the parent collects its exit code. Otherwise it is removed immediately.</p>"},{"location":"concepts/processes/#transitions","title":"Transitions","text":"<p>Each arrow in the diagram is a specific method call in PyOS:</p> Transition Method What triggers it NEW to READY <code>admit()</code> Scheduler accepts the process READY to RUNNING <code>dispatch()</code> Scheduler picks this process to run RUNNING to READY <code>preempt()</code> Time is up, back to the line RUNNING to WAITING <code>wait()</code> Process needs something (I/O, event) WAITING to READY <code>wake()</code> The thing it needed is ready RUNNING to TERMINATED <code>terminate()</code> Process finished normally Any alive state to TERMINATED <code>force_terminate()</code> SIGKILL -- forced shutdown <p>These transitions are strict. You cannot dispatch a process that is not READY, and you cannot terminate a process that is not RUNNING (unless you use <code>force_terminate()</code>, which is the emergency SIGKILL path). If you try, PyOS raises a <code>RuntimeError</code>. Real operating systems enforce similar rules in their kernel code.</p>"},{"location":"concepts/processes/#the-scheduler","title":"The Scheduler","text":"<p>So who decides which READY process gets to be RUNNING? That is the scheduler. Think of the scheduler as the teacher deciding whose turn it is at the whiteboard.</p> <p>The scheduler has a ready queue -- the line of students waiting. When the whiteboard is free, the scheduler picks the next student based on some rule. Different rules give different results.</p>"},{"location":"concepts/processes/#fcfs-first-come-first-served","title":"FCFS (First Come, First Served)","text":"<p>The simplest rule: whoever got in line first goes first. The scheduler picks the process at the front of the queue, and that process runs until it finishes or voluntarily gives up the CPU.</p> <p>This is fair in a basic sense, but it has a problem called the convoy effect. Imagine one student has a 45-minute project and three students behind them each have a 30-second question. Everyone waits 45 minutes for one slow task to finish. Not great.</p>"},{"location":"concepts/processes/#round-robin","title":"Round Robin","text":"<p>A fairer rule: each student gets a fixed amount of time at the whiteboard (say, 2 minutes). When their time is up, they go to the back of the line, and the next student steps up. Everyone gets a turn, no one hogs the whiteboard forever.</p> <p>In PyOS, the amount of time each process gets is called the quantum. The <code>RoundRobinPolicy</code> stores this value, and the scheduler preempts (pulls back) the running process when its quantum expires. This preemption is driven by the hardware timer -- a device that fires an interrupt every few ticks. When the interrupt fires, the kernel checks whether the current process has used up its quantum and, if so, switches to the next one.</p> <pre><code># Round Robin with a quantum of 3 ticks\npolicy = RoundRobinPolicy(quantum=3)\nscheduler = Scheduler(policy=policy)\n</code></pre>"},{"location":"concepts/processes/#priority-scheduling","title":"Priority Scheduling","text":"<p>What if some tasks are more important than others? In a hospital emergency room, a patient with a broken arm is seen before someone with a splinter, even if the splinter patient arrived first. Priority scheduling works the same way: every process has a priority number, and the scheduler always picks the highest-priority process next.</p> <p>In PyOS, higher numbers mean higher priority. A process with <code>priority=10</code> runs before one with <code>priority=1</code>. When two processes have the same priority, the scheduler falls back to FIFO -- whoever arrived first goes first.</p> <pre><code># Priority scheduling -- highest priority runs first\npolicy = PriorityPolicy()\nscheduler = Scheduler(policy=policy)\n</code></pre> <p>There is a catch: starvation. If high-priority processes keep arriving, the low-priority ones never get a turn -- like an emergency room where critical patients keep showing up and the person with a sprained ankle waits forever. The next policy solves exactly this problem.</p>"},{"location":"concepts/processes/#aging-priority","title":"Aging Priority","text":"<p>Imagine a lunch queue where VIP students always cut in front. That is unfair -- regular students could wait all day. Aging is like giving every waiting student a \"patience sticker\" each time someone cuts ahead of them. Once you collect enough stickers, the lunch lady says \"You've waited long enough -- you're next!\" After you get served, your stickers are cleared and the counting starts over.</p> <p>In PyOS, every time the scheduler runs, each waiting process earns a small priority bonus (the <code>aging_boost</code>, default 1). The effective priority is the process's base priority plus its accumulated bonus. Eventually, even a low-priority process collects enough bonus to beat the high-priority newcomers. Once selected, the bonus resets to zero. A cap (<code>max_age</code>, default 10) prevents the bonus from growing without limit.</p> <pre><code># Aging Priority with default settings (boost=1, max_age=10)\npolicy = AgingPriorityPolicy()\nscheduler = Scheduler(policy=policy)\n</code></pre> <p>You can switch to it from the shell:</p> <pre><code>pyos&gt; scheduler aging\nScheduler set to Aging Priority (boost=1, max_age=10)\n</code></pre>"},{"location":"concepts/processes/#multilevel-feedback-queue-mlfq","title":"Multilevel Feedback Queue (MLFQ)","text":"<p>What if the scheduler could learn whether a process is a quick task or a long-running one, and adjust accordingly? That is what the Multilevel Feedback Queue does. It is the most important adaptive scheduling algorithm in real operating systems -- used by Linux (the predecessor to CFS), Windows, and macOS.</p> <p>Analogy: Imagine a science fair with three judging stations. Station 1 (front row) gives each student 2 minutes to present. If you cannot finish in 2 minutes, you move to Station 2, where you get 4 minutes. Still not done? Station 3 gives you 8 minutes. Judges always check Station 1 first, so quick presenters get served fast. Periodically, the teacher calls \"Everyone back to Station 1!\" so that students stuck in the back are not ignored forever.</p> <p>Here is how it works:</p> <ol> <li>New processes start at the top (level 0, shortest quantum).</li> <li>If preempted (used all their time), they are demoted one level down (longer quantum).</li> <li>Judges always serve the highest level first (lowest number = highest priority).</li> <li>Periodic boost resets everyone to level 0 to prevent starvation.</li> </ol> <p>This means short I/O-bound processes (like typing in a text editor) stay at level 0 and get fast response times, while long CPU-bound processes (like video encoding) naturally sink to lower levels with longer quanta -- less context-switching overhead for them.</p> <pre><code># MLFQ with 3 levels, base quantum of 2\npolicy = MLFQPolicy(num_levels=3, base_quantum=2)\n# Quanta: level 0 = 2, level 1 = 4, level 2 = 8\n</code></pre> <p>You can switch to MLFQ and trigger boosts from the shell:</p> <pre><code>pyos&gt; scheduler mlfq\nScheduler set to MLFQ (3 levels, base_quantum=2)\n\npyos&gt; scheduler boost\nMLFQ boost: all processes reset to level 0\n</code></pre>"},{"location":"concepts/processes/#completely-fair-scheduler-cfs","title":"Completely Fair Scheduler (CFS)","text":"<p>Linux replaced its earlier O(1) scheduler with the Completely Fair Scheduler in 2007, and it has been the default ever since. The goal is simple: give every process exactly its fair share of CPU time.</p> <p>Analogy: Imagine a pizza party where everyone should get equal slices, but some kids ordered extra toppings (higher priority). The host keeps a notebook tracking how many slices each person has eaten. The person who has eaten the fewest slices goes next. Kids with extra toppings have their count go up more slowly, so they get to eat more total slices before their number catches up. Eventually, everyone's count is roughly equal -- that is fairness.</p> <p>The notebook number is called virtual runtime (vruntime). Every time a process runs for one scheduling round, its vruntime goes up by <code>base_slice / weight</code>. The weight comes from the process's priority: <code>weight = max(1, priority + 1)</code>. A process with priority 5 has weight 6, so its vruntime grows six times slower than a priority-0 process. That means it gets picked more often before its count catches up -- more CPU time, just like the \"extra toppings\" kids.</p> <p>New processes start with their vruntime set to the current minimum across all processes, so they do not jump ahead or fall behind unfairly.</p> <pre><code># CFS with default base_slice of 1\npolicy = CFSPolicy(base_slice=1)\nscheduler = Scheduler(policy=policy)\n</code></pre> <p>You can switch to CFS from the shell:</p> <pre><code>pyos&gt; scheduler cfs\nScheduler set to CFS (base_slice=1)\n\npyos&gt; scheduler cfs 3\nScheduler set to CFS (base_slice=3)\n</code></pre> <p>How would you make it faster? Our simulator finds the lowest vruntime by scanning through all processes in the queue -- this takes O(n) time. Real Linux CFS uses a red-black tree (a self-balancing binary search tree) so that finding and removing the minimum takes only O(log n) time. For our small simulations this does not matter, but in a real kernel with thousands of processes, that speedup is essential.</p>"},{"location":"concepts/processes/#comparing-the-six-policies","title":"Comparing the Six Policies","text":"Policy Ordering Preemption Starvation risk Best for FCFS Arrival order None Convoy effect Batch jobs Round Robin Arrival order After quantum None Time-sharing Priority Priority number None High Mixed workloads Aging Priority Priority + age bonus None None (aging fixes it) Priority with fairness MLFQ Adaptive levels After level quantum None (with boost) Real-world general use CFS Lowest vruntime After base_slice None (vruntime balances) Modern Linux default <p>You can switch policies at runtime using the <code>scheduler</code> shell command:</p> <pre><code>pyos&gt; scheduler priority\nScheduler set to Priority\n</code></pre>"},{"location":"concepts/processes/#the-strategy-pattern","title":"The Strategy Pattern","text":"<p>Notice something neat about this design: the scheduler itself does not know how to pick the next process. It just asks the policy. You can swap <code>FCFSPolicy</code> for <code>RoundRobinPolicy</code> or <code>PriorityPolicy</code> (or write your own!) without changing a single line in the <code>Scheduler</code> class. This is a design pattern called Strategy -- the \"rules for taking turns\" are a separate, swappable piece.</p>"},{"location":"concepts/processes/#forking","title":"Forking","text":"<p>Imagine you could photocopy an entire student -- their desk, their notes, their pencil, the exact spot they stopped writing. Now there are TWO students, each at their own desk, each with identical notes. From that moment on, they work independently. One might erase something, the other might keep going -- they no longer affect each other.</p> <p>That is <code>fork()</code>.</p> <p>The original student is called the parent. The copy is called the child. The child is a brand new process with its own PID, but it starts with copies of everything the parent had.</p>"},{"location":"concepts/processes/#what-gets-copied","title":"What gets copied","text":"Resource What happens PID The child gets a new, unique PID Memory A full copy of the parent's memory pages -- separate physical frames Priority Inherited from the parent Name Parent's name with \"(fork)\" added State The child starts in READY, immediately eligible to run <p>After the fork, the parent and child are independent. If the child writes to its memory, the parent's memory is not affected. They each have their own copy.</p>"},{"location":"concepts/processes/#why-is-forking-useful","title":"Why is forking useful?","text":"<p>Forking is how an operating system creates new workers. A web server might fork a child process for every new visitor, so each visitor gets their own handler. If one child crashes, the others keep running.</p>"},{"location":"concepts/processes/#the-process-tree","title":"The Process Tree","text":"<p>Because every child remembers its parent (via <code>parent_pid</code>), processes form a tree. On a real Linux system, you can see this with the <code>pstree</code> command:</p> <pre><code>server (pid=1)\n  +-- server (fork) (pid=2)\n  +-- server (fork) (pid=3)\n       +-- server (fork) (fork) (pid=4)\n</code></pre> <p>Every Unix system has a process tree rooted at PID 1 (called <code>init</code> or <code>systemd</code>). All other processes are descendants, created through chains of fork calls.</p>"},{"location":"concepts/processes/#threads","title":"Threads","text":"<p>Forking creates a full copy of a process -- new memory, new everything. But what if you want two things to happen at the same time inside the same process, sharing the same data?</p> <p>That is what threads are for.</p> <p>If forking is like photocopying an entire student (desk, notes, pencil, everything), creating a thread is like giving one student a second pair of hands. Both pairs of hands share the same desk and the same notes. They can work on two things at the same time, and they can both see everything the other is doing.</p>"},{"location":"concepts/processes/#why-threads-are-cheap","title":"Why threads are cheap","text":"<p>When you fork, the kernel has to copy all of the parent's memory into new physical frames. That takes time and space. When you create a thread, no new memory is allocated at all. The thread just uses the memory that the process already has. That is why threads are called \"lightweight.\"</p> <pre><code># Creating a thread inside a process -- no memory cost\nworker = process.create_thread(\"worker-1\")\n</code></pre>"},{"location":"concepts/processes/#why-sharing-is-tricky","title":"Why sharing is tricky","text":"<p>Sharing sounds great, but it comes with a catch. If both pairs of hands try to erase and write in the same spot at the same time, you get a mess. One hand erases while the other is writing, and the result is garbled nonsense.</p> <p>In programming, this is called a race condition -- the result depends on which thread happened to go first, and that can change every time you run the program. Race conditions are some of the hardest bugs to find because they do not happen consistently.</p> <p>The solution involves tools like mutexes (locks that only let one thread in at a time) and semaphores (counters that control access). Those are covered in Synchronization.</p>"},{"location":"concepts/processes/#threads-vs-fork-when-to-use-which","title":"Threads vs Fork -- When to use which","text":"Fork Thread Memory Full copy (expensive) Shared (free) Independence Completely separate Tied together Crash safety Child crash does not affect parent Thread crash can take down the whole process Best for Independent workers, isolation Parallel work within one program <p>Each thread has its own TID (Thread ID), its own name, and its own state that follows the same five-state model as processes (NEW, READY, RUNNING, WAITING, TERMINATED). But all threads in a process share the same virtual memory space.</p>"},{"location":"concepts/processes/#running-programs","title":"Running Programs","text":"<p>So far we have talked about processes having states and taking turns. But what does a process actually do? It runs a program.</p> <p>In PyOS, a program is a Python function that returns a string. The lifecycle goes like this:</p> <ol> <li>Create -- The kernel creates a new process (an empty student shows up).</li> <li>Exec -- A program is loaded into the process (the student receives their assignment sheet).</li> <li>Run -- The process is dispatched and the program executes (the student does the work).</li> <li>Output -- The program returns its result (the student hands in their paper).</li> <li>Exit code -- The process gets a grade: <code>0</code> means everything went well, <code>1</code> means something went wrong.</li> </ol> <p>This mirrors the real Unix pattern of <code>fork()</code> then <code>exec()</code>. The process is created first, and the program is loaded into it as a separate step. That separation is useful because the kernel can set up things like redirections and environment variables in between.</p>"},{"location":"concepts/processes/#exit-codes","title":"Exit Codes","text":"<p>Every process finishes with an exit code -- a number that tells the parent whether things went well.</p> <ul> <li>0 means success. The program ran and returned its output normally.</li> <li>1 (or any non-zero number) means failure. The program hit an error.</li> </ul> <p>In real Unix, you can check the last command's exit code with <code>$?</code>. In PyOS, the exit code is stored on the process object after execution.</p>"},{"location":"concepts/processes/#try-it-in-the-pyos-shell","title":"Try it in the PyOS shell","text":"<p>PyOS comes with a couple of built-in programs you can run:</p> <pre><code>pyos&gt; run hello\nHello from PyOS!\n[exit code: 0]\n\npyos&gt; run counter\n1\n2\n3\n4\n5\n[exit code: 0]\n</code></pre> <p>The <code>run</code> command does the full lifecycle behind the scenes: it creates a process, loads the named program, dispatches and executes it, captures the output, and cleans up -- all through syscalls (<code>SYS_EXEC</code> and <code>SYS_RUN</code>).</p>"},{"location":"concepts/processes/#zombies-and-waiting","title":"Zombies and Waiting","text":"<p>When a child process finishes, it does not just vanish. It still has information the parent might need -- like an exit code that says whether things went well. So the child becomes a zombie: it is dead (TERMINATED), its memory is freed, but its entry stays in the process table, holding its exit code like a receipt.</p>"},{"location":"concepts/processes/#the-milk-analogy","title":"The milk analogy","text":"<p>Imagine you send your sibling to the corner shop to buy milk. They go, they buy it, they come back. But instead of putting the milk in the fridge themselves, they stand in the doorway holding the carton, waiting for you to take it from them. Until you take the milk, they are stuck in the doorway -- that is a zombie. Once you take the milk (collect the exit code), they can finally go sit down and the doorway is clear.</p>"},{"location":"concepts/processes/#wait-and-waitpid","title":"<code>wait()</code> and <code>waitpid()</code>","text":"<p>The parent collects a zombie using <code>wait()</code> or <code>waitpid()</code>:</p> <ul> <li><code>wait()</code> -- \"I don't care which sibling comes back first -- just give me whoever finishes first.\"</li> <li><code>waitpid(pid)</code> -- \"I'm specifically waiting for sibling number 5.\"</li> </ul> <p>If a child has already finished (there is already a zombie), the collection happens instantly. If no child has finished yet, the parent blocks -- it moves to the WAITING state and stops doing anything until a child terminates.</p> <p>In PyOS, because everything is single-threaded, \"blocking\" means the parent transitions to WAITING and records what it is waiting for. When the child later terminates, the kernel checks if the parent is waiting and wakes it up.</p>"},{"location":"concepts/processes/#what-happens-to-orphans","title":"What happens to orphans?","text":"<p>If a process has no parent (or the parent has already been removed), it is an orphan. Orphans are cleaned up immediately when they terminate -- no zombie stage needed, because nobody is going to collect them.</p>"},{"location":"concepts/processes/#try-it-in-the-pyos-shell_1","title":"Try it in the PyOS shell","text":"<pre><code>pyos&gt; fork 1\nForked pid 1 \u2192 child pid 2 (parent (fork))\n\npyos&gt; wait 1\nCollected child pid 2 (exit_code=0, output='hello')\n</code></pre> <p>If the child has not finished yet, you will see:</p> <pre><code>pyos&gt; wait 1\nProcess 1 is now waiting for a child.\n</code></pre>"},{"location":"concepts/processes/#performance-metrics","title":"Performance Metrics","text":"<p>How do we know if our scheduler is doing a good job? Imagine a sports day stopwatch station. Every time a runner (process) steps up to the start line (READY queue), a helper clicks a stopwatch. When the runner actually starts running (dispatched to the CPU), the helper notes how long they waited. When they cross the finish line (terminate), we record their total race time. At the end of the day, we calculate averages to see how the event went.</p> <p>PyOS tracks four key measurements:</p> Metric What it measures Sports day equivalent Wait time How long a process sits in the READY queue How long a runner waits at the start line Turnaround time Total time from creation to termination Time from a runner arriving at the field to crossing the finish line Response time Time from creation to first CPU dispatch How quickly a runner gets their first turn Context switches How many times the CPU switches between processes How many times the baton gets handed off <p>These metrics help answer important questions: - \"Are processes waiting too long?\" (high average wait time) - \"Is the system getting work done?\" (throughput \u2014 completed processes per second) - \"Does the system feel responsive?\" (low average response time)</p>"},{"location":"concepts/processes/#try-it-in-the-pyos-shell_2","title":"Try it in the PyOS shell","text":"<pre><code>pyos&gt; perf\n=== PyOS Performance Metrics ===\nContext switches:    0\nProcesses created:   0\nProcesses completed: 0\nAvg wait time:       0.00s\nAvg turnaround:      0.00s\nAvg response:        0.00s\nThroughput:          0.00 procs/sec\n</code></pre> <p>You can also read the raw numbers from the virtual filesystem:</p> <pre><code>pyos&gt; cat /proc/stat\nCtxSwitches:    42\nTotalCreated:   10\nTotalCompleted: 7\nAvgWaitTime:    0.15 seconds\nAvgTurnaround:  1.23 seconds\nAvgResponse:    0.05 seconds\nThroughput:     2.33 procs/sec\n</code></pre> <p>Or check individual process timing:</p> <pre><code>pyos&gt; cat /proc/42/sched\nWaitTime:       0.05 seconds\nCpuTime:        0.10 seconds\nResponseTime:   0.02 seconds\nTurnaround:     0.15 seconds\n</code></pre> <p>Run <code>perf demo</code> for a guided walkthrough that creates processes and shows how the numbers change.</p>"},{"location":"concepts/processes/#multiple-cpus","title":"Multiple CPUs","text":"<p>So far we've talked about one whiteboard -- one CPU, one student at a time. But modern computers have multiple CPUs (called cores). That is like a classroom with several whiteboards, each with its own queue of students.</p>"},{"location":"concepts/processes/#how-it-works","title":"How it works","text":"<p>Each whiteboard has its own line of waiting students and its own scheduling policy. A teacher (the <code>MultiCPUScheduler</code>) coordinates all the whiteboards:</p> <ul> <li>When a new student arrives, the teacher sends them to the whiteboard with the shortest line.</li> <li>Periodically, the teacher checks if one queue is much longer than the others. If so, they move a student from the crowded queue to a shorter one. This is called load balancing.</li> <li>Some students have a preference -- maybe they're left-handed and whiteboard 2 is easier for them. That preference is called CPU affinity. The teacher respects it: a student pinned to whiteboard 2 won't be moved to whiteboard 0, even during load balancing.</li> </ul>"},{"location":"concepts/processes/#try-it-in-the-pyos-shell_3","title":"Try it in the PyOS shell","text":"<p>PyOS supports multiple CPUs through the bootloader or kernel configuration:</p> <pre><code>pyos&gt; cpu\nCPU 0: FCFSPolicy  ready=2  current=pid 1 (init)\nCPU 1: FCFSPolicy  ready=1  current=none\n\npyos&gt; taskset 3\nProcess 3 affinity: CPU 0, 1\n\npyos&gt; taskset 3 0\nSet process 3 affinity to CPU 0\n\npyos&gt; scheduler balance\nBalanced: 1 migration(s)\n</code></pre> <p>The <code>ps</code> command shows which CPU each process is on:</p> <pre><code>pyos&gt; ps\nPID    CPU  STATE       NAME\n1      0    running     init\n2      1    ready       worker-a\n3      0    ready       worker-b\n</code></pre>"},{"location":"concepts/processes/#under-the-hood","title":"Under the hood","text":"<p>The <code>MultiCPUScheduler</code> wraps N <code>Scheduler</code> instances -- one per CPU. It exposes the same interface as a single-CPU scheduler (so existing code works unchanged), plus new methods for load balancing, affinity, and migration. Each per-CPU scheduler has its own ready queue, current process, and context-switch counter.</p>"},{"location":"concepts/processes/#putting-it-all-together","title":"Putting It All Together","text":"<p>Here is the big picture. A process is a program in action, tracked by a PCB. The scheduler decides which process gets the CPU, using a pluggable policy (FCFS, Round Robin, Priority, Aging Priority, MLFQ, or CFS). On multi-CPU systems, a <code>MultiCPUScheduler</code> coordinates per-CPU schedulers with load balancing and CPU affinity. Processes can create copies of themselves through forking, or run lightweight parallel work using threads. When a process runs a program, it goes through the full lifecycle -- create, load, execute, output, and exit. When a child terminates, it becomes a zombie until its parent collects the exit code with <code>wait()</code> or <code>waitpid()</code>.</p> <p>All of these pieces work together inside the kernel, which coordinates the scheduler, memory manager, and process table to keep everything running smoothly.</p>"},{"location":"concepts/processes/#key-terms","title":"Key Terms","text":"Term Definition Process A program in execution, with its own PID, state, and memory PCB Process Control Block -- the data structure that tracks everything about a process PID Process Identifier -- a unique number assigned to each process Scheduler The part of the OS that decides which process runs next Ready queue The line of processes waiting for the CPU Quantum The amount of time a process gets before being preempted (Round Robin) Preemption Pulling a running process off the CPU so someone else can have a turn Priority A number that tells the scheduler how important a process is (higher = more important) Starvation When a low-priority process never gets to run because higher-priority work keeps arriving Aging A technique that gives waiting processes a small priority boost each round, preventing starvation vruntime Virtual runtime -- a weighted count of how much CPU time a process has consumed (used by CFS) CFS Completely Fair Scheduler -- always picks the process with the lowest vruntime Fork Creating a copy of a process -- new PID, copied memory, independent from the original Thread A lightweight execution unit that shares memory with other threads in the same process Race condition A bug caused by two threads accessing shared data at the same time Exit code A number (0 = success, non-zero = failure) that a process returns when it finishes Zombie A terminated process that stays in the process table until its parent collects the exit code wait() Block until any child terminates, then collect its exit code waitpid() Block until a specific child terminates, then collect its exit code Orphan A process whose parent no longer exists -- cleaned up immediately on termination Wait time How long a process spends in the READY queue, waiting for the CPU Turnaround time Total time from process creation to termination Response time Time from process creation to first CPU dispatch Context switch When the CPU stops running one process and starts running another Throughput Number of processes completed per second of system uptime CPU affinity The set of CPUs a process is allowed to run on Load balancing Moving processes from busy CPUs to less busy ones to keep work even Migration Moving a process from one CPU's ready queue to another MultiCPUScheduler A wrapper that coordinates N per-CPU schedulers with load balancing and affinity"},{"location":"concepts/processes/#where-to-go-next","title":"Where to Go Next","text":"<ul> <li>Memory -- How the OS hands out and protects memory for each process</li> <li>The Kernel -- The core of the OS and how programs talk to it</li> <li>Synchronization -- How threads share resources without stepping on each other</li> <li>Users and Safety -- Permissions, signals, and deadlocks</li> </ul>"},{"location":"concepts/shell/","title":"The Shell","text":"<p>You know how when you walk into a hotel, you don't just wander into the back office, open filing cabinets, and flip light switches yourself? You go to the front desk and tell the receptionist what you need. \"I'd like to check in.\" \"Can I get extra towels?\" The receptionist listens, translates your request into whatever the hotel's internal system requires, and comes back with an answer.</p> <p>The shell is the receptionist of your operating system.</p> <p>You type commands. The shell reads what you typed, figures out what you're asking for, and passes the request to the kernel through system calls. The kernel does the real work, and the shell hands the result back to you as text.</p> <p>Here's the important rule: the shell never touches the kernel's internals directly. It doesn't reach into the filesystem, it doesn't poke the scheduler, it doesn't fiddle with memory. It always goes through the official front door -- system calls. This keeps things clean and safe, just like how the receptionist uses the hotel's booking system instead of personally moving furniture between rooms.</p> <p>In fact, the kernel enforces this. The shell runs in user mode, where accessing kernel subsystems directly raises an error. The only way to get anything done is through <code>kernel.syscall(...)</code>, which temporarily switches to kernel mode for the duration of the request. See User Mode vs Kernel Mode for the full story.</p> <p>One more thing to know: everything the shell gives back to you is a string (text). Even a list of processes or a count of files comes back as plain text. That turns out to be really powerful, as you'll see when we get to pipes.</p>"},{"location":"concepts/shell/#commands","title":"Commands","text":"<p>So how does the shell know what <code>ls</code> or <code>mkdir</code> means? It uses something called a dispatch table. That's a fancy name for a Python dictionary that maps command names to functions.</p> <p>It looks something like this:</p> <pre><code>commands = {\n    \"ls\":    self._cmd_ls,\n    \"mkdir\": self._cmd_mkdir,\n    \"cat\":   self._cmd_cat,\n    # ... and so on\n}\n</code></pre> <p>When you type <code>ls /</code>, the shell splits that into the command name (<code>ls</code>) and the arguments (<code>/</code>). It looks up <code>\"ls\"</code> in the dictionary, finds the matching function, and calls it with the arguments. Done.</p> <p>Want to add a brand new command to PyOS? Write a function that does the thing, then add one line to the dictionary. That's it. No long chain of <code>if</code>/<code>elif</code>/<code>else</code> -- just a clean dictionary lookup.</p> <p>Here are the commands grouped by what they do. You don't need to memorize them -- just know they exist so you can come back and look them up.</p> <p>Files -- working with files and directories:</p> Command What it does <code>ls</code> List the contents of a directory <code>mkdir</code> Create a new directory <code>touch</code> Create an empty file <code>cat</code> Read and display a file's contents <code>write</code> Write text into a file <code>rm</code> Remove (delete) a file or directory <p>Processes -- managing running programs:</p> Command What it does <code>ps</code> List all running processes <code>kill</code> Terminate a process by its PID <code>fork</code> Create a copy of an existing process <code>pstree</code> Show the parent-child process tree <code>threads</code> List the threads inside a process <code>run</code> Create a process and run a built-in program <code>wait</code> Wait for any child process to finish and collect its exit code <code>waitpid</code> Wait for a specific child process to finish <code>signal</code> Send a signal (like SIGTERM or SIGKILL) to a process <code>handle</code> Register a custom signal handler for a process <code>taskset</code> Show or set a process's CPU affinity (which CPUs it can run on) <p>Users -- who's using the system:</p> Command What it does <code>whoami</code> Show the current user <code>adduser</code> Create a new user <code>su</code> Switch to a different user <p>System -- checking on the OS itself:</p> Command What it does <code>top</code> Show a system status dashboard (memory, processes, uptime) <code>log</code> Display recent log entries <code>env</code> List all environment variables <code>export</code> Set an environment variable <code>history</code> Show every command you've typed this session <code>perf</code> Show performance metrics (context switches, wait time, throughput) <code>strace</code> Syscall tracing: on, off, show, clear, demo <code>dmesg</code> Display the kernel boot log <code>exit</code> Shut down the kernel and leave the shell <p>Synchronization -- managing shared resources:</p> Command What it does <code>mutex</code> Create, acquire, release, or list mutexes <code>semaphore</code> Create, acquire, release, or list semaphores <code>rwlock</code> Create, acquire, release, or list reader-writer locks <code>pi</code> Priority inheritance demo and status <code>ordering</code> Deadlock prevention: register ranks, set mode, view violations, demo <code>shm</code> Shared memory: create, attach, detach, write, read, list, destroy, demo <code>dns</code> DNS: register, lookup, remove, list, flush, demo <code>socket</code> Raw sockets: create, bind, listen, connect, accept, send, recv, close, list <code>http</code> HTTP protocol demo (request/response over sockets) <code>proc</code> /proc virtual filesystem demo (live kernel state as files) <p>Virtual filesystem -- inspecting the system through /proc:</p> <p><code>cat</code> and <code>ls</code> automatically detect <code>/proc</code> paths and read from the virtual filesystem instead of the real one. For example:</p> <pre><code>cat /proc/meminfo       -- memory statistics\ncat /proc/uptime        -- system uptime\ncat /proc/stat          -- performance metrics (context switches, throughput)\nls /proc                -- list all /proc entries\nls /proc/42             -- list files for process 42\ncat /proc/42/status     -- process 42's details\ncat /proc/42/sched      -- per-process timing (wait, CPU, response, turnaround)\n</code></pre> <p>Scheduling -- controlling how processes share the CPU:</p> Command What it does <code>scheduler</code> Switch scheduling policies, view settings, or trigger load balancing <code>cpu</code> Show per-CPU status (policy, queue size, current process) <p>Storage -- crash recovery and disk management:</p> Command What it does <code>journal</code> Show the write-ahead log status for crash recovery <p>Learning and monitoring -- explore the OS in action:</p> Command What it does <code>learn</code> Interactive tutorials (processes, memory, filesystem, scheduling, signals, ipc, networking, interrupts, tcp) <code>perf</code> Show performance metrics (demo) <code>strace</code> Syscall tracing (on, off, show, clear, demo) <code>dmesg</code> Show kernel boot log <code>proc</code> /proc virtual filesystem (demo)"},{"location":"concepts/shell/#pipes","title":"Pipes","text":"<p>Imagine an assembly line in a factory. The first worker makes a part, then slides it down the conveyor belt to the second worker, who modifies it, who slides it to the third worker, who counts the results. Each worker does one small job, and together they produce the final product.</p> <p>Pipes work exactly like that. The <code>|</code> character connects commands so that the output of one becomes the input of the next.</p> <pre><code>ls / | grep txt | wc\n</code></pre> <p>Here's what happens step by step:</p> <ol> <li><code>ls /</code> lists all the files in the root directory. Its output is a bunch of    lines of text.</li> <li>That text slides down the pipe to <code>grep txt</code>, which reads every line and    keeps only the ones containing \"txt\". Everything else gets thrown away.</li> <li>The filtered lines slide down another pipe to <code>wc</code>, which counts how many    lines it received and prints the total.</li> </ol> <p>Three tiny tools, each doing one thing well, connected together to answer the question \"how many files in <code>/</code> have 'txt' in their name?\"</p> <p>This idea has a name: the Unix philosophy. Build small, focused tools that each do one thing, then connect them with pipes to solve bigger problems. It's like building with LEGO bricks -- each brick is simple, but you can combine them into anything.</p> <p>Remember how the shell returns everything as strings? That's why pipes work so smoothly. Since every command produces text, any command's output can become any other command's input.</p>"},{"location":"concepts/shell/#redirection","title":"Redirection","text":"<p>Pipes connect commands to each other. But what if you want to send a command's output to a file instead? Or read a command's input from a file instead of typing it? That's what redirection does.</p> <p>Think of it like mail. Normally, when a command finishes, it hands you the result directly -- like someone handing you a letter. Redirection says \"don't hand it to me, put it in that mailbox over there instead.\"</p>"},{"location":"concepts/shell/#output-redirection","title":"Output redirection (<code>&gt;</code>)","text":"<p>The <code>&gt;</code> operator takes a command's output and writes it into a file:</p> <pre><code>echo hello &gt; /greeting.txt\ncat /greeting.txt\n</code></pre> <p>The first command writes \"hello\" into <code>/greeting.txt</code>. The second reads it back. Notice that <code>echo hello &gt;</code> showed nothing on screen -- the output went to the file instead of being displayed.</p> <p>If the file doesn't exist, <code>&gt;</code> creates it. If it already exists, <code>&gt;</code> erases everything in it and writes the new content. It's like ripping out all the pages of a notebook and starting fresh.</p>"},{"location":"concepts/shell/#append-redirection","title":"Append redirection (<code>&gt;&gt;</code>)","text":"<p>What if you don't want to erase the file? Use <code>&gt;&gt;</code> to add to the end:</p> <pre><code>echo dear diary &gt;&gt; /diary.txt\necho today was great &gt;&gt; /diary.txt\n</code></pre> <p>Think of <code>&gt;&gt;</code> as \"keep writing where I left off\" and <code>&gt;</code> as \"start a brand new page.\" If you're building a log file where you want to add entries over time, <code>&gt;&gt;</code> is what you want.</p>"},{"location":"concepts/shell/#input-redirection","title":"Input redirection (<code>&lt;</code>)","text":"<p>The <code>&lt;</code> operator goes the other direction. Instead of redirecting output, it redirects input -- it feeds the contents of a file into a command:</p> <pre><code>grep apple &lt; /fruits.txt\n</code></pre> <p>This is like saying \"open that file and read it out loud to <code>grep</code>.\" The <code>grep</code> command then filters the lines just like it would with piped input. It works with any pipe-aware command like <code>grep</code> or <code>wc</code>:</p> <pre><code>wc &lt; /fruits.txt\n</code></pre> <p>You can even combine input and output redirection:</p> <pre><code>grep apple &lt; /fruits.txt &gt; /results.txt\n</code></pre> <p>That reads from <code>/fruits.txt</code>, filters for lines containing \"apple\", and writes the matching lines into <code>/results.txt</code>.</p>"},{"location":"concepts/shell/#error-redirection-2","title":"Error redirection (<code>2&gt;</code>)","text":"<p>Sometimes a command fails. When that happens, the shell produces an error message instead of normal output. The <code>2&gt;</code> operator captures those error messages and sends them to a file:</p> <pre><code>cat /nonexistent 2&gt; /errors.txt\n</code></pre> <p>If <code>/nonexistent</code> doesn't exist, the error message goes into <code>/errors.txt</code> instead of being displayed. Normal (successful) output is unaffected -- <code>2&gt;</code> only catches errors.</p> <p>Think of it like sorting mail. You have two piles: one for regular letters (normal output) and one for bills and complaints (errors). The <code>&gt;</code> operator redirects the regular pile, and <code>2&gt;</code> redirects the complaints pile. You can even use both at once:</p> <pre><code>ls / &gt; /output.txt 2&gt; /errors.txt\n</code></pre> <p>Why the <code>2</code>? In real Unix systems, every program has numbered channels called file descriptors. Channel 1 is \"standard output\" (stdout) and channel 2 is \"standard error\" (stderr). So <code>2&gt;</code> literally means \"redirect channel 2.\" PyOS simulates this by looking at whether the output string starts with \"Error:\" -- if it does, it's treated as stderr.</p>"},{"location":"concepts/shell/#redirection-and-pipes-together","title":"Redirection and pipes together","text":"<p>You can combine redirection with pipes. Redirection applies to whatever stage it appears in:</p> <pre><code>ls / | grep txt &gt; /matches.txt\n</code></pre> <p>Here, <code>ls /</code> produces a listing, the pipe feeds it to <code>grep txt</code>, and then <code>&gt;</code> sends grep's filtered output to a file.</p> <p>Limitation: You can't combine redirection with background execution (<code>&amp;</code>). If you try <code>echo hello &gt; /out.txt &amp;</code>, you'll get an error. This keeps things simple -- the interaction between backgrounding and file I/O adds complexity that belongs in a later feature.</p>"},{"location":"concepts/shell/#all-redirection-operators","title":"All redirection operators","text":"Operator What it does <code>&gt;</code> Write output to a file (create or overwrite) <code>&gt;&gt;</code> Append output to a file (create if needed) <code>&lt;</code> Read input from a file <code>2&gt;</code> Write error output to a file"},{"location":"concepts/shell/#vocabulary","title":"Vocabulary","text":"<ul> <li>Redirection -- routing a command's input or output to/from a file instead   of the screen</li> <li>Standard output (stdout) -- the normal output channel (file descriptor 1)</li> <li>Standard error (stderr) -- the error output channel (file descriptor 2)</li> <li>Overwrite -- <code>&gt;</code> replaces the file's contents completely</li> <li>Append -- <code>&gt;&gt;</code> adds to the end of the file without erasing</li> </ul>"},{"location":"concepts/shell/#loops","title":"Loops","text":"<p>Imagine you have a big stack of trading cards and you need to sort them. You wouldn't write a separate instruction for each card -- you'd say \"keep doing this until the stack is empty\" or \"do this for every card in the pile.\" That's what loops do in a script: they repeat a block of commands automatically.</p>"},{"location":"concepts/shell/#while-loops","title":"While loops","text":"<p>A while loop is like a traffic light. Keep going as long as the light is green. The moment it turns red, stop.</p> <pre><code>while cat /flag\ndo\n  echo \"still going\"\n  rm /flag\ndone\n</code></pre> <p>Here's what happens:</p> <ol> <li>The shell runs <code>cat /flag</code>. If it succeeds (the file exists), the light is    \"green\" -- enter the loop body.</li> <li>Inside the body, we echo a message and delete the flag file.</li> <li>Back to the top: try <code>cat /flag</code> again. This time it fails (file is gone),    so the light turns \"red\" and the loop stops.</li> </ol> <p>The condition is checked every time before entering the body. If the condition fails on the very first check, the body never runs at all -- just like a red light stopping you before you even start.</p> <p>Important: The condition is re-expanded each iteration. If you use <code>$VAR</code> in the condition, it picks up the latest value of that variable every time around the loop. This is how you can change a variable inside the body and have the condition notice.</p>"},{"location":"concepts/shell/#for-loops","title":"For loops","text":"<p>A for loop is like taking attendance at school. The teacher has a list of names, and for each name on the list, they call it out and mark it down.</p> <pre><code>for FRUIT in apple banana cherry\ndo\n  echo $FRUIT\ndone\n</code></pre> <p>This outputs:</p> <pre><code>apple\nbanana\ncherry\n</code></pre> <p>The shell takes each item after <code>in</code>, assigns it to the variable <code>FRUIT</code>, and runs the body once. Then it assigns the next item and runs the body again, until the list is exhausted.</p> <p>You can use a variable for the list, too:</p> <pre><code>export COLORS=\"red green blue\"\nfor C in $COLORS\ndo\n  echo $C\ndone\n</code></pre> <p>The <code>$COLORS</code> variable gets expanded to <code>red green blue</code>, and the loop iterates over those three words.</p>"},{"location":"concepts/shell/#nesting","title":"Nesting","text":"<p>Loops can go inside other loops, and loops can go inside <code>if</code> blocks (and vice versa). Think of Russian nesting dolls -- each doll can contain another doll inside.</p> <pre><code>for DIR in /data /logs\ndo\n  mkdir $DIR\n  for FILE in a.txt b.txt\n  do\n    touch $DIR/$FILE\n  done\ndone\n</code></pre> <p>This creates two directories and puts two files in each one. The outer loop runs twice (once for <code>/data</code>, once for <code>/logs</code>), and for each outer iteration, the inner loop runs twice (once for <code>a.txt</code>, once for <code>b.txt</code>). Total: four files created.</p> <p>You can also put a while loop inside a for loop, an if inside a while, or any combination. The shell handles nesting by running each inner block as its own mini-script -- the same technique that makes the whole scripting engine work.</p>"},{"location":"concepts/shell/#safety-net","title":"Safety net","text":"<p>What if you accidentally write a while loop whose condition never fails?</p> <pre><code>while cat /always-exists\ndo\n  echo \"forever!\"\ndone\n</code></pre> <p>In a real OS, this would run until you kill the process (Ctrl+C). In PyOS, we have a built-in safety limit: 1,000 iterations. If a loop hits this limit, it stops and reports an error. This prevents your scripts from running away and freezing the system.</p>"},{"location":"concepts/shell/#all-loop-commands","title":"All loop commands","text":"Syntax What it does <code>while &lt;cmd&gt;</code> / <code>do</code> / <code>done</code> Repeat while <code>&lt;cmd&gt;</code> succeeds <code>for VAR in items...</code> / <code>do</code> / <code>done</code> Iterate over a list of items"},{"location":"concepts/shell/#vocabulary_1","title":"Vocabulary","text":"<ul> <li>While loop -- repeat a block as long as a condition is true</li> <li>For loop -- repeat a block once for each item in a list</li> <li>Iteration -- one pass through the loop body</li> <li>Nesting -- putting one loop (or conditional) inside another</li> <li>Infinite loop -- a loop that never stops (PyOS limits these to 1,000   iterations)</li> </ul>"},{"location":"concepts/shell/#scripting","title":"Scripting","text":"<p>So far you've been giving the receptionist one request at a time. But what if you had a whole checklist of things to do? You could hand them the entire list and say \"do all of these, in order.\"</p> <p>That's a script -- a text file with commands, one per line. Instead of typing commands one by one, you write them all down and tell the shell to run the file.</p> <pre><code># Set up a data directory and create a file in it\nmkdir /data\nexport NAME=hello\necho $NAME\nif ls /data\nthen\n  touch /data/$NAME.txt\nfi\n</code></pre> <p>Let's break down the special features you see here.</p> <p>Comments start with <code>#</code>. They're notes for humans. The shell completely ignores them. Use comments to explain why you're doing something so that future-you (or someone else) can understand the script.</p> <p>Variables use the <code>$</code> sign. When the shell sees <code>$NAME</code>, it replaces it with whatever value <code>NAME</code> holds before running the command. So if <code>NAME</code> is <code>hello</code>, then <code>touch /data/$NAME.txt</code> actually runs <code>touch /data/hello.txt</code>. Think of <code>$NAME</code> as a placeholder that gets filled in.</p> <p>Conditionals let you make decisions. The <code>if</code>/<code>then</code>/<code>else</code>/<code>fi</code> block works like this:</p> <pre><code>if some_command\nthen\n  # This runs if some_command succeeded\nelse\n  # This runs if some_command failed\nfi\n</code></pre> <p>The shell runs <code>some_command</code>. If it works (no error), it runs the <code>then</code> block. If it fails, it runs the <code>else</code> block. The <code>else</code> part is optional -- you can leave it out. <code>fi</code> marks the end (it's <code>if</code> spelled backwards, which is a real thing that actual Unix shells do).</p> <p>source runs a script from a file. If you saved the script above to <code>/scripts/setup.sh</code>, you could run it with:</p> <pre><code>source /scripts/setup.sh\n</code></pre> <p>The shell reads the file, and executes each line as if you had typed it yourself.</p>"},{"location":"concepts/shell/#job-control","title":"Job Control","text":"<p>Imagine you're at a restaurant. You order your food, and while the kitchen is working on it, you don't just sit there staring at the kitchen door. You talk to your friends, check your phone, maybe order a drink. When the food is ready, the waiter brings it over.</p> <p>Job control works the same way. You can send a process to the background so it runs on its own, and you keep typing other commands. Meanwhile, the background process keeps doing its thing.</p> <p>Here's the important bit: jobs are a shell concept, not a kernel concept. The kernel knows about processes, but it doesn't know or care which ones you consider \"background jobs.\" The shell keeps its own list.</p>"},{"location":"concepts/shell/#the-operator","title":"The <code>&amp;</code> operator","text":"<p>Adding <code>&amp;</code> to the end of a <code>run</code> command is like telling the kitchen \"bring it when it's ready, I don't need to watch you cook.\" The program runs, but instead of showing its output right away, the shell captures it silently and gives you a job notification:</p> <pre><code>&gt; run hello &amp;\n[1] 42\n</code></pre> <p>That <code>[1]</code> is the job number and <code>42</code> is the process ID. The program has already finished -- its output is waiting for you whenever you're ready to look at it.</p> <p>Important: In a real operating system, <code>&amp;</code> makes a process run at the same time as your other commands (true concurrency). PyOS is a simulator without threads, so the process actually runs to completion immediately -- the only difference is that the output gets stored in the job instead of being printed. Think of it like a restaurant that cooks your food instantly but keeps it warm on a shelf instead of bringing it to your table right away.</p> <p>The <code>&amp;</code> operator is only meaningful for <code>run</code> commands (which create and execute processes). Other commands like <code>touch</code> or <code>ls</code> are so fast that backgrounding them doesn't make sense -- they just run normally.</p> <p>One limitation: you can't combine pipes with <code>&amp;</code> (like <code>ls / | grep txt &amp;</code>). Real shells can do this, but it adds complexity that we'll save for later.</p>"},{"location":"concepts/shell/#retrieving-output","title":"Retrieving output","text":"<p>Once a job is running in the background, you have two ways to get its output:</p> <p><code>fg &lt;job_id&gt;</code> -- brings the job to the foreground and shows its captured output. This also removes the job from the list.</p> <pre><code>&gt; run hello &amp;\n[1] 42\n&gt; fg 1\nHello from PyOS!\n[exit code: 0]\n</code></pre> <p><code>waitjob</code> -- collects output from background jobs without \"bringing them forward.\" Use <code>waitjob</code> to see all jobs, or <code>waitjob &lt;job_id&gt;</code> for a specific one. Either way, the jobs are removed after you collect them.</p> <pre><code>&gt; run hello &amp;\n[1] 42\n&gt; run counter &amp;\n[2] 43\n&gt; waitjob\n[1] hello:\nHello from PyOS!\n[exit code: 0]\n[2] counter:\n1\n2\n3\n4\n5\n[exit code: 0]\n</code></pre> <p>Why is <code>waitjob</code> a separate command from <code>wait</code>? Because they're different concepts. <code>wait</code> is a kernel-level command -- it tells a parent process to wait for a child process to finish (like a parent waiting for their kid to come home). <code>waitjob</code> is a shell-level command -- it retrieves output from a background job you started with <code>&amp;</code>. Keeping them separate helps reinforce where each concept lives in the OS layers.</p>"},{"location":"concepts/shell/#all-job-commands","title":"All job commands","text":"Command What it does <code>run &lt;program&gt; &amp;</code> Run a program in the background <code>bg &lt;pid&gt;</code> Add an existing process as a background job <code>fg &lt;job_id&gt;</code> Bring a job to the foreground (shows output, removes job) <code>jobs</code> List all background jobs <code>waitjob</code> Collect output from all jobs and remove them <code>waitjob &lt;job_id&gt;</code> Collect output from a specific job and remove it"},{"location":"concepts/shell/#vocabulary_2","title":"Vocabulary","text":"<ul> <li>Background job -- a process whose output is captured silently instead of   shown immediately</li> <li>Foreground -- the normal mode where a command's output is shown right away</li> <li><code>&amp;</code> operator -- the ampersand at the end of a command that triggers   background execution</li> <li>Job number -- a small number like <code>[1]</code> or <code>[2]</code> that the shell assigns   for your convenience (much easier to remember than a PID)</li> </ul>"},{"location":"concepts/shell/#history-and-aliases","title":"History and Aliases","text":""},{"location":"concepts/shell/#history","title":"History","text":"<p>The shell remembers every command you type. It's like a diary of your entire session. Type <code>history</code> and you'll see a numbered list of everything you've run:</p> <pre><code>  1  ls /\n  2  mkdir /data\n  3  touch /data/notes.txt\n  4  cat /data/notes.txt\n</code></pre> <p>This is useful when you want to remember what you did, or when you want to double-check the exact command you ran earlier.</p>"},{"location":"concepts/shell/#aliases","title":"Aliases","text":"<p>An alias is a shortcut you create. Let's say you're tired of typing <code>ls /</code> over and over. You can make a shortcut:</p> <pre><code>alias ll=ls /\n</code></pre> <p>Now typing <code>ll</code> does the exact same thing as typing <code>ls /</code>. The shell sees <code>ll</code>, checks its alias list, and quietly replaces it with <code>ls /</code> before running anything.</p> <p>Think of aliases like speed dial on a phone. Instead of dialing a full number every time, you press one button and the phone fills in the rest.</p> <p>Use <code>alias</code> with no arguments to see all your current aliases, and <code>unalias &lt;name&gt;</code> to remove one.</p>"},{"location":"concepts/shell/#tab-completion","title":"Tab Completion","text":"<p>You know how your phone suggests the rest of a word while you're typing? Tab completion works the same way. Start typing a command, press the Tab key, and the shell fills in the rest for you. If there's more than one possibility, press Tab twice to see all the options.</p> <p>For example, type <code>he</code> and press Tab -- the shell completes it to <code>help</code> because that's the only command starting with \"he\". Type <code>ls /</code> and press Tab -- you'll see every file and directory in the root folder.</p> <p>Tab completion isn't just for commands. It works in several contexts depending on what you're typing:</p> Where you are What completes First word on the line Command names (<code>ls</code>, <code>cat</code>, <code>mkdir</code>, ...) After <code>scheduler</code>, <code>mutex</code>, <code>semaphore</code>, <code>rwlock</code>, <code>journal</code>, <code>pi</code>, <code>ordering</code>, <code>shm</code>, <code>dns</code>, <code>socket</code>, <code>http</code>, <code>proc</code> Subcommands (<code>fcfs</code>, <code>create</code>, <code>list</code>, <code>status</code>, <code>demo</code>, <code>register</code>, <code>mode</code>, <code>violations</code>, ...) After a file command (<code>ls</code>, <code>cat</code>, <code>rm</code>, ...) Filesystem paths After <code>run</code> Built-in program names After <code>unset</code> Environment variable names After <code>signal &lt;pid&gt;</code> or <code>handle &lt;pid&gt;</code> Signal names (<code>SIGTERM</code>, <code>SIGKILL</code>, ...) <code>$</code> prefix anywhere Environment variable names with <code>$</code> prefix <p>Under the hood, this works by importing Python's <code>readline</code> module and giving it a completer function. Every time you press Tab, readline calls that function with whatever partial text you've typed so far. The completer looks at the context -- which command you're typing, where in the line you are -- and returns a list of suggestions. All the logic lives in a separate <code>Completer</code> class so it can be tested without any I/O.</p>"},{"location":"concepts/shell/#vocabulary_3","title":"Vocabulary","text":"<ul> <li>Tab completion -- pressing Tab to auto-fill a partial command, path, or   name</li> <li>Completer -- the code that decides what suggestions to offer based on   context</li> <li>readline -- a library that adds line-editing features (Tab completion,   arrow keys, history) to terminal input</li> </ul>"},{"location":"concepts/shell/#environment-variables","title":"Environment Variables","text":"<p>Environment variables are like sticky notes on your desk. Each one has a name and a value, and they store settings that any program can read:</p> <pre><code>USER=rob\nHOME=/root\nPATH=/bin\n</code></pre> <p>To set one:</p> <pre><code>export GREETING=hello\n</code></pre> <p>To see all of them:</p> <pre><code>env\n</code></pre> <p>To use one in a command, put a <code>$</code> in front of the name:</p> <pre><code>echo $GREETING\n</code></pre> <p>That prints <code>hello</code>.</p> <p>Here's something neat: when you <code>fork</code> a process (create a copy of it), the child process gets its own copy of all the environment variables. If the child changes a variable, the parent's copy stays the same. It's like photocopying all your sticky notes for a coworker -- they can scribble on their copies all they want, and your originals are untouched.</p> <p>This is actually an important concept in real operating systems. It's how parent processes pass configuration to their children without worrying about the children messing up the parent's settings. The kernel handles the copying when a fork happens.</p>"},{"location":"concepts/shell/#putting-it-all-together","title":"Putting It All Together","text":"<p>The shell is your window into the operating system. It takes your plain-English (well, plain-command) requests, translates them into system calls, and gives you back the results. It adds convenience features on top -- pipes, scripts, job control, history, aliases, tab completion, variables -- that make the raw power of the kernel accessible and pleasant to use.</p> <p>If the kernel is the engine of a car, the shell is the steering wheel, the pedals, and the dashboard. You don't need to understand every piston and valve to drive somewhere, but it sure helps to know what all those controls do.</p> <p>Next up, you might want to read about the kernel to see what happens on the other side of those system calls.</p>"},{"location":"concepts/synchronization/","title":"Synchronization","text":"<p>When multiple threads share data, things can go wrong fast. Without coordination, two threads might update the same variable at the same time, creating a race condition -- the result depends on which thread happens to run first.</p> <p>Synchronization primitives solve this. They are the traffic lights and turnstiles of concurrent programming.</p>"},{"location":"concepts/synchronization/#the-problem-race-conditions","title":"The Problem: Race Conditions","text":"<p>Imagine two threads both trying to increment a counter:</p> <pre><code>Thread A reads counter (value: 5)\nThread B reads counter (value: 5)\nThread A writes counter = 6\nThread B writes counter = 6    &lt;-- should be 7!\n</code></pre> <p>One increment was lost. This is a data race: both threads read the old value before either wrote the new one.</p>"},{"location":"concepts/synchronization/#mutex-mutual-exclusion","title":"Mutex (Mutual Exclusion)","text":"<p>Analogy: A bathroom lock.</p> <p>A mutex is the simplest synchronization tool. Only one thread can hold it at a time. If another thread tries to acquire it, they wait in a queue until the holder releases it.</p> <pre><code>Thread A: acquire lock  -&gt; success, enters critical section\nThread B: acquire lock  -&gt; blocked, added to wait queue\nThread A: release lock  -&gt; Thread B wakes up and acquires\nThread B: release lock  -&gt; lock is free\n</code></pre> <p>Key rules: - Only the thread that locked it can unlock it (owner tracking) - Waiters are served in FIFO order (no starvation) - Forgetting to release causes deadlock</p> <p>Shell usage:</p> <pre><code>mutex create mylock\nmutex list\n</code></pre>"},{"location":"concepts/synchronization/#semaphore-counting-lock","title":"Semaphore (Counting Lock)","text":"<p>Analogy: A parking lot with limited spaces.</p> <p>A semaphore is like a mutex, but instead of allowing only 1 holder, it allows up to N concurrent holders. Each <code>acquire</code> decrements the count; each <code>release</code> increments it. When the count reaches zero, new arrivals wait.</p> <pre><code>Semaphore \"parking\" (count=3)\n\nCar A enters  -&gt; count=2\nCar B enters  -&gt; count=1\nCar C enters  -&gt; count=0\nCar D arrives -&gt; blocked (lot is full)\nCar A leaves  -&gt; count stays 0, Car D enters\n</code></pre> <p>Special cases: - Binary semaphore (count=1): behaves like a mutex - Bounded semaphore: enforces a maximum count to prevent accidental over-releasing</p> <p>Shell usage:</p> <pre><code>semaphore create parking 3\nsemaphore list\n</code></pre>"},{"location":"concepts/synchronization/#condition-variable-waitnotify","title":"Condition Variable (Wait/Notify)","text":"<p>Analogy: A waiting room where you sit until your name is called.</p> <p>A condition variable lets threads wait for some condition to become true. It is always paired with a mutex:</p> <ol> <li>Thread acquires mutex</li> <li>Checks the condition -- if not met, calls <code>wait</code></li> <li><code>wait</code> atomically releases the mutex and puts the thread to sleep</li> <li>Another thread changes the data, then calls <code>notify</code> or <code>notify_all</code></li> <li>The waiting thread wakes up and re-acquires the mutex</li> </ol> <p>This is the standard producer-consumer pattern: the producer adds items and notifies; the consumer waits until items are available.</p>"},{"location":"concepts/synchronization/#reader-writer-lock-rwlock","title":"Reader-Writer Lock (RWLock)","text":"<p>Analogy: A museum exhibit.</p> <p>Imagine a famous painting in a museum. Any number of visitors (readers) can look at the painting at the same time -- they don't interfere with each other. But when a restorer (writer) needs to work on the painting, they close the room. Visitors already inside can finish looking, but no new visitors are let in until the restorer is done.</p> <p>A reader-writer lock works the same way: - Multiple readers can hold the lock at the same time - Only one writer can hold the lock, and nobody else (no readers, no other writers) - This is perfect for data that gets read much more often than it gets written (config files, caches, lookup tables)</p> <pre><code>Thread A: acquire_read   -&gt; success (1 reader)\nThread B: acquire_read   -&gt; success (2 readers)\nThread C: acquire_write  -&gt; blocked, added to wait queue\nThread D: acquire_read   -&gt; blocked behind writer (writer-preference!)\nThread A: release_read   -&gt; nothing happens (B still reading)\nThread B: release_read   -&gt; 0 readers, C wakes up (writer goes next)\nThread C: release_write  -&gt; D wakes up (reader gets in)\n</code></pre>"},{"location":"concepts/synchronization/#writer-preference","title":"Writer-Preference","text":"<p>Notice that Thread D was blocked even though it was a reader. This is writer-preference: when a writer is waiting in line, new readers queue behind it rather than jumping ahead. Without this rule, a steady stream of readers could starve the writer forever -- the writer would never get a turn.</p> <p>Shell usage:</p> <pre><code>rwlock create db_lock\nrwlock list\n</code></pre>"},{"location":"concepts/synchronization/#priority-inversion","title":"Priority Inversion","text":"<p>Analogy: Three students and one textbook.</p> <p>Imagine a classroom with three students who all need the same textbook:</p> <ul> <li>Slow Student (low priority) -- currently has the textbook and is reading</li> <li>Fast Student (high priority) -- needs the textbook urgently</li> <li>Normal Student (medium priority) -- doesn't need the textbook at all</li> </ul> <p>The teacher (scheduler) always calls on the highest-priority student who is ready to work. Here's the problem:</p> <ol> <li>Slow Student has the textbook and is reading chapter 3</li> <li>Fast Student raises their hand -- \"I need that textbook!\" But Slow Student still has it</li> <li>Normal Student doesn't need the textbook, so they're ready to work</li> <li>The teacher keeps calling on Normal Student (priority 5) instead of Slow Student (priority 1)</li> <li>Slow Student never gets a turn, so they can never finish and return the textbook</li> <li>Fast Student is stuck forever!</li> </ol> <p>This is priority inversion: the high-priority task is effectively running at the lowest priority because it's blocked behind the low-priority holder, and medium-priority tasks keep jumping ahead.</p>"},{"location":"concepts/synchronization/#the-mars-pathfinder-bug","title":"The Mars Pathfinder Bug","text":"<p>This exact problem happened on Mars in 1997. NASA's Pathfinder rover had three tasks:</p> <ul> <li>A low-priority task that collected weather data (and held a shared mutex)</li> <li>A high-priority task that managed the communication bus</li> <li>Medium-priority tasks that ran science experiments</li> </ul> <p>The high-priority bus manager kept getting starved. A watchdog timer detected the failure and rebooted the rover -- over and over. Engineers on Earth diagnosed the problem and uploaded a fix: priority inheritance.</p> <p>Shell usage:</p> <pre><code>pi demo     # Walk through the Mars Pathfinder scenario step by step\npi status   # See which processes are currently boosted\n</code></pre>"},{"location":"concepts/synchronization/#priority-inheritance","title":"Priority Inheritance","text":"<p>The fix: temporarily boost the slow student.</p> <p>Priority inheritance is the kernel's solution to priority inversion. When a high-priority thread blocks on a mutex held by a lower-priority thread, the kernel temporarily boosts the holder's priority to match the waiter's.</p> <p>Back to our classroom:</p> <ol> <li>Fast Student says \"I need the textbook\"</li> <li>The teacher sees Fast Student is blocked waiting for Slow Student</li> <li>The teacher says \"Slow Student, you're temporarily promoted to priority 10!\"</li> <li>Now the teacher calls on Slow Student (priority 10) instead of Normal Student (priority 5)</li> <li>Slow Student finishes quickly, returns the textbook</li> <li>Slow Student drops back to priority 1</li> <li>Fast Student gets the textbook and proceeds</li> </ol>"},{"location":"concepts/synchronization/#transitive-inheritance","title":"Transitive Inheritance","text":"<p>What if Slow Student is also waiting for something? The boost propagates through the chain:</p> <pre><code>Fast Student (priority=10) blocked on Textbook, held by Normal Student (priority=5)\nNormal Student also blocked on Calculator, held by Slow Student (priority=1)\n\nResult: Slow Student boosted to 10, Normal Student boosted to 10\nWhen Slow Student returns Calculator -&gt; Normal Student gets it, Slow Student drops to 1\nWhen Normal Student returns Textbook -&gt; Fast Student gets it, Normal Student drops to 5\n</code></pre> <p>The kernel walks the chain of \"who is blocked on what\" and boosts everyone in the path. Loop detection (via a visited set) prevents infinite chains.</p>"},{"location":"concepts/synchronization/#how-it-works","title":"How It Works","text":"<p>Each process has two priority values:</p> <ul> <li>Base priority -- the original, immutable priority set at creation</li> <li>Effective priority -- what the scheduler actually uses (may be boosted)</li> </ul> <p>When no inheritance is active, <code>effective_priority == base_priority</code>. When a boost happens, only the effective priority changes. When the mutex is released, the kernel recalculates: it looks at all mutexes the process still holds, finds the highest-priority waiter across all of them, and sets <code>effective_priority = max(base_priority, max_waiter_priority)</code>.</p>"},{"location":"concepts/synchronization/#deadlock","title":"Deadlock","text":"<p>Deadlock is the nightmare scenario: two or more processes are stuck forever, each holding a resource the other needs. Nobody can move. It's like two people in a narrow hallway, each refusing to step aside.</p>"},{"location":"concepts/synchronization/#the-four-coffman-conditions","title":"The Four Coffman Conditions","text":"<p>In 1971, computer scientists Coffman, Elphick, and Shoshani proved that deadlock can only happen when all four of these conditions hold at the same time:</p> <ol> <li>Mutual exclusion -- a resource can only be used by one process at a time    (like a bathroom with a lock).</li> <li>Hold and wait -- a process can hold resources while waiting for more    (like a student holding one textbook while asking for another).</li> <li>No preemption -- you can't forcibly take a resource from someone    (no grabbing the textbook out of their hands).</li> <li>Circular wait -- A waits for B, B waits for A, forming a circle    (like two people at a revolving door, each waiting for the other to go first).</li> </ol> <p>Break any one of these and deadlock becomes impossible.</p>"},{"location":"concepts/synchronization/#deadlock-prevention-resource-ordering","title":"Deadlock Prevention: Resource Ordering","text":"<p>PyOS prevents deadlock by attacking the circular wait condition using resource ordering.</p> <p>Analogy: Numbered lockers in a school hallway. The rule: you can only walk forward. If you need locker 3 and locker 7, open 3 first, then walk forward to 7. You can never go backwards. Nobody ever gets stuck in a circle.</p> <p>Here's why this works: imagine you need lockers 3 and 7, and your friend needs lockers 7 and 3. With the \"always go forward\" rule:</p> <ul> <li>You open locker 3 first, then walk to 7.</li> <li>Your friend also opens locker 3 first (they can't start at 7!), then walks to 7.</li> <li>No circle is possible because everyone walks the same direction.</li> </ul> <p>In PyOS, every resource (mutex, semaphore, reader-writer lock) gets a numeric rank. Before a process acquires a resource, the kernel checks: \"Is this rank higher than everything I already hold?\" If yes, allowed. If no, it's a violation.</p>"},{"location":"concepts/synchronization/#three-modes","title":"Three Modes","text":"Mode What happens on violation strict Reject the acquire -- the process can't get the resource warn Allow it, but record the violation for debugging off No checking at all (maximum performance) <p>Shell usage:</p> <pre><code>ordering mode strict\nordering register mutex:lock_a 1\nordering register mutex:lock_b 2\nordering status\nordering violations\nordering demo\n</code></pre>"},{"location":"concepts/synchronization/#prevention-vs-detection","title":"Prevention vs. Detection","text":"<p>PyOS has two complementary approaches to deadlock:</p> Aspect Prevention (ordering) Detection (Banker's algorithm) When Before deadlock happens After deadlock happens How Structural rule (rank ordering) Periodic scan (safety check) Overhead One comparison per acquire Full matrix computation Guarantee Deadlock impossible Deadlock found and reported Trade-off May reject valid acquires Doesn't prevent deadlock Module <code>sync/ordering.py</code> <code>sync/deadlock.py</code> <p>Think of it this way: ordering is like a one-way street (prevents collisions), while detection is like a traffic camera (catches collisions after they happen). Best practice is to use both: ordering prevents most deadlocks cheaply, and detection catches any that slip through.</p>"},{"location":"concepts/synchronization/#how-it-works-in-pyos","title":"How It Works in PyOS","text":"<p>PyOS implements all four primitives in <code>sync/primitives.py</code>, plus priority inheritance in <code>sync/inheritance.py</code> and deadlock prevention in <code>sync/ordering.py</code>:</p> Class Purpose Key Methods <code>Mutex</code> Mutual exclusion <code>acquire(tid)</code>, <code>release(tid)</code>, <code>waiters</code> <code>Semaphore</code> Counting lock <code>acquire(tid)</code>, <code>release()</code> <code>Condition</code> Wait/notify <code>wait(tid)</code>, <code>notify()</code>, <code>notify_all()</code> <code>ReadWriteLock</code> Multiple readers / one writer <code>acquire_read(tid)</code>, <code>acquire_write(tid)</code>, <code>release_read(tid)</code>, <code>release_write(tid)</code> <code>SyncManager</code> Registry <code>create_mutex()</code>, <code>create_semaphore()</code>, <code>create_condition()</code>, <code>create_rwlock()</code> <code>PriorityInheritanceManager</code> Prevent priority inversion <code>on_acquire()</code>, <code>on_block()</code>, <code>on_release()</code> <code>ResourceOrderingManager</code> Prevent deadlock (resource ordering) <code>register()</code>, <code>check_acquire()</code>, <code>on_acquire()</code>, <code>on_release()</code> <p>The kernel owns a <code>SyncManager</code>, a <code>PriorityInheritanceManager</code>, and a <code>ResourceOrderingManager</code>, all created during boot and torn down during shutdown. All user-space access goes through system calls (91-93, 110-125), and the shell provides <code>mutex</code>, <code>semaphore</code>, <code>rwlock</code>, <code>pi</code>, and <code>ordering</code> commands.</p> <p>The <code>PriorityInheritanceManager</code> tracks which process holds each mutex, which processes are blocked waiting, and coordinates priority boosts. The Mutex itself stays simple -- all coordination logic lives in the PI manager.</p>"},{"location":"concepts/synchronization/#syscall-interface","title":"Syscall Interface","text":"Number Name What It Does 110 SYS_CREATE_MUTEX Create a named mutex 111 SYS_ACQUIRE_MUTEX Lock a mutex (or queue if held); optional <code>pid</code> enables PI tracking 112 SYS_RELEASE_MUTEX Unlock a mutex; optional <code>pid</code> triggers priority recalculation 113 SYS_CREATE_SEMAPHORE Create a counting semaphore 114 SYS_ACQUIRE_SEMAPHORE Decrement semaphore (or queue if zero) 115 SYS_RELEASE_SEMAPHORE Increment semaphore 116 SYS_CREATE_CONDITION Create a condition variable 117 SYS_CONDITION_WAIT Wait on a condition 118 SYS_CONDITION_NOTIFY Wake waiters on a condition 119 SYS_CREATE_RWLOCK Create a reader-writer lock 122 SYS_ACQUIRE_READ_LOCK Acquire read access (or queue) 123 SYS_ACQUIRE_WRITE_LOCK Acquire write access (or queue) 124 SYS_RELEASE_READ_LOCK Release read access 125 SYS_RELEASE_WRITE_LOCK Release write access <p>No new syscall numbers were added for priority inheritance -- the existing <code>SYS_ACQUIRE_MUTEX</code> (111) and <code>SYS_RELEASE_MUTEX</code> (112) accept an optional <code>pid</code> parameter that activates PI tracking.</p> <p>Deadlock prevention syscalls:</p> Number Name What It Does 91 SYS_CHECK_ORDERING Return ordering status (mode, ranks, violations) 92 SYS_SET_ORDERING_MODE Set enforcement mode (strict/warn/off) 93 SYS_REGISTER_RANK Register a resource with an explicit rank"},{"location":"concepts/synchronization/#real-world-examples","title":"Real-World Examples","text":"<ul> <li>Mutex: Protecting a shared log file so lines don't interleave</li> <li>Semaphore: Limiting database connections to a pool of 10</li> <li>Condition: A print queue where the printer waits for jobs to arrive</li> <li>Reader-writer lock: A configuration file that many threads read but only one thread updates</li> <li>Priority inheritance: The Mars Pathfinder rover fix -- preventing high-priority tasks from starving when they need a mutex held by a low-priority task</li> </ul>"},{"location":"concepts/synchronization/#where-to-go-next","title":"Where to Go Next","text":"<p>With synchronization in place, you have the tools to build higher-level patterns like thread-safe queues and barriers. These primitives are the building blocks of every concurrent system, from web servers to operating systems.</p> <ul> <li>Processes -- How threads live inside processes, plus fork, signals, and wait/waitpid</li> <li>Users and Safety -- Deadlock detection and how the OS keeps things safe</li> <li>Devices and Networking -- IPC pipes and message queues that use these primitives under the hood</li> <li>The Shell -- The <code>mutex</code>, <code>semaphore</code>, and <code>rwlock</code> shell commands</li> </ul>"},{"location":"concepts/tcp/","title":"TCP: Reliable Delivery","text":"<p>Imagine sending a jigsaw puzzle to a friend through the post. You cannot fit the whole puzzle in one envelope, so you split it into numbered pieces and send each piece in its own envelope. Your friend checks the numbers, puts the pieces in order, and tells you which ones arrived safely. If any go missing, you send them again. That is TCP.</p>"},{"location":"concepts/tcp/#what-is-tcp","title":"What Is TCP?","text":"<p>TCP (Transmission Control Protocol) sits between the application layer (HTTP, DNS) and the network layer (IP). It turns unreliable, unordered network delivery into a reliable, ordered byte stream.</p> <p>TCP gives you four guarantees:</p> <ol> <li>Reliable delivery -- lost segments are detected and retransmitted.</li> <li>Ordered delivery -- segments arrive in the correct sequence.</li> <li>Flow control -- the receiver tells the sender how much room it has.</li> <li>Congestion control -- the sender slows down when the network is busy.</li> </ol> <p>Without TCP, applications would have to handle all of this themselves. With TCP, they just send and receive bytes.</p>"},{"location":"concepts/tcp/#the-three-way-handshake","title":"The Three-Way Handshake","text":"<p>Before two computers can exchange data, they need to agree to start a conversation. TCP uses a three-way handshake:</p> <pre><code>Client                         Server\n  |                              |\n  |--- SYN (seq=0) ------------&gt;|   \"Hey, want to talk?\"\n  |                              |\n  |&lt;-- SYN+ACK (seq=0, ack=1) --|   \"Sure, let's talk!\"\n  |                              |\n  |--- ACK (ack=1) ------------&gt;|   \"Great, we're connected!\"\n  |                              |\n</code></pre> <ul> <li>SYN -- \"synchronise\" -- the client proposes a starting sequence number.</li> <li>SYN+ACK -- the server agrees and proposes its own sequence number.</li> <li>ACK -- the client acknowledges. Both sides are now ESTABLISHED.</li> </ul> <p>In PyOS:</p> <pre><code>tcp listen 80\ntcp connect 5000 80\n</code></pre>"},{"location":"concepts/tcp/#sequence-numbers-and-acknowledgements","title":"Sequence Numbers and Acknowledgements","text":"<p>Every byte of data has a sequence number. When the receiver gets data, it sends back an ACK with the next sequence number it expects. This is how the sender knows what arrived safely.</p> <pre><code>Sender                           Receiver\n  |                                |\n  |--- data (seq=1, 5 bytes) ----&gt;|\n  |                                |\n  |&lt;-- ACK (ack=6) ---------------|   \"Got it, send byte 6 next\"\n  |                                |\n</code></pre> <p>If the sender does not get an ACK within a timeout, it retransmits the data.</p>"},{"location":"concepts/tcp/#flow-control-the-sliding-window","title":"Flow Control: The Sliding Window","text":"<p>The receiver advertises a receive window -- the number of segments it can accept right now. The sender must not send more than this window allows.</p> <p>Think of it like a mailbox with limited space. If the mailbox is full, the postman waits until you empty it before delivering more.</p> <pre><code>Receiver says: \"window_size = 8\"\n\u2192 Sender can have at most 8 segments in flight at once\n</code></pre>"},{"location":"concepts/tcp/#congestion-control-dont-flood-the-network","title":"Congestion Control: Don't Flood the Network","text":"<p>Even if the receiver has room, the network might be busy. TCP uses congestion control to avoid overwhelming the network:</p>"},{"location":"concepts/tcp/#slow-start","title":"Slow Start","text":"<p>Start slow and ramp up quickly:</p> <ol> <li>Begin with a congestion window (cwnd) of 1 segment.</li> <li>For each ACK received, increase cwnd by 1.</li> <li>This means cwnd doubles every round trip -- exponential growth!</li> <li>Keep growing until cwnd reaches the slow-start threshold (ssthresh).</li> </ol>"},{"location":"concepts/tcp/#congestion-avoidance-aimd","title":"Congestion Avoidance (AIMD)","text":"<p>Once cwnd reaches ssthresh, switch to cautious growth:</p> <ul> <li>Additive Increase -- increase cwnd by 1 per round trip (linear growth).</li> <li>Multiplicative Decrease -- on timeout, set ssthresh = cwnd / 2 and reset cwnd to 1.</li> </ul> <p>This \"AIMD\" pattern creates a sawtooth shape: cwnd grows slowly, drops sharply on loss, then grows again.</p> <pre><code>cwnd\n  ^\n  |    /\\      /\\      /\\\n  |   /  \\    /  \\    /  \\\n  |  /    \\  /    \\  /    \\\n  | /      \\/      \\/      \\\n  +----------------------------&gt; time\n</code></pre> <p>In PyOS, you can see the congestion state:</p> <pre><code>tcp info 1\n\nConnection 1:\n  State:            ESTABLISHED\n  cwnd:             4\n  ssthresh:         16\n  effective_window: 4\n  unacked:          0\n</code></pre>"},{"location":"concepts/tcp/#the-effective-window","title":"The Effective Window","text":"<p>The sender's actual limit is the effective window: the smaller of cwnd and the receiver's advertised window.</p> <pre><code>effective_window = min(cwnd, peer_recv_window)\n</code></pre> <p>This ensures the sender respects both the receiver's capacity and the network's capacity.</p>"},{"location":"concepts/tcp/#retransmission","title":"Retransmission","text":"<p>If a segment is not acknowledged within a timeout period, the sender assumes it was lost and retransmits:</p> <ol> <li>Start a timer when a segment is sent.</li> <li>If the timer expires before an ACK arrives, retransmit the oldest unacknowledged segment.</li> <li>Apply multiplicative decrease: ssthresh = cwnd / 2, cwnd = 1.</li> </ol> <p>In PyOS, retransmission is driven by <code>kernel.tick()</code>. The default timeout is 10 ticks.</p>"},{"location":"concepts/tcp/#graceful-close","title":"Graceful Close","text":"<p>When both sides are done, they close the connection with a four-way close:</p> <pre><code>Client                         Server\n  |                              |\n  |--- FIN ----------------------&gt;|   \"I'm done sending\"\n  |&lt;-- ACK ----------------------|   \"OK, I heard you\"\n  |                              |\n  |&lt;-- FIN ----------------------|   \"I'm done too\"\n  |--- ACK ----------------------&gt;|   \"OK, goodbye\"\n  |                              |\n</code></pre> <p>After the final ACK, the connection enters TIME_WAIT briefly to handle any delayed segments, then closes.</p>"},{"location":"concepts/tcp/#tcp-state-machine","title":"TCP State Machine","text":"<p>A TCP connection moves through 11 states:</p> State Meaning CLOSED No connection LISTEN Waiting for incoming SYN SYN_SENT SYN sent, waiting for SYN+ACK SYN_RECEIVED SYN received, SYN+ACK sent ESTABLISHED Connected, data flows FIN_WAIT_1 FIN sent, waiting for ACK FIN_WAIT_2 FIN acknowledged, waiting for peer's FIN TIME_WAIT Both FINs acknowledged, waiting before close CLOSE_WAIT Peer's FIN received, waiting to close LAST_ACK FIN sent, waiting for final ACK CLOSING Both sides sent FIN simultaneously"},{"location":"concepts/tcp/#try-it-yourself","title":"Try It Yourself","text":"<p>Boot PyOS and run the interactive lesson:</p> <pre><code>learn tcp\n</code></pre> <p>Or experiment manually:</p> <pre><code>tcp listen 80              # Server listens on port 80\ntcp connect 5000 80        # Client connects from port 5000\ntcp send 2 \"Hello!\"        # Send data on connection 2\ntcp recv 3                 # Receive data on connection 3\ntcp info 2                 # See congestion/flow control state\ntcp close 2                # Graceful close\ntcp list                   # See all connections\n</code></pre> <p>Or run the built-in demo:</p> <pre><code>tcp demo\n</code></pre> <p>Previous: Learn about hardware events in Interrupts and Timers.</p>"},{"location":"concepts/tutorials/","title":"Interactive Tutorials","text":""},{"location":"concepts/tutorials/#what-are-tutorials","title":"What Are Tutorials?","text":"<p>Imagine you just got a brand-new video game. You could read the manual, but most games start with a tutorial level that teaches you the controls while you play. PyOS tutorials work the same way -- they teach you OS concepts by running real commands and showing you what happens, step by step.</p>"},{"location":"concepts/tutorials/#how-they-work","title":"How They Work","text":"<p>Each tutorial is a lesson that:</p> <ol> <li>Introduces a concept with a friendly analogy (like comparing    processes to recipes in a kitchen).</li> <li>Runs real syscalls so you can see the OS doing actual work --    creating processes, allocating memory, writing files, and more.</li> <li>Explains what happened after each step, so you understand why    the OS did what it did.</li> <li>Summarises what you learned and suggests the next lesson.</li> </ol> <p>Behind the scenes, the <code>TutorialRunner</code> class in <code>tutorials.py</code> calls the same kernel syscalls that the shell uses. Nothing is faked -- you are watching the real operating system in action.</p>"},{"location":"concepts/tutorials/#available-lessons","title":"Available Lessons","text":"Lesson Analogy What You Learn <code>processes</code> Recipes and cooks How the OS creates, runs, and tracks programs <code>memory</code> Warehouse with shelves How the OS divides RAM into frames and pages <code>filesystem</code> A library How files and directories are organised on disk <code>scheduling</code> Sports-day coaches How the OS decides which process runs next <code>signals</code> School bells How processes send notifications to each other <code>ipc</code> A shared mailbox How processes share data through shared memory <code>networking</code> A phone system How DNS and sockets let programs talk over a network <code>interrupts</code> Doorbells How hardware devices get the CPU's attention <code>tcp</code> Numbered postcards How TCP guarantees reliable, ordered delivery"},{"location":"concepts/tutorials/#running-tutorials","title":"Running Tutorials","text":"<p>From the PyOS shell, use the <code>learn</code> command:</p> <pre><code>PyOS&gt; learn              # list all available lessons\nPyOS&gt; learn processes    # run the processes lesson\nPyOS&gt; learn all          # run every lesson in order\n</code></pre> <p>Tab completion works too -- type <code>learn p</code> and press Tab to complete <code>processes</code>.</p>"},{"location":"concepts/tutorials/#why-tutorials-matter","title":"Why Tutorials Matter","text":"<p>Reading about an operating system is one thing. Watching one work is another. Tutorials bridge that gap by letting you see concepts in action without needing to write any code yourself. They are a great starting point before you explore the shell commands on your own.</p>"},{"location":"concepts/tutorials/#where-to-go-next","title":"Where to Go Next","text":"<ul> <li>What Is an OS? -- Start here if you haven't already</li> <li>The Shell -- All the commands you can type after the tutorials</li> <li>Web UI -- Run PyOS from your browser instead of the terminal</li> </ul>"},{"location":"concepts/users-and-safety/","title":"Users and Safety","text":"<p>Your computer is not just for you. Even if you are the only person sitting at the keyboard, there are dozens of programs running at the same time -- a web browser, a music player, background updaters. The operating system needs to keep track of who is allowed to do what, handle emergencies when things go wrong, keep a record of everything that happened, and prevent programs from getting stuck in traffic jams. This page covers all four of those jobs.</p>"},{"location":"concepts/users-and-safety/#users-and-permissions","title":"Users and Permissions","text":"<p>Think of a school library. Every student has a library card with a unique number printed on it. When you check out a book, the librarian stamps your card number on the back cover. Now anyone who picks up that book can see who checked it out.</p> <p>An operating system works the same way.</p>"},{"location":"concepts/users-and-safety/#uids-and-usernames","title":"UIDs and Usernames","text":"<p>Every user gets two things when their account is created:</p> Field What it is Example UID A unique ID number (like your library card number) <code>0</code>, <code>1</code>, <code>1000</code> Username A human-friendly name <code>\"alice\"</code>, <code>\"bob\"</code>, <code>\"root\"</code> <p>The UID is what the system actually uses behind the scenes. The username is just a label so humans do not have to memorize numbers.</p>"},{"location":"concepts/users-and-safety/#file-ownership","title":"File Ownership","text":"<p>When you create a file, your UID gets stamped on it. You are now the owner of that file. This is exactly like the librarian stamping your card number on a book -- the file knows who made it.</p>"},{"location":"concepts/users-and-safety/#permissions","title":"Permissions","text":"<p>Owning a file is not enough on its own. The system also tracks what you are allowed to do with each file. Permissions answer two questions for two groups of people:</p> Can they read it? Can they write to it? Owner (the person who made the file) Maybe Maybe Everyone else Maybe Maybe <p>Each of those four slots is either \"yes\" or \"no.\" When you create a file, you decide the initial permissions. For example, you might say \"I can read and write this file, but everyone else can only read it.\" That way, other users can look at your homework but they cannot change your answers.</p>"},{"location":"concepts/users-and-safety/#the-root-user","title":"The root User","text":"<p>There is one special user that exists on every system: root, who always has UID 0.</p> <p>Root is like the school principal. The principal can walk into any classroom, open any locker, and read any file in the school office. There are no locked doors for the principal. In the same way, root can read and write any file on the system, regardless of what the permissions say. Root is sometimes called the superuser because they have super-powered access to everything.</p> <p>On a real Unix system, root can do absolutely anything -- install programs, delete other users, change system settings, even break the operating system. That is why you should only use root when you truly need it. Running as root all the time is like leaving every door in the school unlocked. It works, but it is asking for trouble.</p>"},{"location":"concepts/users-and-safety/#try-it-in-the-pyos-shell","title":"Try it in the PyOS shell","text":"<pre><code>pyos&gt; whoami\nalice (uid=1000)\n\npyos&gt; adduser bob\nUser 'bob' created with uid=1001\n\npyos&gt; su bob\nSwitched to user 'bob'\n\npyos&gt; whoami\nbob (uid=1001)\n</code></pre> <ul> <li><code>whoami</code> -- tells you which user you are right now.</li> <li><code>adduser</code> -- creates a new user account.</li> <li><code>su</code> -- short for \"switch user.\" It lets you become a different user, kind of like handing your library card to someone else (except you get it back later).</li> </ul>"},{"location":"concepts/users-and-safety/#signals","title":"Signals","text":"<p>Imagine you are sitting in class, focused on your work. Someone taps you on the shoulder. You look up. That tap is a signal -- a small message sent from one process to another (or from the operating system to a process) that says \"hey, pay attention.\"</p> <p>Different taps mean different things.</p>"},{"location":"concepts/users-and-safety/#the-six-signals","title":"The Six Signals","text":"Signal What it means Real-life version Can you catch it? Default action SIGKILL (9) \"STOP RIGHT NOW.\" Being physically picked up and removed from the room No Terminate SIGUSR1 (10) \"Custom tap #1\" A secret handshake only your friend understands Yes Ignore SIGUSR2 (12) \"Custom tap #2\" A different secret handshake Yes Ignore SIGTERM (15) \"Please stop what you're doing.\" A polite tap on the shoulder Yes Terminate SIGCONT (18) \"Ok, you can move again.\" Someone unfreezes you in freeze tag Yes Continue SIGSTOP (19) \"Freeze! Don't move.\" A game of freeze tag -- you are frozen in place No Stop <p>SIGTERM is the polite way to ask a process to stop. The process receives the signal and gets a chance to wrap up what it is doing -- save files, close connections, say goodbye. Most of the time, this is what you want.</p> <p>SIGKILL is the emergency stop. It can never be caught, blocked, or ignored. The operating system itself handles SIGKILL by immediately yanking the process off the CPU and marking it as TERMINATED. The process does not get a chance to clean up. This sounds harsh, but it is necessary. If a program goes haywire and stops responding to polite requests, you need a guaranteed way to shut it down. That is why <code>kill -9</code> (SIGKILL's number is 9) always works on a real Unix system.</p> <p>SIGSTOP and SIGCONT work together like a pause and play button. SIGSTOP freezes a process in place -- it is still alive, but it is not doing anything. SIGCONT unfreezes it and lets it pick up where it left off. These are useful for debugging or for temporarily suspending a process that is using too many resources. Like SIGKILL, SIGSTOP is uncatchable -- you cannot register a handler for it. This guarantees that you can always pause a process, no matter what.</p>"},{"location":"concepts/users-and-safety/#user-defined-signals-sigusr1-and-sigusr2","title":"User-Defined Signals: SIGUSR1 and SIGUSR2","text":"<p>SIGUSR1 and SIGUSR2 are like custom shoulder taps. They have no built-in meaning -- the operating system does not do anything special when they arrive. By default, they are simply ignored.</p> <p>But a process can register a handler for them, and then they become a private communication channel. Imagine you and your friend agree: \"If I tap you twice on the left shoulder, it means 'check your phone.'\" That tap only means something because you both agreed on it.</p> <p>In real Unix, programs use SIGUSR1 and SIGUSR2 for things like telling a server to reload its configuration file or triggering a status dump. They are completely up to the programmer.</p>"},{"location":"concepts/users-and-safety/#signal-handlers","title":"Signal Handlers","text":"<p>Here is where it gets interesting. A process can set up a signal handler -- a function that runs automatically when a specific signal arrives. Think of it like telling a friend: \"If someone taps me on the left shoulder, remind me to save my work before I turn around.\"</p> <pre><code># \"When I receive SIGTERM, run my cleanup function first\"\nkernel.register_signal_handler(pid, SIGTERM, my_cleanup_function)\n</code></pre> <p>When SIGTERM arrives, instead of the default action (terminating the process), the handler runs instead. The process stays alive. Maybe the handler saves a file. Maybe it sends a goodbye message. Maybe it decides to keep running. The handler replaces the default action -- this is exactly how real Unix works.</p> <p>This is why SIGKILL exists. If a process could catch SIGTERM and just... not stop, you would need an uncatchable signal as a last resort. SIGKILL is that last resort.</p> <p>SIGCONT is special: even if you register a handler for it, the process always resumes. The handler fires in addition to the default resume, not instead of it. This prevents a bug where registering a SIGCONT handler accidentally makes a frozen process unresumable.</p> <p>But here is the critical part: you cannot set a handler for SIGKILL or SIGSTOP. There is no negotiating with them. They do not knock -- they kick the door down. That is by design. If programs could ignore SIGKILL, a broken program could become truly unstoppable, and you would have to restart your entire computer to get rid of it.</p>"},{"location":"concepts/users-and-safety/#logging","title":"Logging","text":"<p>Every school has security cameras. They record what happens throughout the day -- who entered the building in the morning, who went to which classroom, whether anyone tripped the fire alarm. If something goes wrong, you can rewind the footage and figure out what happened.</p> <p>The kernel has its own version of security cameras: the logger. It records events as they happen inside the operating system. When something breaks, the log is the first place you look.</p>"},{"location":"concepts/users-and-safety/#log-levels","title":"Log Levels","text":"<p>Not every event is equally important. The logger uses levels to mark how serious each message is, from least to most important:</p> Level What it means Example DEBUG Tiny details, useful for digging into problems \"System call SYS_READ executed by pid=3\" INFO Normal events, things working as expected \"System booted successfully\" WARNING Something unusual that might become a problem \"Memory usage at 85%\" ERROR Something actually went wrong \"Process 7 crashed with exit code 1\" <p>Think of it this way. DEBUG is like the security camera footage of a student walking through the hallway -- nothing interesting, but useful if you need to retrace someone's steps. INFO is the morning announcement that school is open. WARNING is a note that the library is almost full and might need to start turning people away. ERROR is the fire alarm going off.</p> <p>Every system call gets logged at the DEBUG level. Boot events get logged at INFO. This means the log can get very long very quickly, which is why the levels exist -- you can filter for just WARNINGs and ERRORs when you do not need all the tiny details.</p>"},{"location":"concepts/users-and-safety/#try-it-in-the-pyos-shell_1","title":"Try it in the PyOS shell","text":"<pre><code>pyos&gt; log\n[INFO] System booted at tick 0\n[INFO] User 'root' logged in\n[DEBUG] SYS_CREATE_PROCESS: pid=1 name='init'\n[DEBUG] SYS_EXEC: pid=1 program='hello'\n[WARNING] Memory usage at 85%\n</code></pre> <p>The <code>log</code> command shows you the kernel's log. It is like pulling up the security footage and scrolling through it. When something goes wrong and you are not sure why, the log is your best friend.</p>"},{"location":"concepts/users-and-safety/#deadlock","title":"Deadlock","text":"<p>Imagine two people walking toward each other in a narrow hallway. Each one is carrying a big cardboard box. They meet in the middle. Person A cannot move forward because Person B is in the way. Person B cannot move forward because Person A is in the way. Neither person can back up because, well, they are both stubborn. They are stuck. Forever.</p> <p>That is a deadlock.</p> <p>In operating system terms, a deadlock happens when two or more processes are each waiting for something that only the other one can provide. Nobody can make progress, so everything freezes.</p>"},{"location":"concepts/users-and-safety/#the-four-conditions","title":"The Four Conditions","text":"<p>A deadlock can only happen when ALL four of these conditions are true at the same time. If even one is missing, you are safe.</p> <p>1. Mutual exclusion -- Only one process can use a resource at a time. Think of the narrow hallway: only one person fits through at once. If the hallway were wide enough for both, there would be no problem.</p> <p>2. Hold and wait -- Each process is holding onto one resource AND waiting for another. Each person is holding their box AND waiting for the other person to move. If one of them put their box down, they could squeeze past.</p> <p>3. No preemption -- You cannot force a process to give up its resource. Nobody can force either person to drop their box. In some systems, the OS can forcibly take resources away, which breaks this condition.</p> <p>4. Circular wait -- The waiting forms a circle. A waits for B, and B waits for A. If A was waiting for B but B was not waiting for A (maybe B was waiting for C, who was free), then B could eventually finish and free things up for A.</p> <p>Break any ONE of these four conditions and deadlocks become impossible.</p>"},{"location":"concepts/users-and-safety/#prevention-the-bankers-algorithm","title":"Prevention: The Banker's Algorithm","text":"<p>One approach to dealing with deadlocks is to prevent them from ever happening. The most famous prevention method is called the Banker's Algorithm, and the analogy is right there in the name.</p> <p>Imagine a small-town banker who gives out loans. The banker has a limited amount of money in the vault. Several customers want loans, and the banker knows the maximum each customer might eventually need. Before approving any new loan, the banker asks: \"If I give this loan, will I still have enough money left to make sure everyone can eventually pay me back?\"</p> <p>If the answer is yes, the loan is safe -- go ahead and approve it. If the answer is no, the loan is unsafe -- deny it, even if the customer is upset. Better to say \"not right now\" than to run out of money and leave everyone stuck.</p> <p>The OS does the same thing with resources (like memory or access to devices). Before granting a resource to a process, it checks: \"If I give this out, is there still a sequence where every process can finish?\" If yes, grant it. If no, make the process wait.</p> <p>The downside of prevention is that it is conservative. Sometimes the banker says \"no\" even when things would have been fine. But the upside is powerful: deadlocks literally cannot happen.</p>"},{"location":"concepts/users-and-safety/#detection-find-and-fix","title":"Detection: Find and Fix","text":"<p>The other approach is the opposite philosophy: let processes grab whatever resources they want, but periodically check whether a deadlock has actually occurred.</p> <p>Detection works by looking for circular waits in the system. If Process A is waiting for Process B, and Process B is waiting for Process A, the detector spots that circle and reports it.</p> <p>This approach is more permissive -- processes are never told \"no\" just in case. But you need a plan for what to do when a deadlock is found. Usually, the OS picks one of the stuck processes and terminates it (using SIGKILL) to break the circle. Tough luck for that process, but it frees everyone else.</p>"},{"location":"concepts/users-and-safety/#two-philosophies","title":"Two Philosophies","text":"Prevention (Banker's) Detection When it checks Before granting a resource After the fact, periodically Can deadlocks happen? No, never Yes, but they get caught Downside Sometimes says \"no\" unnecessarily A process might get killed to break the deadlock Best for Systems where deadlocks are unacceptable (medical, aviation) Systems where occasional recovery is fine"},{"location":"concepts/users-and-safety/#try-it-in-the-pyos-shell_2","title":"Try it in the PyOS shell","text":"<pre><code>pyos&gt; resources\nResource Allocation Table:\n  Process 1 holds: [Printer]  waiting for: [Scanner]\n  Process 2 holds: [Scanner]  waiting for: [Printer]\n\npyos&gt; deadlock\nDeadlock detected! Processes 1 and 2 are in a circular wait.\n</code></pre> <ul> <li><code>resources</code> -- shows you which processes are holding which resources and what they are waiting for.</li> <li><code>deadlock</code> -- checks the current state for circular waits and tells you if any processes are stuck.</li> </ul>"},{"location":"concepts/users-and-safety/#putting-it-all-together","title":"Putting It All Together","text":"<p>These four systems work together to keep the operating system running safely and smoothly.</p> <p>Users and permissions make sure that one person cannot mess with another person's files. The filesystem stamps every file with an owner, and the kernel checks permissions before allowing any read or write.</p> <p>Signals give the OS a way to communicate with processes -- politely asking them to stop, forcibly killing them if they refuse, or pausing and resuming them as needed.</p> <p>Logging records everything that happens so you can figure out what went wrong after the fact. Every system call, every boot event, every error gets written down.</p> <p>Deadlock handling prevents or detects situations where processes get permanently stuck waiting for each other, keeping the system from freezing up.</p> <p>Together with processes, memory management, the filesystem, and the kernel, these pieces form the safety net that lets dozens of programs run at the same time without stepping on each other's toes.</p>"},{"location":"concepts/users-and-safety/#key-terms","title":"Key Terms","text":"Term Definition UID User Identifier -- a unique number assigned to each user account root The superuser (UID 0) who can read and write any file on the system Permissions Rules that control who can read and write each file Signal A small message sent to a process to notify it of an event SIGTERM A polite request for a process to stop (can be caught and handled) SIGKILL A forced termination that cannot be caught or ignored SIGSTOP A forced pause that cannot be caught or ignored SIGUSR1 / SIGUSR2 User-defined signals with no built-in meaning (ignored by default) Uncatchable A signal (SIGKILL, SIGSTOP) for which no handler can be registered Signal handler A function that runs automatically when a specific signal is received, replacing the default action Default action What the kernel does when a signal arrives and no handler is registered (terminate, stop, continue, or ignore) Logger The kernel subsystem that records events as they happen Log level A label (DEBUG, INFO, WARNING, ERROR) indicating how serious a log entry is Deadlock A situation where two or more processes are stuck waiting for each other forever Mutual exclusion A resource can only be used by one process at a time Banker's Algorithm A deadlock prevention method that checks whether granting a resource is safe Circular wait A cycle of processes where each is waiting for the next one in the circle"},{"location":"concepts/users-and-safety/#where-to-go-next","title":"Where to Go Next","text":"<ul> <li>Synchronization -- Mutexes, semaphores, and how threads share resources safely</li> <li>Processes -- How the OS creates, runs, and schedules programs</li> <li>The Kernel -- The core of the OS and how programs talk to it</li> </ul>"},{"location":"concepts/web-ui/","title":"Web UI","text":""},{"location":"concepts/web-ui/#what-is-the-web-ui","title":"What Is the Web UI?","text":"<p>The web UI lets you use PyOS from a web browser instead of the terminal. It looks like a dark terminal window with green text on a dark blue background -- just like computers in old movies!</p>"},{"location":"concepts/web-ui/#how-it-works","title":"How It Works","text":"<p>Think of the web UI like a TV remote for your OS:</p> <ol> <li>You type a command in the browser (press a button on the remote).</li> <li>The browser sends that command to a web server running on your    computer (the remote sends a signal to the TV).</li> <li>The server passes the command to the PyOS shell (the TV processes    the signal).</li> <li>The shell's output travels back to the browser (the TV changes    channel).</li> </ol> <p>Behind the scenes, a small Python web framework called Flask handles the communication.  Flask is like a postal worker -- it receives your letters (HTTP requests), delivers them to the right person (the shell), and brings back the reply (JSON responses).</p>"},{"location":"concepts/web-ui/#endpoints","title":"Endpoints","text":"<p>The web server exposes three endpoints:</p> Endpoint Method What It Does <code>/</code> GET Serves the HTML terminal page <code>/api/execute</code> POST Runs a shell command and returns the output <code>/api/status</code> GET Returns whether the OS is running plus a dashboard"},{"location":"concepts/web-ui/#running-the-web-ui","title":"Running the Web UI","text":"<p>Install the optional <code>web</code> extra, then start the server:</p> <pre><code>pip install py-os[web]\npy-os-web\n</code></pre> <p>Open your browser to <code>http://localhost:8080</code> and start typing commands -- just like the regular terminal, but in your browser!</p>"},{"location":"concepts/web-ui/#why-a-web-ui","title":"Why a Web UI?","text":"<p>A web interface makes PyOS accessible to anyone with a browser.  You do not need to install Python or know how to use a terminal.  It is also a great example of the client-server model -- the same pattern used by every website you visit.</p>"},{"location":"concepts/web-ui/#where-to-go-next","title":"Where to Go Next","text":"<ul> <li>The Shell -- All the commands available in the web terminal</li> <li>Interactive Tutorials -- Try the guided lessons from your browser</li> <li>Devices and Networking -- How the client-server model works under the hood</li> </ul>"},{"location":"concepts/what-is-an-os/","title":"What Is an Operating System?","text":"<p>You turn on your computer, click some stuff, maybe open a game or a browser. Everything just... works. But have you ever wondered who is making all of that happen behind the scenes?</p> <p>That would be the operating system (OS for short).</p>"},{"location":"concepts/what-is-an-os/#the-school-principal-analogy","title":"The School Principal Analogy","text":"<p>Imagine a school with no principal, no schedule, and no rules. Hundreds of students show up and try to use the same classrooms, the same art supplies, and the same lunch tables all at once. It would be total chaos.</p> <p>A principal fixes that. They make the schedule, decide who gets which classroom, handle problems when two students fight over the same computer, and keep the whole building running smoothly. The students don't need to worry about any of that -- they just show up and do their work.</p> <p>An operating system is the principal of your computer.</p> <p>The \"students\" are programs -- your browser, your text editor, your game. They all need to use the computer's hardware (the screen, the memory, the hard drive), and they all need to share without stepping on each other. The OS coordinates all of it so every program can do its job without chaos.</p>"},{"location":"concepts/what-is-an-os/#why-does-a-computer-need-an-os","title":"Why Does a Computer Need an OS?","text":"<p>Without an OS, every program you write would have to know how to:</p> <ul> <li>Talk directly to the screen to draw pixels</li> <li>Find free space in memory and claim it</li> <li>Read and write raw data on the hard drive</li> <li>Share the processor with every other program running at the same time</li> </ul> <p>That is a lot of work, and most of it has nothing to do with what your program actually wants to accomplish. It would be like asking every student to also build their own desk, wire their own lights, and cook their own lunch before they could start learning.</p> <p>The OS handles all of that for you. Your program just says \"hey, I need some memory\" or \"save this file for me,\" and the OS takes care of the messy details.</p>"},{"location":"concepts/what-is-an-os/#the-layers-how-it-all-fits-together","title":"The Layers: How It All Fits Together","text":"<p>An OS isn't one big blob of code. It's built in layers, kind of like a school building.</p> <p>The Shell is like the front desk. It's where you (the human) walk in and make requests. You type commands, and the shell figures out what you're asking for and passes your request along.</p> <p>System Calls (syscalls) are like official request forms. When a program needs something from the OS -- more memory, access to a file, permission to talk to the network -- it fills out a syscall. This is the only way to ask the kernel for help. No cutting in line, no back doors.</p> <p>The Kernel is the principal's office. This is where the real decisions get made. The kernel manages all the computer's resources: memory, files, running programs, devices, the network, and users. Everything flows through here.</p> <p>Here's a picture of how the layers stack up:</p> <pre><code>+---------------------------------------------+\n|                   Shell                      |  You talk to the OS here\n|  (commands, pipes, job control)              |\n+---------------------------------------------+\n|              System Calls                    |  The official request forms\n|  (the only way to ask the kernel for help)   |\n+---------------------------------------------+\n|                  Kernel                      |  The brain of the OS\n|  (manages everything below)                  |\n|  +----------+ +----------+ +----------+     |\n|  |Processes | | Memory   | |  Files   |     |\n|  +----------+ +----------+ +----------+     |\n|  +----------+ +----------+ +----------+     |\n|  |  Users   | | Devices  | | Network  |     |\n|  +----------+ +----------+ +----------+     |\n+---------------------------------------------+\n</code></pre> <p>You sit at the top (the shell). Your requests travel down through syscalls into the kernel. The kernel does the heavy lifting and sends results back up.</p>"},{"location":"concepts/what-is-an-os/#what-is-pyos","title":"What Is PyOS?","text":"<p>PyOS is a simulated operating system built entirely in Python. It's not a \"real\" OS -- it won't boot up a laptop or run on bare metal hardware. Instead, it's a miniature version of an OS that you can read, run, tinker with, and learn from.</p> <p>Think of it like a model airplane. A model airplane doesn't fly passengers across the ocean, but building one teaches you a ton about how real airplanes work -- wings, engines, control surfaces, all of it.</p> <p>PyOS works the same way. By building and exploring it, you'll learn how real operating systems manage processes, memory, files, and more. And because it's written in Python (a language you already know!), you can actually read the code and understand what's happening at every step.</p>"},{"location":"concepts/what-is-an-os/#the-major-parts-of-pyos","title":"The Major Parts of PyOS","text":"<p>Here's a quick tour of the big pieces. Don't worry about understanding them deeply right now -- each one has its own page where we'll dig in.</p> <p>Processes -- A process is a program that is currently running. When you open a calculator app, that's a process. When you open a browser, that's another process. The OS has to keep track of all of them, decide who gets to use the processor, and make sure they don't interfere with each other.</p> <p>Memory -- Programs need space to store their data while they're running. The OS hands out chunks of memory to each process and makes sure no process accidentally (or sneakily) reads another process's data.</p> <p>Filesystem -- This is how the OS organizes files and folders on your hard drive. It keeps track of where every file lives, what's inside it, and who's allowed to read or change it.</p> <p>Shell -- The shell is your way of talking to the OS. You type commands, and the shell interprets them and makes things happen. It can also chain commands together using pipes and run tasks in the background.</p> <p>Devices -- Your computer has a screen, a keyboard, a mouse, maybe a printer. The OS needs to talk to all of them, and they all speak different \"languages.\" The device system translates between programs and hardware.</p> <p>Networking -- When your computer sends a message over the internet or talks to another computer on your Wi-Fi, the OS manages that connection. It breaks data into packets, sends them out, and reassembles incoming packets into something useful.</p> <p>Users -- Most operating systems support multiple users. The user system keeps track of who is who, what they're allowed to do, and makes sure one user can't mess with another user's files or processes.</p>"},{"location":"concepts/what-is-an-os/#where-to-go-next","title":"Where to Go Next","text":"<p>Pick whatever sounds most interesting to you. There's no wrong order -- each topic stands on its own.</p> <ul> <li>Processes -- How the OS runs programs and shares the processor</li> <li>Memory -- How the OS hands out and protects memory</li> <li>Filesystem -- How files and folders are organized and stored</li> <li>The Kernel -- The core of the OS and how programs talk to it</li> <li>The Shell -- Your command-line interface to the OS</li> <li>Devices and Networking -- How the OS talks to hardware and the internet</li> <li>Users and Safety -- How the OS keeps users and their data separate</li> <li>Synchronization -- How threads share resources without stepping on each other</li> <li>The Boot Chain -- What happens between pressing the power button and seeing a prompt</li> <li>Interrupts and Timers -- How hardware devices get the CPU's attention</li> <li>TCP: Reliable Delivery -- How TCP guarantees data arrives complete and in order</li> <li>Interactive Tutorials -- Guided lessons that teach OS concepts hands-on</li> <li>Web UI -- Run PyOS from your browser instead of the terminal</li> </ul> <p>Happy exploring!</p>"}]}